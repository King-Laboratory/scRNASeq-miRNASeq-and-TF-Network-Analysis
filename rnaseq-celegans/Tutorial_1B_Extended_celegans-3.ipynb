{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extended RNA-Seq Analysis Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial workflow uses the full dataset from Mittenbühler MJ et al., project.\n",
    "\n",
    "The tutorial repeats the short tutorial, but with the full fastq files and includes some extra steps, such as how to access SRA metadata using Athena, a more powerful and fast step compared to sra-tools.\n",
    "\n",
    "Full fastq files can be rather large, and so the downloading, extracting, and analysis of them means this tutorial can take over 13 hours to run the code fully using ml.m5.4xlarge instance.\n",
    "\n",
    "All outputs used in the DEG tutorial were created using this extended full dataset tutorial workflow.\n",
    "\n",
    "![RNA-Seq workflow](../images/rnaseq-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 1: Install Miniforge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install Miniforge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 86.0M  100 86.0M    0     0   124M      0 --:--:-- --:--:-- --:--:--  124M\n",
      "PREFIX=/home/ec2-user/miniforge\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/ec2-user/miniforge/envs/_virtual_specs_checks\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "Dry run. Not executing the transaction.\n",
      "Unpacking payload ...\n",
      "Extracting _libgcc_mutex-0.1-conda_forge.tar.bz2\n",
      "Extracting ca-certificates-2024.8.30-hbcca054_0.conda\n",
      "Extracting ld_impl_linux-64-2.40-hf3520f5_7.conda\n",
      "Extracting pybind11-abi-4-hd8ed1ab_3.tar.bz2\n",
      "Extracting python_abi-3.12-5_cp312.conda\n",
      "Extracting tzdata-2024a-h8827d51_1.conda\n",
      "Extracting libgomp-14.1.0-h77fa898_1.conda\n",
      "Extracting _openmp_mutex-4.5-2_gnu.tar.bz2\n",
      "Extracting libgcc-14.1.0-h77fa898_1.conda\n",
      "Extracting libexpat-2.6.3-h5888daf_0.conda\n",
      "Extracting libgcc-ng-14.1.0-h69a702a_1.conda\n",
      "Extracting libstdcxx-14.1.0-hc0a3c3a_1.conda\n",
      "Extracting openssl-3.3.2-hb9d3cd8_0.conda\n",
      "Extracting bzip2-1.0.8-h4bc722e_7.conda\n",
      "Extracting c-ares-1.32.3-h4bc722e_0.conda\n",
      "Extracting keyutils-1.6.1-h166bdaf_0.tar.bz2\n",
      "Extracting libev-4.33-hd590300_2.conda\n",
      "Extracting libffi-3.4.2-h7f98852_5.tar.bz2\n",
      "Extracting libiconv-1.17-hd590300_2.conda\n",
      "Extracting libnsl-2.0.1-hd590300_0.conda\n",
      "Extracting libstdcxx-ng-14.1.0-h4852527_1.conda\n",
      "Extracting libuuid-2.38.1-h0b41bf4_0.conda\n",
      "Extracting libxcrypt-4.4.36-hd590300_1.conda\n",
      "Extracting libzlib-1.3.1-h4ab18f5_1.conda\n",
      "Extracting lzo-2.10-hd590300_1001.conda\n",
      "Extracting ncurses-6.5-he02047a_1.conda\n",
      "Extracting reproc-14.2.4.post0-hd590300_1.conda\n",
      "Extracting xz-5.2.6-h166bdaf_0.tar.bz2\n",
      "Extracting fmt-10.2.1-h00ab1b0_0.conda\n",
      "Extracting icu-75.1-he02047a_0.conda\n",
      "Extracting libedit-3.1.20191231-he28a2e2_2.tar.bz2\n",
      "Extracting libnghttp2-1.58.0-h47da74e_1.conda\n",
      "Extracting libsolv-0.7.30-h3509ff9_0.conda\n",
      "Extracting libsqlite-3.46.1-hadc24fc_0.conda\n",
      "Extracting libssh2-1.11.0-h0841786_0.conda\n",
      "Extracting lz4-c-1.9.4-hcb278e6_0.conda\n",
      "Extracting readline-8.2-h8228510_1.conda\n",
      "Extracting reproc-cpp-14.2.4.post0-h59595ed_1.conda\n",
      "Extracting tk-8.6.13-noxft_h4845f30_101.conda\n",
      "Extracting yaml-cpp-0.8.0-h59595ed_0.conda\n",
      "Extracting zstd-1.5.6-ha6fb4c9_0.conda\n",
      "Extracting krb5-1.21.3-h659f571_0.conda\n",
      "Extracting libxml2-2.12.7-he7c6b58_4.conda\n",
      "Extracting python-3.12.6-hc5c86c4_1_cpython.conda\n",
      "Extracting libarchive-3.7.4-hfca40fe_0.conda\n",
      "Extracting libcurl-8.10.1-hbbe4b11_0.conda\n",
      "Extracting menuinst-2.1.2-py312h7900ff3_1.conda\n",
      "Extracting archspec-0.2.3-pyhd8ed1ab_0.conda\n",
      "Extracting boltons-24.0.0-pyhd8ed1ab_0.conda\n",
      "Extracting brotli-python-1.1.0-py312h2ec8cdc_2.conda\n",
      "Extracting certifi-2024.8.30-pyhd8ed1ab_0.conda\n",
      "Extracting charset-normalizer-3.3.2-pyhd8ed1ab_0.conda\n",
      "Extracting colorama-0.4.6-pyhd8ed1ab_0.tar.bz2\n",
      "Extracting distro-1.9.0-pyhd8ed1ab_0.conda\n",
      "Extracting frozendict-2.4.4-py312h66e93f0_1.conda\n",
      "Extracting hpack-4.0.0-pyh9f0ad1d_0.tar.bz2\n",
      "Extracting hyperframe-6.0.1-pyhd8ed1ab_0.tar.bz2\n",
      "Extracting idna-3.10-pyhd8ed1ab_0.conda\n",
      "Extracting jsonpointer-3.0.0-py312h7900ff3_1.conda\n",
      "Extracting libmamba-1.5.9-h4cc3d14_0.conda\n",
      "Extracting packaging-24.1-pyhd8ed1ab_0.conda\n",
      "Extracting platformdirs-4.3.6-pyhd8ed1ab_0.conda\n",
      "Extracting pluggy-1.5.0-pyhd8ed1ab_0.conda\n",
      "Extracting pycosat-0.6.6-py312h98912ed_0.conda\n",
      "Extracting pycparser-2.22-pyhd8ed1ab_0.conda\n",
      "Extracting pysocks-1.7.1-pyha2e5f31_6.tar.bz2\n",
      "Extracting ruamel.yaml.clib-0.2.8-py312h98912ed_0.conda\n",
      "Extracting setuptools-74.1.2-pyhd8ed1ab_0.conda\n",
      "Extracting truststore-0.9.2-pyhd8ed1ab_0.conda\n",
      "Extracting wheel-0.44.0-pyhd8ed1ab_0.conda\n",
      "Extracting cffi-1.17.1-py312h06ac9bb_0.conda\n",
      "Extracting h2-4.1.0-pyhd8ed1ab_0.tar.bz2\n",
      "Extracting jsonpatch-1.33-pyhd8ed1ab_0.conda\n",
      "Extracting libmambapy-1.5.9-py312h7fb9e8e_0.conda\n",
      "Extracting pip-24.2-pyh8b19718_1.conda\n",
      "Extracting ruamel.yaml-0.18.6-py312h98912ed_0.conda\n",
      "Extracting tqdm-4.66.5-pyhd8ed1ab_0.conda\n",
      "Extracting zstandard-0.23.0-py312hef9b889_1.conda\n",
      "Extracting conda-package-streaming-0.10.0-pyhd8ed1ab_0.conda\n",
      "Extracting urllib3-2.2.3-pyhd8ed1ab_0.conda\n",
      "Extracting conda-package-handling-2.3.0-pyh7900ff3_0.conda\n",
      "Extracting requests-2.32.3-pyhd8ed1ab_0.conda\n",
      "Extracting conda-24.7.1-py312h7900ff3_0.conda\n",
      "Extracting conda-libmamba-solver-24.7.0-pyhd8ed1ab_0.conda\n",
      "Extracting mamba-1.5.9-py312h9460a1c_0.conda\n",
      "\n",
      "Installing base environment...\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/ec2-user/miniforge\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - conda-forge/linux-64::_libgcc_mutex==0.1=conda_forge[md5=d7c89558ba9fa0495403155b64376d81]\n",
      "   - conda-forge/linux-64::ca-certificates==2024.8.30=hbcca054_0[md5=c27d1c142233b5bc9ca570c6e2e0c244]\n",
      "   - conda-forge/linux-64::ld_impl_linux-64==2.40=hf3520f5_7[md5=b80f2f396ca2c28b8c14c437a4ed1e74]\n",
      "   - conda-forge/noarch::pybind11-abi==4=hd8ed1ab_3[md5=878f923dd6acc8aeb47a75da6c4098be]\n",
      "   - conda-forge/linux-64::python_abi==3.12=5_cp312[md5=0424ae29b104430108f5218a66db7260]\n",
      "   - conda-forge/noarch::tzdata==2024a=h8827d51_1[md5=8bfdead4e0fff0383ae4c9c50d0531bd]\n",
      "   - conda-forge/linux-64::libgomp==14.1.0=h77fa898_1[md5=23c255b008c4f2ae008f81edcabaca89]\n",
      "   - conda-forge/linux-64::_openmp_mutex==4.5=2_gnu[md5=73aaf86a425cc6e73fcf236a5a46396d]\n",
      "   - conda-forge/linux-64::libgcc==14.1.0=h77fa898_1[md5=002ef4463dd1e2b44a94a4ace468f5d2]\n",
      "   - conda-forge/linux-64::libexpat==2.6.3=h5888daf_0[md5=59f4c43bb1b5ef1c71946ff2cbf59524]\n",
      "   - conda-forge/linux-64::libgcc-ng==14.1.0=h69a702a_1[md5=1efc0ad219877a73ef977af7dbb51f17]\n",
      "   - conda-forge/linux-64::libstdcxx==14.1.0=hc0a3c3a_1[md5=9dbb9699ea467983ba8a4ba89b08b066]\n",
      "   - conda-forge/linux-64::openssl==3.3.2=hb9d3cd8_0[md5=4d638782050ab6faa27275bed57e9b4e]\n",
      "   - conda-forge/linux-64::bzip2==1.0.8=h4bc722e_7[md5=62ee74e96c5ebb0af99386de58cf9553]\n",
      "   - conda-forge/linux-64::c-ares==1.32.3=h4bc722e_0[md5=7624e34ee6baebfc80d67bac76cc9d9d]\n",
      "   - conda-forge/linux-64::keyutils==1.6.1=h166bdaf_0[md5=30186d27e2c9fa62b45fb1476b7200e3]\n",
      "   - conda-forge/linux-64::libev==4.33=hd590300_2[md5=172bf1cd1ff8629f2b1179945ed45055]\n",
      "   - conda-forge/linux-64::libffi==3.4.2=h7f98852_5[md5=d645c6d2ac96843a2bfaccd2d62b3ac3]\n",
      "   - conda-forge/linux-64::libiconv==1.17=hd590300_2[md5=d66573916ffcf376178462f1b61c941e]\n",
      "   - conda-forge/linux-64::libnsl==2.0.1=hd590300_0[md5=30fd6e37fe21f86f4bd26d6ee73eeec7]\n",
      "   - conda-forge/linux-64::libstdcxx-ng==14.1.0=h4852527_1[md5=bd2598399a70bb86d8218e95548d735e]\n",
      "   - conda-forge/linux-64::libuuid==2.38.1=h0b41bf4_0[md5=40b61aab5c7ba9ff276c41cfffe6b80b]\n",
      "   - conda-forge/linux-64::libxcrypt==4.4.36=hd590300_1[md5=5aa797f8787fe7a17d1b0821485b5adc]\n",
      "   - conda-forge/linux-64::libzlib==1.3.1=h4ab18f5_1[md5=57d7dc60e9325e3de37ff8dffd18e814]\n",
      "   - conda-forge/linux-64::lzo==2.10=hd590300_1001[md5=ec7398d21e2651e0dcb0044d03b9a339]\n",
      "   - conda-forge/linux-64::ncurses==6.5=he02047a_1[md5=70caf8bb6cf39a0b6b7efc885f51c0fe]\n",
      "   - conda-forge/linux-64::reproc==14.2.4.post0=hd590300_1[md5=82ca53502dfd5a64a80dee76dae14685]\n",
      "   - conda-forge/linux-64::xz==5.2.6=h166bdaf_0[md5=2161070d867d1b1204ea749c8eec4ef0]\n",
      "   - conda-forge/linux-64::fmt==10.2.1=h00ab1b0_0[md5=35ef8bc24bd34074ebae3c943d551728]\n",
      "   - conda-forge/linux-64::icu==75.1=he02047a_0[md5=8b189310083baabfb622af68fd9d3ae3]\n",
      "   - conda-forge/linux-64::libedit==3.1.20191231=he28a2e2_2[md5=4d331e44109e3f0e19b4cb8f9b82f3e1]\n",
      "   - conda-forge/linux-64::libnghttp2==1.58.0=h47da74e_1[md5=700ac6ea6d53d5510591c4344d5c989a]\n",
      "   - conda-forge/linux-64::libsolv==0.7.30=h3509ff9_0[md5=02539b77d25aa4f65b20246549e256c3]\n",
      "   - conda-forge/linux-64::libsqlite==3.46.1=hadc24fc_0[md5=36f79405ab16bf271edb55b213836dac]\n",
      "   - conda-forge/linux-64::libssh2==1.11.0=h0841786_0[md5=1f5a58e686b13bcfde88b93f547d23fe]\n",
      "   - conda-forge/linux-64::lz4-c==1.9.4=hcb278e6_0[md5=318b08df404f9c9be5712aaa5a6f0bb0]\n",
      "   - conda-forge/linux-64::readline==8.2=h8228510_1[md5=47d31b792659ce70f470b5c82fdfb7a4]\n",
      "   - conda-forge/linux-64::reproc-cpp==14.2.4.post0=h59595ed_1[md5=715e1d720ec1a03715bebd237972fca5]\n",
      "   - conda-forge/linux-64::tk==8.6.13=noxft_h4845f30_101[md5=d453b98d9c83e71da0741bb0ff4d76bc]\n",
      "   - conda-forge/linux-64::yaml-cpp==0.8.0=h59595ed_0[md5=965eaacd7c18eb8361fd12bb9e7a57d7]\n",
      "   - conda-forge/linux-64::zstd==1.5.6=ha6fb4c9_0[md5=4d056880988120e29d75bfff282e0f45]\n",
      "   - conda-forge/linux-64::krb5==1.21.3=h659f571_0[md5=3f43953b7d3fb3aaa1d0d0723d91e368]\n",
      "   - conda-forge/linux-64::libxml2==2.12.7=he7c6b58_4[md5=08a9265c637230c37cb1be4a6cad4536]\n",
      "   - conda-forge/linux-64::python==3.12.6=hc5c86c4_1_cpython[md5=00836baacdca254f28c54d2543e97514]\n",
      "   - conda-forge/linux-64::libarchive==3.7.4=hfca40fe_0[md5=32ddb97f897740641d8d46a829ce1704]\n",
      "   - conda-forge/linux-64::libcurl==8.10.1=hbbe4b11_0[md5=6e801c50a40301f6978c53976917b277]\n",
      "   - conda-forge/linux-64::menuinst==2.1.2=py312h7900ff3_1[md5=c6575ae996f2bc0369c73b632db5ca61]\n",
      "   - conda-forge/noarch::archspec==0.2.3=pyhd8ed1ab_0[md5=192278292e20704f663b9c766909d67b]\n",
      "   - conda-forge/noarch::boltons==24.0.0=pyhd8ed1ab_0[md5=61de176bd62041f9cd5bd4fcd09eb0ff]\n",
      "   - conda-forge/linux-64::brotli-python==1.1.0=py312h2ec8cdc_2[md5=b0b867af6fc74b2a0aa206da29c0f3cf]\n",
      "   - conda-forge/noarch::certifi==2024.8.30=pyhd8ed1ab_0[md5=12f7d00853807b0531775e9be891cb11]\n",
      "   - conda-forge/noarch::charset-normalizer==3.3.2=pyhd8ed1ab_0[md5=7f4a9e3fcff3f6356ae99244a014da6a]\n",
      "   - conda-forge/noarch::colorama==0.4.6=pyhd8ed1ab_0[md5=3faab06a954c2a04039983f2c4a50d99]\n",
      "   - conda-forge/noarch::distro==1.9.0=pyhd8ed1ab_0[md5=bbdb409974cd6cb30071b1d978302726]\n",
      "   - conda-forge/linux-64::frozendict==2.4.4=py312h66e93f0_1[md5=82a14d06575c4023a5df6b0798acff71]\n",
      "   - conda-forge/noarch::hpack==4.0.0=pyh9f0ad1d_0[md5=914d6646c4dbb1fd3ff539830a12fd71]\n",
      "   - conda-forge/noarch::hyperframe==6.0.1=pyhd8ed1ab_0[md5=9f765cbfab6870c8435b9eefecd7a1f4]\n",
      "   - conda-forge/noarch::idna==3.10=pyhd8ed1ab_0[md5=7ba2ede0e7c795ff95088daf0dc59753]\n",
      "   - conda-forge/linux-64::jsonpointer==3.0.0=py312h7900ff3_1[md5=6b51f7459ea4073eeb5057207e2e1e3d]\n",
      "   - conda-forge/linux-64::libmamba==1.5.9=h4cc3d14_0[md5=896cece5b883ad86e9dd88b1f4d23c99]\n",
      "   - conda-forge/noarch::packaging==24.1=pyhd8ed1ab_0[md5=cbe1bb1f21567018ce595d9c2be0f0db]\n",
      "   - conda-forge/noarch::platformdirs==4.3.6=pyhd8ed1ab_0[md5=fd8f2b18b65bbf62e8f653100690c8d2]\n",
      "   - conda-forge/noarch::pluggy==1.5.0=pyhd8ed1ab_0[md5=d3483c8fc2dc2cc3f5cf43e26d60cabf]\n",
      "   - conda-forge/linux-64::pycosat==0.6.6=py312h98912ed_0[md5=8f1c372e7b843167be885dc8229931c1]\n",
      "   - conda-forge/noarch::pycparser==2.22=pyhd8ed1ab_0[md5=844d9eb3b43095b031874477f7d70088]\n",
      "   - conda-forge/noarch::pysocks==1.7.1=pyha2e5f31_6[md5=2a7de29fb590ca14b5243c4c812c8025]\n",
      "   - conda-forge/linux-64::ruamel.yaml.clib==0.2.8=py312h98912ed_0[md5=05f31c2a79ba61df8d6d903ce4a4ce7b]\n",
      "   - conda-forge/noarch::setuptools==74.1.2=pyhd8ed1ab_0[md5=56c9c11d004428e81d02eeb730fc6336]\n",
      "   - conda-forge/noarch::truststore==0.9.2=pyhd8ed1ab_0[md5=f14e46d1bf271e748ff556d8b872e28a]\n",
      "   - conda-forge/noarch::wheel==0.44.0=pyhd8ed1ab_0[md5=d44e3b085abcaef02983c6305b84b584]\n",
      "   - conda-forge/linux-64::cffi==1.17.1=py312h06ac9bb_0[md5=a861504bbea4161a9170b85d4d2be840]\n",
      "   - conda-forge/noarch::h2==4.1.0=pyhd8ed1ab_0[md5=b748fbf7060927a6e82df7cb5ee8f097]\n",
      "   - conda-forge/noarch::jsonpatch==1.33=pyhd8ed1ab_0[md5=bfdb7c5c6ad1077c82a69a8642c87aff]\n",
      "   - conda-forge/linux-64::libmambapy==1.5.9=py312h7fb9e8e_0[md5=ccaeeb6e3caaf0c744480393791aa366]\n",
      "   - conda-forge/noarch::pip==24.2=pyh8b19718_1[md5=6c78fbb8ddfd64bcb55b5cbafd2d2c43]\n",
      "   - conda-forge/linux-64::ruamel.yaml==0.18.6=py312h98912ed_0[md5=a99a06a875138829ef65f44bbe2c30ca]\n",
      "   - conda-forge/noarch::tqdm==4.66.5=pyhd8ed1ab_0[md5=c6e94fc2b2ec71ea33fe7c7da259acb4]\n",
      "   - conda-forge/linux-64::zstandard==0.23.0=py312hef9b889_1[md5=8b7069e9792ee4e5b4919a7a306d2e67]\n",
      "   - conda-forge/noarch::conda-package-streaming==0.10.0=pyhd8ed1ab_0[md5=3480386e00995f7a1dfb3b9aa2fe70fd]\n",
      "   - conda-forge/noarch::urllib3==2.2.3=pyhd8ed1ab_0[md5=6b55867f385dd762ed99ea687af32a69]\n",
      "   - conda-forge/noarch::conda-package-handling==2.3.0=pyh7900ff3_0[md5=0a7dce281ae2be81acab0aa963e6bb99]\n",
      "   - conda-forge/noarch::requests==2.32.3=pyhd8ed1ab_0[md5=5ede4753180c7a550a443c430dc8ab52]\n",
      "   - conda-forge/linux-64::conda==24.7.1=py312h7900ff3_0[md5=e1bf59014e88eaff036101358f63a496]\n",
      "   - conda-forge/noarch::conda-libmamba-solver==24.7.0=pyhd8ed1ab_0[md5=857c9e25f0a77c0bd7eb622d46d9418f]\n",
      "   - conda-forge/linux-64::mamba==1.5.9=py312h9460a1c_0[md5=a8525c8a1647b4f5967fa6b552722851]\n",
      "\n",
      "\n",
      "  Package                         Version  Build               Channel         Size\n",
      "─────────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "─────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[32m+ _libgcc_mutex          \u001b[0m           0.1  conda_forge         conda-forge         \n",
      "  \u001b[32m+ ca-certificates        \u001b[0m     2024.8.30  hbcca054_0          conda-forge         \n",
      "  \u001b[32m+ ld_impl_linux-64       \u001b[0m          2.40  hf3520f5_7          conda-forge         \n",
      "  \u001b[32m+ pybind11-abi           \u001b[0m             4  hd8ed1ab_3          conda-forge         \n",
      "  \u001b[32m+ python_abi             \u001b[0m          3.12  5_cp312             conda-forge         \n",
      "  \u001b[32m+ tzdata                 \u001b[0m         2024a  h8827d51_1          conda-forge         \n",
      "  \u001b[32m+ libgomp                \u001b[0m        14.1.0  h77fa898_1          conda-forge         \n",
      "  \u001b[32m+ _openmp_mutex          \u001b[0m           4.5  2_gnu               conda-forge         \n",
      "  \u001b[32m+ libgcc                 \u001b[0m        14.1.0  h77fa898_1          conda-forge         \n",
      "  \u001b[32m+ libexpat               \u001b[0m         2.6.3  h5888daf_0          conda-forge         \n",
      "  \u001b[32m+ libgcc-ng              \u001b[0m        14.1.0  h69a702a_1          conda-forge         \n",
      "  \u001b[32m+ libstdcxx              \u001b[0m        14.1.0  hc0a3c3a_1          conda-forge         \n",
      "  \u001b[32m+ openssl                \u001b[0m         3.3.2  hb9d3cd8_0          conda-forge         \n",
      "  \u001b[32m+ bzip2                  \u001b[0m         1.0.8  h4bc722e_7          conda-forge         \n",
      "  \u001b[32m+ c-ares                 \u001b[0m        1.32.3  h4bc722e_0          conda-forge         \n",
      "  \u001b[32m+ keyutils               \u001b[0m         1.6.1  h166bdaf_0          conda-forge         \n",
      "  \u001b[32m+ libev                  \u001b[0m          4.33  hd590300_2          conda-forge         \n",
      "  \u001b[32m+ libffi                 \u001b[0m         3.4.2  h7f98852_5          conda-forge         \n",
      "  \u001b[32m+ libiconv               \u001b[0m          1.17  hd590300_2          conda-forge         \n",
      "  \u001b[32m+ libnsl                 \u001b[0m         2.0.1  hd590300_0          conda-forge         \n",
      "  \u001b[32m+ libstdcxx-ng           \u001b[0m        14.1.0  h4852527_1          conda-forge         \n",
      "  \u001b[32m+ libuuid                \u001b[0m        2.38.1  h0b41bf4_0          conda-forge         \n",
      "  \u001b[32m+ libxcrypt              \u001b[0m        4.4.36  hd590300_1          conda-forge         \n",
      "  \u001b[32m+ libzlib                \u001b[0m         1.3.1  h4ab18f5_1          conda-forge         \n",
      "  \u001b[32m+ lzo                    \u001b[0m          2.10  hd590300_1001       conda-forge         \n",
      "  \u001b[32m+ ncurses                \u001b[0m           6.5  he02047a_1          conda-forge         \n",
      "  \u001b[32m+ reproc                 \u001b[0m  14.2.4.post0  hd590300_1          conda-forge         \n",
      "  \u001b[32m+ xz                     \u001b[0m         5.2.6  h166bdaf_0          conda-forge         \n",
      "  \u001b[32m+ fmt                    \u001b[0m        10.2.1  h00ab1b0_0          conda-forge         \n",
      "  \u001b[32m+ icu                    \u001b[0m          75.1  he02047a_0          conda-forge         \n",
      "  \u001b[32m+ libedit                \u001b[0m  3.1.20191231  he28a2e2_2          conda-forge         \n",
      "  \u001b[32m+ libnghttp2             \u001b[0m        1.58.0  h47da74e_1          conda-forge         \n",
      "  \u001b[32m+ libsolv                \u001b[0m        0.7.30  h3509ff9_0          conda-forge         \n",
      "  \u001b[32m+ libsqlite              \u001b[0m        3.46.1  hadc24fc_0          conda-forge         \n",
      "  \u001b[32m+ libssh2                \u001b[0m        1.11.0  h0841786_0          conda-forge         \n",
      "  \u001b[32m+ lz4-c                  \u001b[0m         1.9.4  hcb278e6_0          conda-forge         \n",
      "  \u001b[32m+ readline               \u001b[0m           8.2  h8228510_1          conda-forge         \n",
      "  \u001b[32m+ reproc-cpp             \u001b[0m  14.2.4.post0  h59595ed_1          conda-forge         \n",
      "  \u001b[32m+ tk                     \u001b[0m        8.6.13  noxft_h4845f30_101  conda-forge         \n",
      "  \u001b[32m+ yaml-cpp               \u001b[0m         0.8.0  h59595ed_0          conda-forge         \n",
      "  \u001b[32m+ zstd                   \u001b[0m         1.5.6  ha6fb4c9_0          conda-forge         \n",
      "  \u001b[32m+ krb5                   \u001b[0m        1.21.3  h659f571_0          conda-forge         \n",
      "  \u001b[32m+ libxml2                \u001b[0m        2.12.7  he7c6b58_4          conda-forge         \n",
      "  \u001b[32m+ python                 \u001b[0m        3.12.6  hc5c86c4_1_cpython  conda-forge         \n",
      "  \u001b[32m+ libarchive             \u001b[0m         3.7.4  hfca40fe_0          conda-forge         \n",
      "  \u001b[32m+ libcurl                \u001b[0m        8.10.1  hbbe4b11_0          conda-forge         \n",
      "  \u001b[32m+ menuinst               \u001b[0m         2.1.2  py312h7900ff3_1     conda-forge         \n",
      "  \u001b[32m+ archspec               \u001b[0m         0.2.3  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ boltons                \u001b[0m        24.0.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ brotli-python          \u001b[0m         1.1.0  py312h2ec8cdc_2     conda-forge         \n",
      "  \u001b[32m+ certifi                \u001b[0m     2024.8.30  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ charset-normalizer     \u001b[0m         3.3.2  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ colorama               \u001b[0m         0.4.6  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ distro                 \u001b[0m         1.9.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ frozendict             \u001b[0m         2.4.4  py312h66e93f0_1     conda-forge         \n",
      "  \u001b[32m+ hpack                  \u001b[0m         4.0.0  pyh9f0ad1d_0        conda-forge         \n",
      "  \u001b[32m+ hyperframe             \u001b[0m         6.0.1  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ idna                   \u001b[0m          3.10  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ jsonpointer            \u001b[0m         3.0.0  py312h7900ff3_1     conda-forge         \n",
      "  \u001b[32m+ libmamba               \u001b[0m         1.5.9  h4cc3d14_0          conda-forge         \n",
      "  \u001b[32m+ packaging              \u001b[0m          24.1  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ platformdirs           \u001b[0m         4.3.6  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ pluggy                 \u001b[0m         1.5.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ pycosat                \u001b[0m         0.6.6  py312h98912ed_0     conda-forge         \n",
      "  \u001b[32m+ pycparser              \u001b[0m          2.22  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ pysocks                \u001b[0m         1.7.1  pyha2e5f31_6        conda-forge         \n",
      "  \u001b[32m+ ruamel.yaml.clib       \u001b[0m         0.2.8  py312h98912ed_0     conda-forge         \n",
      "  \u001b[32m+ setuptools             \u001b[0m        74.1.2  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ truststore             \u001b[0m         0.9.2  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ wheel                  \u001b[0m        0.44.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ cffi                   \u001b[0m        1.17.1  py312h06ac9bb_0     conda-forge         \n",
      "  \u001b[32m+ h2                     \u001b[0m         4.1.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ jsonpatch              \u001b[0m          1.33  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ libmambapy             \u001b[0m         1.5.9  py312h7fb9e8e_0     conda-forge         \n",
      "  \u001b[32m+ pip                    \u001b[0m          24.2  pyh8b19718_1        conda-forge         \n",
      "  \u001b[32m+ ruamel.yaml            \u001b[0m        0.18.6  py312h98912ed_0     conda-forge         \n",
      "  \u001b[32m+ tqdm                   \u001b[0m        4.66.5  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ zstandard              \u001b[0m        0.23.0  py312hef9b889_1     conda-forge         \n",
      "  \u001b[32m+ conda-package-streaming\u001b[0m        0.10.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ urllib3                \u001b[0m         2.2.3  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ conda-package-handling \u001b[0m         2.3.0  pyh7900ff3_0        conda-forge         \n",
      "  \u001b[32m+ requests               \u001b[0m        2.32.3  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ conda                  \u001b[0m        24.7.1  py312h7900ff3_0     conda-forge         \n",
      "  \u001b[32m+ conda-libmamba-solver  \u001b[0m        24.7.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ mamba                  \u001b[0m         1.5.9  py312h9460a1c_0     conda-forge         \n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 85 packages\n",
      "\n",
      "  Total download: 0 B\n",
      "\n",
      "─────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\n",
      "\n",
      "Transaction starting\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "Transaction finished\n",
      "\n",
      "To activate this environment, use:\n",
      "\n",
      "    micromamba activate /home/ec2-user/miniforge\n",
      "\n",
      "Or to execute a single command in this environment, use:\n",
      "\n",
      "    micromamba run -p /home/ec2-user/miniforge mycommand\n",
      "\n",
      "installation finished.\n",
      "07:28:38\n"
     ]
    }
   ],
   "source": [
    "# Download Miniforge or Mambaforge (you can use either based on preference)\n",
    "!curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\n",
    "\n",
    "# Install Miniforge (or Mambaforge) - no need to install conda since mamba will be available immediately\n",
    "!bash Miniforge3-$(uname)-$(uname -m).sh -b -u -p $HOME/miniforge\n",
    "!date +\"%T\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using mambaforge and bioconda, install the tools that will be used in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for: ['trimmomatic', 'fastqc', 'multiqc', 'sql-magic', 'entrez-direct', 'gffread', 'parallel-fastq-dump', 'sra-tools', 'sql-magic', 'pyathena', 'samtools', 'star', 'rsem', 'entrez-direct', 'subread', 'pigz']\n",
      "\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/home/ec2-user/anaconda3/pkgs/cache/497deca9.json\" was modified by another program\n",
      "\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/home/ec2-user/anaconda3/pkgs/cache/09cdf8bf.json\" was modified by another program\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "bioconda/linux-64 (check zst) \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m   0.0 B @  ??.?MB/s Checking  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gbioconda/linux-64 (check zst)                       Checked  0.2s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gbioconda/noarch (check zst)                        Checked  0.0s\n",
      "\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Could not parse state file: Could not load cache state: [json.exception.type_error.302] type must be string, but is null\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/.. \u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   0.0 B  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0Ghttps://aws-ml-conda.s3.us-west-2.amazonaws.com/..  0.2s\n",
      "\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Could not parse state file: Could not load cache state: [json.exception.type_error.302] type must be string, but is null\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Ghttps://aws-ml-conda.s3.us-west-2.amazonaws.com/.. Checked  0.1s\n",
      "\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/home/ec2-user/anaconda3/pkgs/cache/c9ddbd6b.json\" was modified by another program\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/linux-64 (check zst)                        Checked  0.0s\n",
      "\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/home/ec2-user/anaconda3/pkgs/cache/b121c3e7.json\" was modified by another program\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/noarch (check zst)                          Checked  0.0s\n",
      "\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/home/ec2-user/anaconda3/pkgs/cache/ee0ed9e9.json\" was modified by another program\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpytorch/linux-64 (check zst)                       Checked  0.0s\n",
      "\u001b[?25h\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/home/ec2-user/anaconda3/pkgs/cache/edb1952f.json\" was modified by another program\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpytorch/noarch (check zst)                         Checked  0.1s\n",
      "\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "conda-forge/linux-64                               \u001b[90m━━━━━━━━━━━━━━━\u001b[0m 567.6kB  0.1s\n",
      "conda-forge/noarch                                 \u001b[90m━━━━━━━━━━━━━━━\u001b[0m  28.0kB  0.1s\n",
      "bioconda/linux-64                                  \u001b[90m━━━━━━━━━━━━━━━\u001b[0m  28.7kB  0.1s\n",
      "bioconda/noarch                                    ━╸\u001b[90m━━━━━━━━━━━━━\u001b[0m 769.3kB  0.1s\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/.. \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m   0.0 B  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gbioconda/noarch                                     0.1s\n",
      "pytorch/linux-64                                   185.6kB @   1.0MB/s  0.0s\n",
      "bioconda/linux-64                                   0.2s\n",
      "[+] 0.2s\n",
      "conda-forge/linux-64                               ╸\u001b[90m━━━━━━━━━━━━━━\u001b[0m   4.2MB  0.2s\n",
      "conda-forge/noarch                                 ━╸\u001b[90m━━━━━━━━━━━━━\u001b[0m   3.3MB  0.2s\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/.. ╸\u001b[90m━━━━━━━━━━━━━━\u001b[0m  17.0kB  0.2s\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/.. \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m   0.0 B  0.0s\n",
      "nvidia/linux-64                                    \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   0.0 B  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnvidia/linux-64                                     0.0s\n",
      "nvidia/noarch                                       17.1kB @  67.8kB/s  0.0s\n",
      "pytorch/noarch                                       9.9kB @  34.1kB/s  0.0s\n",
      "[+] 0.3s\n",
      "conda-forge/linux-64                               ━━╸\u001b[90m━━━━━━━━━━━━\u001b[0m  10.2MB  0.3s\n",
      "conda-forge/noarch                                 ━━━━━━━╸\u001b[90m━━━━━━━\u001b[0m   9.4MB  0.3s\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/.. ━━━━━━━━━╸\u001b[90m━━━━━\u001b[0m 103.0kB  0.3s\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/.. \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   0.0 B  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ghttps://aws-ml-conda.s3.us-west-2.amazonaws.com/..  0.3s\n",
      "conda-forge/noarch                                  0.4s\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/..  0.2s\n",
      "[+] 0.4s\n",
      "conda-forge/linux-64 ━━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━\u001b[0m  16.6MB /  38.8MB @  45.8MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━━\u001b[0m  30.4MB /  38.8MB @  65.7MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                                38.8MB @  74.1MB/s  0.5s\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.10.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/ec2-user/anaconda3/envs/tensorflow2_p310\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - trimmomatic\n",
      "   - fastqc\n",
      "   - multiqc\n",
      "   - sql-magic\n",
      "   - entrez-direct\n",
      "   - gffread\n",
      "   - parallel-fastq-dump\n",
      "   - sra-tools\n",
      "   - sql-magic\n",
      "   - pyathena\n",
      "   - samtools\n",
      "   - star\n",
      "   - rsem\n",
      "   - entrez-direct\n",
      "   - subread\n",
      "   - pigz\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package                         Version  Build                Channel           Size\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[32m+ colormath                \u001b[0m       3.0.0  py_2                 conda-forge       35kB\n",
      "  \u001b[32m+ pyaml-env                \u001b[0m       1.2.1  pyhd8ed1ab_0         conda-forge       14kB\n",
      "  \u001b[32m+ humanize                 \u001b[0m      4.11.0  pyhd8ed1ab_0         conda-forge       66kB\n",
      "  \u001b[32m+ importlib-metadata       \u001b[0m       8.5.0  pyha770c72_0         conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ packaging                \u001b[0m        24.1  pyhd8ed1ab_0         conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ rich-click               \u001b[0m       1.8.3  pyhd8ed1ab_0         conda-forge       34kB\n",
      "  \u001b[32m+ annotated-types          \u001b[0m       0.7.0  pyhd8ed1ab_0         conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ botocore                 \u001b[0m     1.35.35  pyge310_1234567_0    conda-forge        7MB\n",
      "  \u001b[32m+ findspark                \u001b[0m       2.0.1  pyhd8ed1ab_0         conda-forge        8kB\n",
      "  \u001b[32m+ sqlparse                 \u001b[0m       0.5.1  pyhd8ed1ab_0         conda-forge       40kB\n",
      "  \u001b[32m+ humanfriendly            \u001b[0m        10.0  pyhd8ed1ab_6         conda-forge       73kB\n",
      "  \u001b[32m+ _r-mutex                 \u001b[0m       1.0.1  anacondar_1          conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libgcc-devel_linux-64    \u001b[0m      14.1.0  h5d3d1c9_101         conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libstdcxx-devel_linux-64 \u001b[0m      14.1.0  h5d3d1c9_101         conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ kernel-headers_linux-64  \u001b[0m      3.10.0  he073ed8_17          conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ spectra                  \u001b[0m      0.0.11  py_1                 conda-forge       19kB\n",
      "  \u001b[32m+ typeguard                \u001b[0m       4.3.0  pyhd8ed1ab_1         conda-forge       35kB\n",
      "  \u001b[32m+ markdown                 \u001b[0m         3.6  pyhd8ed1ab_0         conda-forge       78kB\n",
      "  \u001b[32m+ boto3                    \u001b[0m     1.35.35  pyhd8ed1ab_0         conda-forge       83kB\n",
      "  \u001b[32m+ coloredlogs              \u001b[0m      15.0.1  pyhd8ed1ab_3         conda-forge       41kB\n",
      "  \u001b[32m+ sysroot_linux-64         \u001b[0m        2.17  h4a8ded7_17          conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ pyathena                 \u001b[0m       3.9.0  pyhd8ed1ab_0         conda-forge       55kB\n",
      "  \u001b[32m+ libgcc                   \u001b[0m      14.1.0  h77fa898_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ perl                     \u001b[0m    5.22.2.1  0                    conda-forge       16MB\n",
      "  \u001b[32m+ bwidget                  \u001b[0m      1.9.14  ha770c72_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ mathjax                  \u001b[0m       2.7.7  ha770c72_3           conda-forge       22MB\n",
      "  \u001b[32m+ binutils_impl_linux-64   \u001b[0m        2.40  ha1999f0_7           conda-forge        6MB\n",
      "  \u001b[32m+ make                     \u001b[0m       4.4.1  hb9d3cd8_2           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ pydantic-core            \u001b[0m      2.23.4  py310h505e2c1_0      conda-forge        2MB\n",
      "  \u001b[32m+ libstdcxx                \u001b[0m      14.1.0  hc0a3c3a_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libsanitizer             \u001b[0m      14.1.0  hcba0ae0_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ pandas                   \u001b[0m       2.2.3  py310h5eaa309_1      conda-forge       13MB\n",
      "  \u001b[32m+ sed                      \u001b[0m         4.8  he412f7d_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libunistring             \u001b[0m      0.9.10  h7f98852_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ tktable                  \u001b[0m        2.10  h8bc8fbc_6           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ gcc_impl_linux-64        \u001b[0m      14.1.0  h3c94d91_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ ossuuid                  \u001b[0m       1.6.2  hf484d3e_1000        conda-forge       57kB\n",
      "  \u001b[32m+ libidn2                  \u001b[0m       2.3.7  hd590300_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ sqlite                   \u001b[0m      3.46.0  h6d4b2fc_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ pigz                     \u001b[0m         2.8  h2797004_0           conda-forge       72kB\n",
      "  \u001b[32m+ gfortran_impl_linux-64   \u001b[0m      14.1.0  he4a1faa_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ gxx_impl_linux-64        \u001b[0m      14.1.0  h8d00ecb_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ kaleido-core             \u001b[0m       0.2.1  h3644ca4_0           conda-forge       62MB\n",
      "  \u001b[32m+ wget                     \u001b[0m      1.21.4  hda4d442_0           conda-forge      770kB\n",
      "  \u001b[32m+ xorg-libxt               \u001b[0m       1.3.0  hd590300_1           conda-forge      379kB\n",
      "  \u001b[32m+ openjdk                  \u001b[0m      21.0.2  haa376d0_0           conda-forge      181MB\n",
      "  \u001b[32m+ r-base                   \u001b[0m       4.4.0  h019f4a6_1           conda-forge       27MB\n",
      "  \u001b[32m+ r-spatial                \u001b[0m      7.3_17  r44hb1dbf0f_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-rpart                  \u001b[0m      4.1.23  r44hb1dbf0f_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-mass                   \u001b[0m  7.3_60.0.1  r44hb1dbf0f_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-lattice                \u001b[0m      0.22_6  r44hb1dbf0f_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-kernsmooth             \u001b[0m     2.23_24  r44hc2011d3_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-foreign                \u001b[0m      0.8_87  r44hb1dbf0f_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-cluster                \u001b[0m       2.1.6  r44hbcb9c34_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-nnet                   \u001b[0m      7.3_19  r44hb1dbf0f_2        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-class                  \u001b[0m      7.3_22  r44hb1dbf0f_2        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-nlme                   \u001b[0m     3.1_165  r44hbcb9c34_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-matrix                 \u001b[0m       1.6_5  r44he966344_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-survival               \u001b[0m       3.7_0  r44hdb488b9_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-mgcv                   \u001b[0m       1.9_1  r44h0d28552_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ perl-threaded            \u001b[0m      5.32.1  hdfd78af_1           bioconda           6kB\n",
      "  \u001b[32m+ fastqc                   \u001b[0m      0.12.1  hdfd78af_0           bioconda          12MB\n",
      "  \u001b[32m+ trimmomatic              \u001b[0m        0.39  hdfd78af_2           bioconda         147kB\n",
      "  \u001b[32m+ pydantic                 \u001b[0m       2.9.2  pyhd8ed1ab_0         conda-forge      301kB\n",
      "  \u001b[32m+ sql-magic                \u001b[0m       0.0.4  pyhd8ed1ab_0         conda-forge       15kB\n",
      "  \u001b[32m+ python-kaleido           \u001b[0m       0.2.1  pyhd8ed1ab_0         conda-forge       18kB\n",
      "  \u001b[32m+ r-boot                   \u001b[0m      1.3_31  r44hc72bb7e_0        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-codetools              \u001b[0m      0.2_20  r44hc72bb7e_1        conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r-recommended            \u001b[0m         4.4  r44hd8ed1ab_1007     conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ r                        \u001b[0m         4.4  r44hd8ed1ab_1008     conda-forge       18kB\n",
      "  \u001b[32m+ ncbi-vdb                 \u001b[0m       3.1.1  h4ac6f70_2           bioconda          11MB\n",
      "  \u001b[32m+ subread                  \u001b[0m       2.0.6  he4a0461_2           bioconda          27MB\n",
      "  \u001b[32m+ gffread                  \u001b[0m      0.12.7  hdcf5f25_4           bioconda         134kB\n",
      "  \u001b[32m+ htslib                   \u001b[0m        1.21  h5efdd21_0           bioconda           3MB\n",
      "  \u001b[32m+ entrez-direct            \u001b[0m        22.4  he881be0_0           bioconda          15MB\n",
      "  \u001b[32m+ perl-uri                 \u001b[0m        1.71  0                    bioconda          38kB\n",
      "  \u001b[32m+ perl-xml-sax-base        \u001b[0m        1.08  0                    bioconda          13kB\n",
      "  \u001b[32m+ perl-xml-namespacesupport\u001b[0m        1.11  0                    bioconda           6kB\n",
      "  \u001b[32m+ rsem                     \u001b[0m      1.2.28  0                    bioconda           6MB\n",
      "  \u001b[32m+ star                     \u001b[0m     2.7.11b  h43eeafb_2           bioconda           8MB\n",
      "  \u001b[32m+ samtools                 \u001b[0m        1.21  h50ea8bc_0           bioconda         473kB\n",
      "  \u001b[32m+ perl-xml-sax             \u001b[0m        0.99  0                    bioconda          25kB\n",
      "  \u001b[32m+ perl-xml-libxml          \u001b[0m      2.0124  0                    bioconda         220kB\n",
      "  \u001b[32m+ sra-tools                \u001b[0m       3.1.1  h4304569_2           bioconda          61MB\n",
      "  \u001b[32m+ multiqc                  \u001b[0m      1.25.1  pyhdfd78af_0         bioconda           4MB\n",
      "  \u001b[32m+ parallel-fastq-dump      \u001b[0m       0.6.7  pyhdfd78af_0         bioconda          10kB\n",
      "\n",
      "  Change:\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[31m- libgomp                  \u001b[0m      14.1.0  h77fa898_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libgomp                  \u001b[0m      14.1.0  h77fa898_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- libgcc-ng                \u001b[0m      14.1.0  h77fa898_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libgcc-ng                \u001b[0m      14.1.0  h69a702a_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- libstdcxx-ng             \u001b[0m      14.1.0  hc0a3c3a_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libstdcxx-ng             \u001b[0m      14.1.0  h4852527_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- libxml2                  \u001b[0m      2.12.7  h4c95cb1_3           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libxml2                  \u001b[0m      2.12.7  hc051c1a_1           conda-forge      705kB\n",
      "  \u001b[31m- aws-checksums            \u001b[0m      0.1.18  he027950_7           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-checksums            \u001b[0m      0.1.18  h83b837d_6           conda-forge       50kB\n",
      "  \u001b[31m- aws-c-compression        \u001b[0m      0.2.18  he027950_7           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-compression        \u001b[0m      0.2.18  h83b837d_6           conda-forge       19kB\n",
      "  \u001b[31m- aws-c-sdkutils           \u001b[0m      0.1.16  he027950_3           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-sdkutils           \u001b[0m      0.1.16  h83b837d_2           conda-forge       55kB\n",
      "  \u001b[31m- xorg-libx11              \u001b[0m       1.8.9  hb711507_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ xorg-libx11              \u001b[0m       1.8.9  h8ee46fc_0           conda-forge      828kB\n",
      "  \u001b[31m- mysql-common             \u001b[0m       8.3.0  h70512c7_5           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ mysql-common             \u001b[0m       8.3.0  hf1915f5_4           conda-forge      785kB\n",
      "  \u001b[31m- libxkbcommon             \u001b[0m       1.7.0  h2c5496b_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libxkbcommon             \u001b[0m       1.7.0  h662e7e4_0           conda-forge      594kB\n",
      "  \u001b[31m- xcb-util-image           \u001b[0m       0.4.0  hb711507_2           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ xcb-util-image           \u001b[0m       0.4.0  h8ee46fc_1           conda-forge       24kB\n",
      "  \u001b[31m- mysql-libs               \u001b[0m       8.3.0  ha479ceb_5           conda-forge        2MB\n",
      "  \u001b[32m+ mysql-libs               \u001b[0m       8.3.0  hca2cd23_4           conda-forge        2MB\n",
      "  \u001b[31m- imagecodecs              \u001b[0m    2024.6.1  py310h51fded0_2      conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ imagecodecs              \u001b[0m    2024.6.1  py310h6158a3f_0      conda-forge        2MB\n",
      "  \u001b[31m- pytables                 \u001b[0m       3.9.2  py310h73b55d5_3      conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ pytables                 \u001b[0m       3.9.2  py310hd76cd5d_2      conda-forge        1MB\n",
      "  \u001b[31m- cairo                    \u001b[0m      1.18.0  hbb29018_2           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ cairo                    \u001b[0m      1.18.0  h3faef2a_0           conda-forge      982kB\n",
      "  \u001b[31m- aws-c-event-stream       \u001b[0m       0.4.2  h7671281_15          conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-event-stream       \u001b[0m       0.4.2  ha47c788_12          conda-forge       54kB\n",
      "  \u001b[31m- aws-c-mqtt               \u001b[0m      0.10.4  hcd6a914_8           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-mqtt               \u001b[0m      0.10.4  h759edc4_4           conda-forge      164kB\n",
      "  \u001b[31m- aws-c-auth               \u001b[0m      0.7.22  hbd3ac97_10          conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-auth               \u001b[0m      0.7.22  h96bc93b_2           conda-forge      106kB\n",
      "  \u001b[31m- pango                    \u001b[0m      1.54.0  h4c5309f_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ pango                    \u001b[0m      1.54.0  h84a9a3c_0           conda-forge      448kB\n",
      "  \u001b[31m- qt-main                  \u001b[0m      5.15.8  h320f8da_24          conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ qt-main                  \u001b[0m      5.15.8  hc9dc06e_21          conda-forge       61MB\n",
      "  \u001b[31m- aws-sdk-cpp              \u001b[0m    1.11.329  h46c3b66_9           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-sdk-cpp              \u001b[0m    1.11.329  hba8bd5f_3           conda-forge        4MB\n",
      "  \u001b[31m- qt-webengine             \u001b[0m      5.15.8  h8f589be_8           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ qt-webengine             \u001b[0m      5.15.8  h3e791b3_6           conda-forge       59MB\n",
      "\n",
      "  Upgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[31m- certifi                  \u001b[0m    2024.7.4  pyhd8ed1ab_0         conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ certifi                  \u001b[0m   2024.8.30  pyhd8ed1ab_0         conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- ca-certificates          \u001b[0m    2024.7.4  hbcca054_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ ca-certificates          \u001b[0m   2024.8.30  hbcca054_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- llvm-openmp              \u001b[0m      18.1.8  hf5423f3_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ llvm-openmp              \u001b[0m      19.1.0  h024ca30_1           conda-forge        3MB\n",
      "  \u001b[31m- openssl                  \u001b[0m       3.3.1  h4bc722e_2           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ openssl                  \u001b[0m       3.3.2  hb9d3cd8_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "\n",
      "  Downgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[31m- libzlib                  \u001b[0m       1.3.1  h4ab18f5_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libzlib                  \u001b[0m      1.2.13  h4ab18f5_6           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- aws-c-common             \u001b[0m      0.9.23  h4ab18f5_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-common             \u001b[0m      0.9.19  h4ab18f5_0           conda-forge      226kB\n",
      "  \u001b[31m- libxcb                   \u001b[0m        1.16  hd590300_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libxcb                   \u001b[0m        1.15  h0b41bf4_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- zlib-ng                  \u001b[0m       2.2.1  he02047a_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ zlib-ng                  \u001b[0m       2.0.7  h0b41bf4_0           conda-forge       95kB\n",
      "  \u001b[31m- nss                      \u001b[0m       3.102  h593d115_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ nss                      \u001b[0m       3.100  hca3bf56_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- llvmlite                 \u001b[0m      0.43.0  py310h4c7c693_0      conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ llvmlite                 \u001b[0m      0.42.0  py310h1b8f574_1      conda-forge        3MB\n",
      "  \u001b[31m- zlib                     \u001b[0m       1.3.1  h4ab18f5_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ zlib                     \u001b[0m      1.2.13  h4ab18f5_6           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- pcre2                    \u001b[0m       10.44  h0f59acf_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ pcre2                    \u001b[0m       10.43  hcad00b1_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- blosc                    \u001b[0m      1.21.6  hef167b5_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ blosc                    \u001b[0m      1.21.5  hc2324a3_1           conda-forge       49kB\n",
      "  \u001b[31m- xcb-util-wm              \u001b[0m       0.4.2  hb711507_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ xcb-util-wm              \u001b[0m       0.4.1  h8ee46fc_1           conda-forge       52kB\n",
      "  \u001b[31m- xcb-util-keysyms         \u001b[0m       0.4.1  hb711507_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ xcb-util-keysyms         \u001b[0m       0.4.0  h8ee46fc_1           conda-forge       14kB\n",
      "  \u001b[31m- xcb-util                 \u001b[0m       0.4.1  hb711507_2           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ xcb-util                 \u001b[0m       0.4.0  hd590300_1           conda-forge       20kB\n",
      "  \u001b[31m- pillow                   \u001b[0m      10.4.0  py310hebfe307_0      conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ pillow                   \u001b[0m      10.3.0  py310hf73ecf8_0      conda-forge       42MB\n",
      "  \u001b[31m- xcb-util-renderutil      \u001b[0m      0.3.10  hb711507_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ xcb-util-renderutil      \u001b[0m       0.3.9  hd590300_1           conda-forge       17kB\n",
      "  \u001b[31m- libcurl                  \u001b[0m       8.9.0  hdb1bdb2_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libcurl                  \u001b[0m       8.8.0  hca28451_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- s2n                      \u001b[0m      1.4.17  he19d79f_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ s2n                      \u001b[0m      1.4.15  he19d79f_0           conda-forge      350kB\n",
      "  \u001b[31m- aws-c-cal                \u001b[0m       0.7.1  h87b94db_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-cal                \u001b[0m      0.6.14  h88a6e22_1           conda-forge       47kB\n",
      "  \u001b[31m- c-blosc2                 \u001b[0m      2.15.0  h6d6b9e4_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ c-blosc2                 \u001b[0m      2.14.4  hb4ffafa_1           conda-forge      337kB\n",
      "  \u001b[31m- numba                    \u001b[0m      0.60.0  py310h5dc88bb_0      conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ numba                    \u001b[0m      0.59.1  py310h7dc5dd1_0      conda-forge        4MB\n",
      "  \u001b[31m- libllvm18                \u001b[0m      18.1.8  h8b73ec9_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libllvm18                \u001b[0m      18.1.7  hb77312f_0           conda-forge       38MB\n",
      "  \u001b[31m- libglib                  \u001b[0m      2.80.3  h8a4344b_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libglib                  \u001b[0m      2.80.2  hf974151_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[31m- libgoogle-cloud          \u001b[0m      2.26.0  h26d7fe4_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libgoogle-cloud          \u001b[0m      2.24.0  h2736e30_0           conda-forge        1MB\n",
      "  \u001b[31m- curl                     \u001b[0m       8.9.0  h18eb788_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ curl                     \u001b[0m       8.8.0  he654da7_1           conda-forge      166kB\n",
      "  \u001b[31m- cmake                    \u001b[0m      3.30.1  hf8c4bd3_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ cmake                    \u001b[0m      3.29.4  h91dbaaa_0           conda-forge       19MB\n",
      "  \u001b[31m- aws-c-io                 \u001b[0m     0.14.10  h826b7d6_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-io                 \u001b[0m      0.14.8  h21d4f22_5           conda-forge      158kB\n",
      "  \u001b[31m- libclang13               \u001b[0m      18.1.8  default_h9def88c_1   conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libclang13               \u001b[0m      18.1.7  default_h087397f_0   conda-forge       11MB\n",
      "  \u001b[31m- glib-tools               \u001b[0m      2.80.3  h73ef956_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ glib-tools               \u001b[0m      2.80.2  hb6ce0ca_0           conda-forge      114kB\n",
      "  \u001b[31m- libgoogle-cloud-storage  \u001b[0m      2.26.0  ha262f82_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libgoogle-cloud-storage  \u001b[0m      2.24.0  h3d9a0c8_0           conda-forge      752kB\n",
      "  \u001b[31m- aws-c-http               \u001b[0m       0.8.2  he17ee6b_6           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-http               \u001b[0m       0.8.1  h29d6fba_17          conda-forge      195kB\n",
      "  \u001b[31m- glib                     \u001b[0m      2.80.3  h8a4344b_1           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ glib                     \u001b[0m      2.80.2  hf974151_0           conda-forge      600kB\n",
      "  \u001b[31m- harfbuzz                 \u001b[0m       9.0.0  hfac3d4d_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ harfbuzz                 \u001b[0m       8.5.0  hfac3d4d_0           conda-forge        2MB\n",
      "  \u001b[31m- gstreamer                \u001b[0m      1.24.6  haf2f30d_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ gstreamer                \u001b[0m      1.24.4  haf2f30d_0           conda-forge        2MB\n",
      "  \u001b[31m- aws-c-s3                 \u001b[0m       0.6.0  h365ddd8_2           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-c-s3                 \u001b[0m       0.5.9  h594631b_3           conda-forge      110kB\n",
      "  \u001b[31m- gst-plugins-base         \u001b[0m      1.24.6  hbaaba92_0           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ gst-plugins-base         \u001b[0m      1.24.4  h9ad1361_0           conda-forge        3MB\n",
      "  \u001b[31m- aws-crt-cpp              \u001b[0m      0.27.3  hda66527_2           conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ aws-crt-cpp              \u001b[0m      0.26.9  he3a8b3b_0           conda-forge      340kB\n",
      "  \u001b[31m- libarrow                 \u001b[0m      17.0.0  h4b47046_3_cpu       conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libarrow                 \u001b[0m      16.1.0  hcb6531f_6_cpu       conda-forge        8MB\n",
      "  \u001b[31m- pyarrow-core             \u001b[0m      17.0.0  py310hda9dd24_0_cpu  conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ pyarrow-core             \u001b[0m      16.1.0  py310h6f79a3a_1_cpu  conda-forge        4MB\n",
      "  \u001b[31m- libarrow-acero           \u001b[0m      17.0.0  he02047a_3_cpu       conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libarrow-acero           \u001b[0m      16.1.0  hac33072_6_cpu       conda-forge      599kB\n",
      "  \u001b[31m- libparquet               \u001b[0m      17.0.0  h9e5060d_3_cpu       conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libparquet               \u001b[0m      16.1.0  h6a7eafb_6_cpu       conda-forge        1MB\n",
      "  \u001b[31m- libarrow-dataset         \u001b[0m      17.0.0  he02047a_3_cpu       conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libarrow-dataset         \u001b[0m      16.1.0  hac33072_6_cpu       conda-forge      580kB\n",
      "  \u001b[31m- libarrow-substrait       \u001b[0m      17.0.0  hc9a23c6_3_cpu       conda-forge\u001b[32m     Cached\u001b[0m\n",
      "  \u001b[32m+ libarrow-substrait       \u001b[0m      16.1.0  h7e0c224_6_cpu       conda-forge      549kB\n",
      "  \u001b[31m- pyarrow                  \u001b[0m      17.0.0  py310hb7f781d_0      conda-forge       26kB\n",
      "  \u001b[32m+ pyarrow                  \u001b[0m      16.1.0  py310h17c5347_1      conda-forge       27kB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 86 packages\n",
      "  Change: 22 packages\n",
      "  Upgrade: 4 packages\n",
      "  Downgrade: 42 packages\n",
      "\n",
      "  Total download: 768MB\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "Downloading      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B                            0.0s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcolormath                                           35.3kB @ 742.8kB/s  0.0s\n",
      "pyaml-env                                           14.4kB @ 230.4kB/s  0.1s\n",
      "rich-click                                          33.8kB @ 540.1kB/s  0.1s\n",
      "humanize                                            66.2kB @ 762.9kB/s  0.1s\n",
      "[+] 0.1s\n",
      "Downloading  (6) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 297.2kB blosc                      0.0s\n",
      "Extracting   (5) \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m       0 colormath                  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpyathena                                            55.1kB @ 555.2kB/s  0.0s\n",
      "zlib-ng                                             94.6kB @ 705.9kB/s  0.0s\n",
      "blosc                                               48.7kB @ 331.7kB/s  0.0s\n",
      "aws-c-compression                                   19.3kB @ 112.1kB/s  0.0s\n",
      "xcb-util-keysyms                                    14.2kB @  77.1kB/s  0.0s\n",
      "[+] 0.2s\n",
      "Downloading  (5) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m  13.4MB botocore                   0.1s\n",
      "Extracting  (10) \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m       0 colormath                  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gllvm-openmp                                          3.2MB @  15.8MB/s  0.1s\n",
      "botocore                                             7.2MB @  35.3MB/s  0.2s\n",
      "xcb-util-renderutil                                 17.0kB @  76.1kB/s  0.0s\n",
      "pandas                                              13.0MB @  52.6MB/s  0.2s\n",
      "xorg-libx11                                        828.1kB @   3.3MB/s  0.1s\n",
      "xorg-libxt                                         379.3kB @   1.4MB/s  0.0s\n",
      "curl                                               166.5kB @ 585.2kB/s  0.0s\n",
      "[+] 0.3s\n",
      "Downloading  (5) \u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m  32.2MB aws-c-event-stream         0.2s\n",
      "Extracting   (5) ━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m      12 botocore                   0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gglib-tools                                         114.4kB @ 367.9kB/s  0.0s\n",
      "aws-c-event-stream                                  54.0kB @ 167.1kB/s  0.0s\n",
      "harfbuzz                                             1.6MB @   4.5MB/s  0.0s\n",
      "aws-c-mqtt                                         164.2kB @ 463.2kB/s  0.0s\n",
      "aws-c-s3                                           109.7kB @ 283.6kB/s  0.0s\n",
      "[+] 0.4s\n",
      "Downloading  (5) ╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m  54.0MB cmake                      0.3s\n",
      "Extracting   (5) ━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m      17 botocore                   0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggst-plugins-base                                     2.8MB @   6.6MB/s  0.1s\n",
      "cmake                                               19.0MB @  41.2MB/s  0.2s\n",
      "libarrow-acero                                     599.3kB @   1.3MB/s  0.0s\n",
      "pyarrow                                             26.7kB @  54.1kB/s  0.0s\n",
      "[+] 0.5s\n",
      "Downloading  (5) ━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m 105.3MB kaleido-core               0.4s\n",
      "Extracting   (5) ━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m      21 cmake                      0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibarrow-substrait                                 549.5kB @   1.1MB/s  0.0s\n",
      "sql-magic                                           15.1kB @  28.3kB/s  0.0s\n",
      "htslib                                               3.2MB @   5.5MB/s  0.0s\n",
      "libllvm18                                           38.4MB @  66.1MB/s  0.4s\n",
      "[+] 0.6s\n",
      "Downloading  (5) ━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m 144.9MB kaleido-core               0.5s\n",
      "Extracting   (4) ━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m      26 cmake                      0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gperl-xml-sax-base                                   12.9kB @  21.2kB/s  0.0s\n",
      "perl-xml-libxml                                    219.6kB @ 345.3kB/s  0.0s\n",
      "ncbi-vdb                                            11.2MB @  17.0MB/s  0.1s\n",
      "star                                                 8.5MB @  12.6MB/s  0.1s\n",
      "parallel-fastq-dump                                  9.9kB @  14.6kB/s  0.0s\n",
      "[+] 0.7s\n",
      "Downloading  (5) ━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m 191.4MB kaleido-core               0.6s\n",
      "Extracting   (5) ━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m      30 cmake                      0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ghumanfriendly                                       73.4kB @ 100.8kB/s  0.1s\n",
      "boto3                                               82.7kB @ 113.6kB/s  0.1s\n",
      "aws-c-common                                       226.5kB @ 300.0kB/s  0.0s\n",
      "ossuuid                                             56.9kB @  74.0kB/s  0.0s\n",
      "aws-c-sdkutils                                      55.0kB @  69.9kB/s  0.0s\n",
      "[+] 0.8s\n",
      "Downloading  (5) ━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m 199.0MB kaleido-core               0.7s\n",
      "Extracting   (8) ━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m      32 cmake                      0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gaws-c-cal                                           46.7kB @  57.4kB/s  0.0s\n",
      "kaleido-core                                        62.1MB @  73.1MB/s  0.6s\n",
      "wget                                               770.4kB @ 897.1kB/s  0.0s\n",
      "mysql-libs                                           1.5MB @   1.7MB/s  0.0s\n",
      "[+] 0.9s\n",
      "Downloading  (5) ━━━━━━╸\u001b[33m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m 248.9MB cairo                      0.8s\n",
      "Extracting   (8) ━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m      36 htslib                     0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gimagecodecs                                          2.1MB @   2.3MB/s  0.1s\n",
      "cairo                                              982.4kB @   1.0MB/s  0.1s\n",
      "mathjax                                             22.3MB @  23.2MB/s  0.3s\n",
      "glib                                               600.4kB @ 624.8kB/s  0.0s\n",
      "aws-crt-cpp                                        339.6kB @ 342.2kB/s  0.0s\n",
      "[+] 1.0s\n",
      "Downloading  (5) ━━━━━━━╸\u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 280.0MB libarrow-dataset           0.9s\n",
      "Extracting  (10) ━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m      39 htslib                     0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibarrow-dataset                                   580.0kB @ 565.0kB/s  0.0s\n",
      "trimmomatic                                        147.4kB @ 137.8kB/s  0.0s\n",
      "qt-webengine                                        58.5MB @  53.5MB/s  0.7s\n",
      "[+] 1.1s\n",
      "Downloading  (5) ━━━━━━━╸\u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m 295.8MB entrez-direct              1.0s\n",
      "Extracting   (7) ━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m      45 kaleido-core               1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gr                                                   18.0kB @  16.2kB/s  0.0s\n",
      "rsem                                                 6.4MB @   5.4MB/s  0.1s\n",
      "pillow                                              41.8MB @  35.1MB/s  0.4s\n",
      "[+] 1.2s\n",
      "Downloading  (5) ━━━━━━━━━╸\u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m 363.0MB entrez-direct              1.1s\n",
      "Extracting   (8) ━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m      47 kaleido-core               1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gentrez-direct                                       14.7MB @  11.8MB/s  0.1s\n",
      "multiqc                                              3.8MB @   3.0MB/s  0.1s\n",
      "[+] 1.3s\n",
      "Downloading  (5) ━━━━━━━━━━╸\u001b[33m━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m 395.3MB coloredlogs                1.2s\n",
      "Extracting   (9) ━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m      48 kaleido-core               1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcoloredlogs                                         40.6kB @  31.0kB/s  0.1s\n",
      "pydantic-core                                        1.6MB @   1.2MB/s  0.1s\n",
      "pigz                                                72.5kB @  53.1kB/s  0.1s\n",
      "xcb-util                                            19.7kB @  14.3kB/s  0.0s\n",
      "[+] 1.4s\n",
      "Downloading  (5) ━━━━━━━━━━━╸\u001b[33m━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m 412.7MB numba                      1.3s\n",
      "Extracting  (13) ━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m      49 kaleido-core               1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gc-blosc2                                           337.1kB @ 240.9kB/s  0.0s\n",
      "pytables                                             1.4MB @ 939.4kB/s  0.0s\n",
      "numba                                                4.3MB @   2.9MB/s  0.1s\n",
      "aws-c-http                                         194.8kB @ 132.3kB/s  0.0s\n",
      "[+] 1.5s\n",
      "Downloading  (5) ━━━━━━━━━━━╸\u001b[33m━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m 434.3MB libarrow                   1.4s\n",
      "Extracting  (12) ━━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m      53 mathjax                    1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpango                                              448.5kB @ 297.5kB/s  0.0s\n",
      "perl-threaded                                        5.5kB @   3.6kB/s  0.0s\n",
      "libarrow                                             8.3MB @   5.2MB/s  0.1s\n",
      "python-kaleido                                      18.3kB @  11.5kB/s  0.0s\n",
      "[+] 1.6s\n",
      "Downloading  (5) ━━━━━━━━━━━━╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m 465.2MB openjdk                    1.5s\n",
      "Extracting  (12) ━━━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m      57 mathjax                    1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gperl-uri                                            37.7kB @  23.2kB/s  0.0s\n",
      "perl-xml-sax                                        24.7kB @  14.9kB/s  0.1s\n",
      "spectra                                             19.4kB @  11.6kB/s  0.0s\n",
      "[+] 1.7s\n",
      "Downloading  (5) ━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m 483.2MB openjdk                    1.6s\n",
      "Extracting  (13) ━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m      59 mathjax                    1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtypeguard                                           34.5kB @  20.3kB/s  0.0s\n",
      "libxml2                                            705.0kB @ 409.7kB/s  0.0s\n",
      "s2n                                                349.5kB @ 200.7kB/s  0.0s\n",
      "libgoogle-cloud-storage                            752.4kB @ 423.3kB/s  0.0s\n",
      "[+] 1.8s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m 508.9MB openjdk                    1.7s\n",
      "Extracting  (12) ━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m      64 mathjax                    1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgoogle-cloud                                      1.2MB @ 676.4kB/s  0.1s\n",
      "qt-main                                             61.3MB @  32.9MB/s  0.9s\n",
      "libparquet                                           1.2MB @ 633.2kB/s  0.1s\n",
      "[+] 1.9s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━\u001b[0m 551.4MB openjdk                    1.8s\n",
      "Extracting  (10) ━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m      69 multiqc                    1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gsamtools                                           473.4kB @ 248.6kB/s  0.0s\n",
      "[+] 2.0s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━\u001b[0m 593.4MB perl                       1.9s\n",
      "Extracting   (9) ━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m      71 multiqc                    1.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gsra-tools                                           60.7MB @  30.3MB/s  0.8s\n",
      "aws-checksums                                       50.1kB @  24.5kB/s  0.0s\n",
      "r-base                                              27.1MB @  13.1MB/s  0.3s\n",
      "libxkbcommon                                       593.5kB @ 283.8kB/s  0.0s\n",
      "[+] 2.1s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━\u001b[0m 637.4MB perl                       2.0s\n",
      "Extracting   (9) ━━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━\u001b[0m      76 entrez-direct              2.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gperl                                                15.7MB @   7.4MB/s  0.2s\n",
      "subread                                             27.4MB @  12.9MB/s  0.3s\n",
      "aws-sdk-cpp                                          3.6MB @   1.7MB/s  0.1s\n",
      "[+] 2.2s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m 673.2MB gffread                    2.1s\n",
      "Extracting  (10) ━━━━━━━━━━━━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━\u001b[0m      77 entrez-direct              2.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggffread                                            133.6kB @  60.7kB/s  0.1s\n",
      "pydantic                                           300.6kB @ 135.8kB/s  0.1s\n",
      "libclang13                                          11.1MB @   4.9MB/s  0.2s\n",
      "xcb-util-image                                      24.5kB @  10.9kB/s  0.0s\n",
      "aws-c-io                                           158.0kB @  70.1kB/s  0.0s\n",
      "llvmlite                                             3.3MB @   1.5MB/s  0.1s\n",
      "perl-xml-namespacesupport                            6.4kB @   2.8kB/s  0.0s\n",
      "[+] 2.3s\n",
      "Downloading  (6) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m 679.6MB aws-c-auth                 2.2s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━\u001b[0m      80 entrez-direct              2.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfindspark                                            8.4kB @   3.7kB/s  0.1s\n",
      "aws-c-auth                                         105.9kB @  46.0kB/s  0.1s\n",
      "[+] 2.4s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m 679.7MB binutils_impl_linux-64     2.3s\n",
      "Extracting  (16) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━\u001b[0m      80 entrez-direct              2.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m 679.7MB binutils_impl_linux-64     2.4s\n",
      "Extracting  (16) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━\u001b[0m      80 findspark                  2.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m 679.7MB binutils_impl_linux-64     2.5s\n",
      "Extracting  (16) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━\u001b[0m      80 findspark                  2.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m 679.7MB binutils_impl_linux-64     2.6s\n",
      "Extracting  (16) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━\u001b[0m      80 findspark                  2.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m 679.7MB fastqc                     2.7s\n",
      "Extracting  (16) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━\u001b[0m      80 findspark                  2.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gsqlparse                                            40.4kB @  14.0kB/s  0.6s\n",
      "[+] 2.9s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━\u001b[0m 681.4MB fastqc                     2.8s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━\u001b[0m      84 kaleido-core               2.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggstreamer                                            2.0MB @ 689.2kB/s  0.0s\n",
      "pyarrow-core                                         4.4MB @   1.5MB/s  0.6s\n",
      "xcb-util-wm                                         52.1kB @  17.5kB/s  0.0s\n",
      "mysql-common                                       784.8kB @ 261.8kB/s  0.1s\n",
      "[+] 3.0s\n",
      "Downloading  (3) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 707.6MB fastqc                     2.9s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      87 kaleido-core               2.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gbinutils_impl_linux-64                               6.3MB @   2.1MB/s  0.7s\n",
      "fastqc                                              11.7MB @   3.8MB/s  0.8s\n",
      "[+] 3.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.0s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 kaleido-core               3.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.1s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 kaleido-core               3.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.2s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 libclang13                 3.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.3s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 libclang13                 3.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.4s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 libclang13                 3.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.5s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 libclang13                 3.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.6s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 mathjax                    3.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.7s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 mathjax                    3.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.8s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 mathjax                    3.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    3.9s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 mathjax                    3.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    4.0s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 mysql-common               4.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 721.0MB openjdk                    4.1s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      89 mysql-common               4.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m 732.6MB openjdk                    4.2s\n",
      "Extracting   (9) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m      94 binutils_impl_linux-64     4.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    4.3s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 entrez-direct              4.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    4.4s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 entrez-direct              4.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    4.5s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 entrez-direct              4.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    4.6s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 entrez-direct              4.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    4.7s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 fastqc                     4.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    4.8s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 fastqc                     4.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    4.9s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 fastqc                     4.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    5.0s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 fastqc                     5.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    5.1s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 kaleido-core               5.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    5.2s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 kaleido-core               5.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    5.3s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 kaleido-core               5.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    5.4s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 kaleido-core               5.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 747.5MB openjdk                    5.5s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 mathjax                    5.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 752.0MB openjdk                    5.6s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 mathjax                    5.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m 764.9MB openjdk                    5.7s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 mathjax                    5.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gopenjdk                                            180.9MB @  31.1MB/s  4.9s\n",
      "[+] 5.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (9) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      95 mathjax                    5.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      96 openjdk                    5.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      96 openjdk                    6.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      96 openjdk                    6.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      96 openjdk                    6.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      96 perl                       6.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (7) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      97 perl                       6.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (7) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      97 perl                       6.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (6) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      98 perl                       6.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (6) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      98 sra-tools                  6.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (6) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      98 sra-tools                  6.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (6) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      98 sra-tools                  6.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (6) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      98 sra-tools                  7.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (6) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      98 subread                    7.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (5) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      99 subread                    7.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (5) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      99 subread                    7.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (5) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      99 subread                    7.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (5) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      99 kaleido-core               7.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (5) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      99 kaleido-core               7.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     100 kaleido-core               7.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     100 kaleido-core               7.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     100 mathjax                    7.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     100 mathjax                    8.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     100 mathjax                    8.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 mathjax                    8.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 sra-tools                  8.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 sra-tools                  8.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 sra-tools                  8.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 sra-tools                  8.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 kaleido-core               8.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 kaleido-core               8.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 kaleido-core               8.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 kaleido-core               9.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 mathjax                    9.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 mathjax                    9.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 mathjax                    9.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 mathjax                    9.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 sra-tools                  9.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 sra-tools                  9.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 sra-tools                  9.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 sra-tools                  9.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     101 kaleido-core               9.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              10.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              10.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              10.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 10.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 10.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 10.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 10.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              10.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              10.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              10.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              11.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 11.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 11.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 11.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 11.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              11.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              11.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              11.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 kaleido-core              11.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 11.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 12.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     102 sra-tools                 12.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     103 kaleido-core              12.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━ 768.1MB                            5.8s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m     103 kaleido-core              12.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "# Update PATH to point to the Miniforge (or Mambaforge) bin files\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + os.environ[\"HOME\"]+\"/miniforge/bin\"\n",
    "\n",
    "#now we can easily use 'mamba' command to install software \n",
    "!mamba install -y -c conda-forge -c bioconda trimmomatic fastqc multiqc sql-magic entrez-direct gffread parallel-fastq-dump sra-tools sql-magic pyathena samtools star rsem entrez-direct subread pigz -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 2: Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of directories in the sra-data-athena to store the reads, reference sequence files, and output files. Notice that first we remove the `data` directory to clean up files from Tutorial_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "!cd $HOMEDIR\n",
    "!echo $PWD\n",
    "!mkdir -p data\n",
    "!mkdir -p data/trunc_rawfastq\n",
    "!mkdir -p data/trimmed\n",
    "!mkdir -p data/fastqc\n",
    "!mkdir -p data/fastqc_samples/\n",
    "!mkdir -p data/reference\n",
    "!mkdir -p data/aligned_bam\n",
    "!mkdir -p data/rsem_reference/mouse_rsem_reference\n",
    "!mkdir -p data/rsem_output\n",
    "!mkdir -p data/reference/STAR_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set # THREADS depending on your VM size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of threads: 15\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "THREADS = max(1, num_cores - 1)\n",
    "\n",
    "print(\"Number of threads:\", THREADS)\n",
    "os.environ[\"THREADS\"] = str(THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 3: Downloading relevant FASTQ files using SRA Tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will need to download the relevant fastq files.\n",
    "\n",
    "Because these files can be large, the process of downloading and extracting fastq files can be quite lengthy.\n",
    "\n",
    "We will be downloading the sample runs from this project using SRA tools, downloading from the NCBI's SRA (Sequence Run Archives).\n",
    "\n",
    "However, first we need to find the associated accession numbers in order to download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.1: Finding run accession numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SRA stores sequence data in terms of runs, (SRR stands for Sequence Read Run). To download runs, we will need the accession ID for each run we wish to download.\n",
    "\n",
    "The Mittenbühler MJ et al., project contains 8 runs. To make it easier, these are the run IDs associated with this project:\n",
    "\n",
    "- SRR21972730\n",
    "- SRR21972729\n",
    "- SRR21972728\n",
    "- SRR21972727\n",
    "- SRR21972725\n",
    "- SRR21972724\n",
    "- SRR21972723\n",
    "- SRR21972726\n",
    "\n",
    "In this case, all these runs belong to the Bioproject PRJNA892075.\n",
    "\n",
    "Sequence run experiments can be searched for using the SRA database on the NCBI website; and article-specific sample run information can be found in the supplementary section of that article.\n",
    "\n",
    "For instance, here, the the authors posted a link to the sequence data GSE (Gene Series number), GSE164210. This leads to the appropriate 'Gene Expression Omnibus' page where, among other useful files and information, the relevant SRA database link can be found.\n",
    "\n",
    "Once the accession numbers are located, one can make a text file containing the list of accession IDs however they like.\n",
    "\n",
    "Once again, to make things easier, we have made a .txt with these IDs that you can simply download here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR11550221\n",
      "SRR11550223\n",
      "SRR11550225\n",
      "SRR11550227\n",
      "SRR11550229\n",
      "SRR11550231\n"
     ]
    }
   ],
   "source": [
    "!esearch -db sra -query \"PRJNA625528\" | efetch -format runinfo | cut -d',' -f1 | tail -n +2 > all_accs.txt\n",
    "!grep -E \"SRR11550221|SRR11550223|SRR11550225|SRR11550227|SRR11550229|SRR11550231\" all_accs.txt > accs.txt\n",
    "!cat accs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### STEP 3.2 Finding run accession numbers using Athena (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Athena is a serverless query engine that allows you to analyze data stored in Amazon S3 using standard SQL. It offers several advantages over traditional SRA tools, making it a more efficient and scalable solution for large-scale RNA-seq data analysis.\n",
    "\n",
    "Using Athena to access metadata is optional, but allows you to query large SRA metadata directly from AWS without needing to download and process files locally, making it faster and more scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "\n",
    "# Use the correct argument name: s3_staging_dir\n",
    "conn = connect(s3_staging_dir='s3://sra-data-athena/', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the Glue client\n",
    "glue_client = boto3.client('glue', region_name='us-east-1')\n",
    "\n",
    "# Run the crawler\n",
    "crawler_name = 'sra_crawler'  # Use your crawler's name\n",
    "glue_client.start_crawler(Name=crawler_name)\n",
    "\n",
    "print(f\"Crawler {crawler_name} started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM AwsDataCatalog.srametadata.metadata\n",
    "WHERE bioproject = 'PRJNA892075'\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#write the SRR column to a text file\n",
    "with open('accs.txt', 'w') as f:\n",
    "    accs = df['acc'].to_string(header=False, index=False)\n",
    "    f.write(accs)\n",
    "    \n",
    "#print the text file\n",
    "!cat accs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.3 Using the SRA-toolkit for a single sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet demonstrates how to download and preprocess single SRA data using the prefetch and fasterq-dump commands. First, prefetch downloads the specified SRA file and then, fasterq-dump converts the SRA file into paired-end FASTQ files. Finally, the generated FASTQ files are compressed using pigz to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-09T05:56:00 prefetch.3.1.1: 1) Resolving 'SRR11550221'...\n",
      "2024-10-09T05:56:00 prefetch.3.1.1: Current preference is set to retrieve SRA Normalized Format files with full base quality scores\n",
      "2024-10-09T05:56:00 prefetch.3.1.1: 1) Downloading 'SRR11550221'...\n",
      "2024-10-09T05:56:00 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-10-09T05:56:00 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-10-09T05:56:54 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-10-09T05:56:56 prefetch.3.1.1:  'SRR11550221' is valid: 1357522631 bytes were streamed from 1357514436\n",
      "2024-10-09T05:56:56 prefetch.3.1.1: 1) 'SRR11550221' was downloaded successfully\n",
      "2024-10-09T05:56:56 prefetch.3.1.1: 'SRR11550221' has 0 dependencies\n"
     ]
    }
   ],
   "source": [
    "# Example usage for SRA download:\n",
    "!prefetch SRR11550221 -O data/raw_fastq -f yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spots read      : 46,053,552\n",
      "reads read      : 92,107,104\n",
      "reads written   : 46,053,552\n",
      "reads 0-length  : 46,053,552\n"
     ]
    }
   ],
   "source": [
    "#convert sra to fastq\n",
    "!fasterq-dump data/raw_fastq/SRR11550221 -f -O data/raw_fastq/ -e $THREADS\n",
    "#compress fastq to fastq.gz to save space\n",
    "!pigz -p $THREADS data/raw_fastq/SRR11550221.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3.4 Downloading multiple files using the SRA-toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code uses prefetch to download multiple SRA files in parallel. It reads the list of SRR IDs from accs.txt, uses xargs to execute prefetch for each ID, and specifies the output directory and the -f option to create FASTQ files in the same directory as the SRA files. To speed up the download the code uses -P $THREADS option allowing parallel execution using the specified number of threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Resolving 'SRR11550227'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Resolving 'SRR11550225'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Resolving 'SRR11550223'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Resolving 'SRR11550221'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Resolving 'SRR11550229'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Resolving 'SRR11550231'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: Current preference is set to retrieve SRA Normalized Format files with full base quality scores\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: Current preference is set to retrieve SRA Normalized Format files with full base quality scores\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: Current preference is set to retrieve SRA Normalized Format files with full base quality scores\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: Current preference is set to retrieve SRA Normalized Format files with full base quality scores\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: Current preference is set to retrieve SRA Normalized Format files with full base quality scores\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: Current preference is set to retrieve SRA Normalized Format files with full base quality scores\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Downloading 'SRR11550225'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Downloading 'SRR11550221'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Downloading 'SRR11550231'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Downloading 'SRR11550229'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Downloading 'SRR11550227'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1: 1) Downloading 'SRR11550223'...\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-10-09T06:01:15 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-10-09T06:02:03 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-10-09T06:02:05 prefetch.3.1.1:  'SRR11550225' is valid: 1088705939 bytes were streamed from 1088702437\n",
      "2024-10-09T06:02:05 prefetch.3.1.1: 1) 'SRR11550225' was downloaded successfully\n",
      "2024-10-09T06:02:05 prefetch.3.1.1: 'SRR11550225' has 0 dependencies\n",
      "2024-10-09T06:02:07 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-10-09T06:02:09 prefetch.3.1.1:  'SRR11550223' is valid: 1183975637 bytes were streamed from 1183967527\n",
      "2024-10-09T06:02:09 prefetch.3.1.1: 1) 'SRR11550223' was downloaded successfully\n",
      "2024-10-09T06:02:09 prefetch.3.1.1: 'SRR11550223' has 0 dependencies\n",
      "2024-10-09T06:02:10 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-10-09T06:02:13 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-10-09T06:02:13 prefetch.3.1.1:  'SRR11550229' is valid: 1214376042 bytes were streamed from 1214369515\n",
      "2024-10-09T06:02:13 prefetch.3.1.1: 1) 'SRR11550229' was downloaded successfully\n",
      "2024-10-09T06:02:13 prefetch.3.1.1: 'SRR11550229' has 0 dependencies\n",
      "2024-10-09T06:02:15 prefetch.3.1.1:  'SRR11550221' is valid: 1357522631 bytes were streamed from 1357514438\n",
      "2024-10-09T06:02:15 prefetch.3.1.1: 1) 'SRR11550221' was downloaded successfully\n",
      "2024-10-09T06:02:15 prefetch.3.1.1: 'SRR11550221' has 0 dependencies\n",
      "2024-10-09T06:02:21 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-10-09T06:02:23 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-10-09T06:02:24 prefetch.3.1.1:  'SRR11550231' is valid: 1548602059 bytes were streamed from 1548593527\n",
      "2024-10-09T06:02:24 prefetch.3.1.1: 1) 'SRR11550231' was downloaded successfully\n",
      "2024-10-09T06:02:24 prefetch.3.1.1: 'SRR11550231' has 0 dependencies\n",
      "2024-10-09T06:02:26 prefetch.3.1.1:  'SRR11550227' is valid: 1470638974 bytes were streamed from 1470635405\n",
      "2024-10-09T06:02:26 prefetch.3.1.1: 1) 'SRR11550227' was downloaded successfully\n",
      "2024-10-09T06:02:26 prefetch.3.1.1: 'SRR11550227' has 0 dependencies\n"
     ]
    }
   ],
   "source": [
    "!cat accs.txt | xargs -P $THREADS -I {} prefetch {} -O data/raw_fastq -f yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3.5 Converting Multiple SRA files to Fastq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the SRA files will be processed in parallel using parallel-fastq-dump. Each SRR ID from accs.txt will be read, and xargs will be used to execute parallel-fastq-dump for each SRA ID. This will result in the creation of two paired-end FASTQ files for each SRR ID, which will be compressed into a .gz file to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 41530740 spots for data/raw_fastq/SRR11550229/SRR11550229.sra\n",
      "Written 41530740 spots for data/raw_fastq/SRR11550229/SRR11550229.sra\n",
      "Read 37087937 spots for data/raw_fastq/SRR11550225/SRR11550225.sra\n",
      "Written 37087937 spots for data/raw_fastq/SRR11550225/SRR11550225.sra\n",
      "Read 40255612 spots for data/raw_fastq/SRR11550223/SRR11550223.sra\n",
      "Written 40255612 spots for data/raw_fastq/SRR11550223/SRR11550223.sra\n",
      "Read 46053552 spots for data/raw_fastq/SRR11550221/SRR11550221.sra\n",
      "Written 46053552 spots for data/raw_fastq/SRR11550221/SRR11550221.sra\n",
      "Read 49645505 spots for data/raw_fastq/SRR11550227/SRR11550227.sra\n",
      "Written 49645505 spots for data/raw_fastq/SRR11550227/SRR11550227.sra\n",
      "Read 53090577 spots for data/raw_fastq/SRR11550231/SRR11550231.sra\n",
      "Written 53090577 spots for data/raw_fastq/SRR11550231/SRR11550231.sra\n"
     ]
    }
   ],
   "source": [
    "!cat accs.txt | xargs -P $THREADS -I {} fastq-dump --outdir data/raw_fastq/ --gzip data/raw_fastq/{}/{}.sra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, it is good practice to turn .fastq files into .fastq.gz files to save space.\n",
    "\n",
    "In our case, we will actually need to concatenate the fastq files later on, and so will zip after this.\n",
    "\n",
    "The no redundant SRA files can also be deleted to save more space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘data/raw_fastq’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#find and delete all SRR subfolders in the raw_fastq directory\n",
    "!find data/raw_fastq -type d -name 'SRR*' -exec rm -rf {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3.6 Download reference transcriptome files that will be used by STAR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step downloads and prepares the reference data needed for your RNA-seq analysis. It retrieves three essential files:\n",
    "\n",
    "- Mouse genome (Mus_musculus.GRCm39.dna.primary_assembly.fa.gz): This compressed FASTA file contains the complete mouse genome sequence, that will be used as the reference for aligning your RNA-seq reads.\n",
    "- Mouse gene annotations (Mus_musculus.GRCm39.104.gtf.gz): This compressed GTF file provides information about the genes and transcripts in the mouse genome, including their locations and structures. This data will crucial for interpreting the aligned RNA-seq reads and understanding what genes are expressed in each.\n",
    "- Mouse feature table (GCF_000001635.27_GRCm39_feature_table.txt.gz): This compressed table provides additional annotations for the mouse genome features, potentially including information about gene functions and pathways. This step will further used to analyze the differential gene expression (DEG) analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-09 07:11:13--  ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_genomic.fna.gz\n",
      "           => ‘data/reference/celegans_genome.fa.gz’\n",
      "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.11, 130.14.250.12, 130.14.250.13, ...\n",
      "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.11|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235 ... done.\n",
      "==> SIZE GCF_000002985.6_WBcel235_genomic.fna.gz ... 31710738\n",
      "==> PASV ... done.    ==> RETR GCF_000002985.6_WBcel235_genomic.fna.gz ... done.\n",
      "Length: 31710738 (30M) (unauthoritative)\n",
      "\n",
      "GCF_000002985.6_WBc 100%[===================>]  30.24M  7.93MB/s    in 3.8s    \n",
      "\n",
      "2024-10-09 07:11:18 (7.93 MB/s) - ‘data/reference/celegans_genome.fa.gz’ saved [31710738]\n",
      "\n",
      "--2024-10-09 07:11:18--  https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_genomic.gtf.gz\n",
      "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.10, 130.14.250.7, 130.14.250.31, ...\n",
      "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.10|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9640927 (9.2M) [application/x-gzip]\n",
      "Saving to: ‘data/reference/celegans_annotation.gtf.gz’\n",
      "\n",
      "data/reference/cele 100%[===================>]   9.19M  25.5MB/s    in 0.4s    \n",
      "\n",
      "2024-10-09 07:11:19 (25.5 MB/s) - ‘data/reference/celegans_annotation.gtf.gz’ saved [9640927/9640927]\n",
      "\n",
      "--2024-10-09 07:11:19--  https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_feature_table.txt.gz\n",
      "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.11, 130.14.250.10, 130.14.250.7, ...\n",
      "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2793771 (2.7M) [application/x-gzip]\n",
      "Saving to: ‘data/reference/celegans_feature_table.txt.gz’\n",
      "\n",
      "data/reference/cele 100%[===================>]   2.66M  16.1MB/s    in 0.2s    \n",
      "\n",
      "2024-10-09 07:11:19 (16.1 MB/s) - ‘data/reference/celegans_feature_table.txt.gz’ saved [2793771/2793771]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_genomic.fna.gz -O data/reference/celegans_genome.fa.gz\n",
    "!wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_genomic.gtf.gz -O data/reference/celegans_annotation.gtf.gz\n",
    "!wget -O data/reference/celegans_feature_table.txt.gz https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/985/GCF_000002985.6_WBcel235/GCF_000002985.6_WBcel235_feature_table.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget https://sra-data-athena.s3.amazonaws.com/reference/celegans_genomic.fna -O data/reference/celegans_genomic.fna\n",
    "#!wget https://sra-data-athena.s3.amazonaws.com/reference/celegans_genomic.gtf -O data/reference/celegans_annnotation.gtf\n",
    "#!wget https://sra-data-athena.s3.amazonaws.com/reference/celegans_feature_table.txt -O data/reference/celegans_feature_table.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gunzip -f data/reference/celegans_genome.fa.gz\n",
    "!gunzip -f data/reference/celegans_annotation.gtf.gz\n",
    "!gunzip -f data/reference/celegans_feature_table.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.7: Copy data file for Trimmomatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of trimmomatics functions is to trim sequence machine specific adapter sequences. These are usually within the trimmomatic installation directory in a folder called adapters.\n",
    "\n",
    "Directories of packages within conda installations can be confusing, so in the case of using conda with trimmomatic, it may be easier to simply download or create a file with the relevant adapter sequencecs and store it in an easy to find directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-09 06:30:16--  https://sra-data-athena.s3.amazonaws.com/reference/TruSeq3-SE.fa\n",
      "Resolving sra-data-athena.s3.amazonaws.com (sra-data-athena.s3.amazonaws.com)... 52.216.138.115, 3.5.29.24, 52.217.140.49, ...\n",
      "Connecting to sra-data-athena.s3.amazonaws.com (sra-data-athena.s3.amazonaws.com)|52.216.138.115|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 120 [binary/octet-stream]\n",
      "Saving to: ‘data/trimmed/TruSeq3-SE.fa’\n",
      "\n",
      "data/trimmed/TruSeq 100%[===================>]     120  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-09 06:30:16 (5.20 MB/s) - ‘data/trimmed/TruSeq3-SE.fa’ saved [120/120]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://sra-data-athena.s3.amazonaws.com/reference/TruSeq3-SE.fa -O data/trimmed/TruSeq3-SE.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: Run FastQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastQC is an invaluable tool that allows you to evaluate whether there are problems with a set of reads. For example, it will provide a report of whether there is any bias in the sequence composition of the reads.\n",
    "\n",
    "The below code may take a while to run. To make it run faster we can use threads to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application/gzip\n",
      "application/gzip\n",
      "application/gzip\n",
      "application/gzip\n",
      "application/gzip\n",
      "Started analysis of SRR11550221.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of SRR11550229.fastq.gz\n",
      "Started analysis of SRR11550227.fastq.gz\n",
      "Started analysis of SRR11550223.fastq.gz\n",
      "Started analysis of SRR11550225.fastq.gz\n",
      "Started analysis of SRR11550231.fastq.gz\n",
      "Approx 5% complete for SRR11550225.fastq.gz\n",
      "Approx 5% complete for SRR11550223.fastq.gz\n",
      "Approx 5% complete for SRR11550221.fastq.gz\n",
      "Approx 5% complete for SRR11550229.fastq.gz\n",
      "Approx 5% complete for SRR11550227.fastq.gz\n",
      "Approx 5% complete for SRR11550231.fastq.gz\n",
      "Approx 10% complete for SRR11550225.fastq.gz\n",
      "Approx 10% complete for SRR11550229.fastq.gz\n",
      "Approx 10% complete for SRR11550221.fastq.gz\n",
      "Approx 10% complete for SRR11550223.fastq.gz\n",
      "Approx 10% complete for SRR11550227.fastq.gz\n",
      "Approx 10% complete for SRR11550231.fastq.gz\n",
      "Approx 15% complete for SRR11550225.fastq.gz\n",
      "Approx 15% complete for SRR11550229.fastq.gz\n",
      "Approx 15% complete for SRR11550221.fastq.gz\n",
      "Approx 15% complete for SRR11550223.fastq.gz\n",
      "Approx 15% complete for SRR11550227.fastq.gz\n",
      "Approx 20% complete for SRR11550225.fastq.gz\n",
      "Approx 20% complete for SRR11550229.fastq.gz\n",
      "Approx 15% complete for SRR11550231.fastq.gz\n",
      "Approx 20% complete for SRR11550223.fastq.gz\n",
      "Approx 20% complete for SRR11550221.fastq.gz\n",
      "Approx 25% complete for SRR11550225.fastq.gz\n",
      "Approx 20% complete for SRR11550227.fastq.gz\n",
      "Approx 25% complete for SRR11550229.fastq.gz\n",
      "Approx 25% complete for SRR11550223.fastq.gz\n",
      "Approx 25% complete for SRR11550221.fastq.gz\n",
      "Approx 20% complete for SRR11550231.fastq.gz\n",
      "Approx 30% complete for SRR11550225.fastq.gz\n",
      "Approx 25% complete for SRR11550227.fastq.gz\n",
      "Approx 30% complete for SRR11550229.fastq.gz\n",
      "Approx 30% complete for SRR11550223.fastq.gz\n",
      "Approx 30% complete for SRR11550221.fastq.gz\n",
      "Approx 35% complete for SRR11550225.fastq.gz\n",
      "Approx 25% complete for SRR11550231.fastq.gz\n",
      "Approx 30% complete for SRR11550227.fastq.gz\n",
      "Approx 35% complete for SRR11550229.fastq.gz\n",
      "Approx 35% complete for SRR11550223.fastq.gz\n",
      "Approx 35% complete for SRR11550221.fastq.gz\n",
      "Approx 40% complete for SRR11550225.fastq.gz\n",
      "Approx 40% complete for SRR11550229.fastq.gz\n",
      "Approx 35% complete for SRR11550227.fastq.gz\n",
      "Approx 40% complete for SRR11550223.fastq.gz\n",
      "Approx 30% complete for SRR11550231.fastq.gz\n",
      "Approx 40% complete for SRR11550221.fastq.gz\n",
      "Approx 45% complete for SRR11550225.fastq.gz\n",
      "Approx 45% complete for SRR11550229.fastq.gz\n",
      "Approx 45% complete for SRR11550223.fastq.gz\n",
      "Approx 40% complete for SRR11550227.fastq.gz\n",
      "Approx 50% complete for SRR11550225.fastq.gz\n",
      "Approx 45% complete for SRR11550221.fastq.gz\n",
      "Approx 35% complete for SRR11550231.fastq.gz\n",
      "Approx 50% complete for SRR11550229.fastq.gz\n",
      "Approx 50% complete for SRR11550223.fastq.gz\n",
      "Approx 55% complete for SRR11550225.fastq.gz\n",
      "Approx 45% complete for SRR11550227.fastq.gz\n",
      "Approx 50% complete for SRR11550221.fastq.gz\n",
      "Approx 40% complete for SRR11550231.fastq.gz\n",
      "Approx 55% complete for SRR11550223.fastq.gz\n",
      "Approx 55% complete for SRR11550229.fastq.gz\n",
      "Approx 60% complete for SRR11550225.fastq.gz\n",
      "Approx 50% complete for SRR11550227.fastq.gz\n",
      "Approx 55% complete for SRR11550221.fastq.gz\n",
      "Approx 65% complete for SRR11550225.fastq.gz\n",
      "Approx 60% complete for SRR11550229.fastq.gz\n",
      "Approx 60% complete for SRR11550223.fastq.gz\n",
      "Approx 45% complete for SRR11550231.fastq.gz\n",
      "Approx 60% complete for SRR11550221.fastq.gz\n",
      "Approx 70% complete for SRR11550225.fastq.gz\n",
      "Approx 55% complete for SRR11550227.fastq.gz\n",
      "Approx 65% complete for SRR11550223.fastq.gz\n",
      "Approx 65% complete for SRR11550229.fastq.gz\n",
      "Approx 75% complete for SRR11550225.fastq.gz\n",
      "Approx 65% complete for SRR11550221.fastq.gz\n",
      "Approx 50% complete for SRR11550231.fastq.gz\n",
      "Approx 70% complete for SRR11550223.fastq.gz\n",
      "Approx 70% complete for SRR11550229.fastq.gz\n",
      "Approx 60% complete for SRR11550227.fastq.gz\n",
      "Approx 80% complete for SRR11550225.fastq.gz\n",
      "Approx 70% complete for SRR11550221.fastq.gz\n",
      "Approx 75% complete for SRR11550223.fastq.gz\n",
      "Approx 75% complete for SRR11550229.fastq.gz\n",
      "Approx 65% complete for SRR11550227.fastq.gz\n",
      "Approx 55% complete for SRR11550231.fastq.gz\n",
      "Approx 85% complete for SRR11550225.fastq.gz\n",
      "Approx 75% complete for SRR11550221.fastq.gz\n",
      "Approx 80% complete for SRR11550223.fastq.gz\n",
      "Approx 80% complete for SRR11550229.fastq.gz\n",
      "Approx 70% complete for SRR11550227.fastq.gz\n",
      "Approx 90% complete for SRR11550225.fastq.gz\n",
      "Approx 60% complete for SRR11550231.fastq.gz\n",
      "Approx 85% complete for SRR11550223.fastq.gz\n",
      "Approx 80% complete for SRR11550221.fastq.gz\n",
      "Approx 85% complete for SRR11550229.fastq.gz\n",
      "Approx 95% complete for SRR11550225.fastq.gz\n",
      "Approx 75% complete for SRR11550227.fastq.gz\n",
      "Approx 90% complete for SRR11550223.fastq.gz\n",
      "Approx 85% complete for SRR11550221.fastq.gz\n",
      "Approx 65% complete for SRR11550231.fastq.gz\n",
      "Approx 90% complete for SRR11550229.fastq.gz\n",
      "Analysis complete for SRR11550225.fastq.gz\n",
      "Approx 80% complete for SRR11550227.fastq.gz\n",
      "Approx 95% complete for SRR11550223.fastq.gz\n",
      "Approx 90% complete for SRR11550221.fastq.gz\n",
      "Approx 95% complete for SRR11550229.fastq.gz\n",
      "Approx 70% complete for SRR11550231.fastq.gz\n",
      "Approx 85% complete for SRR11550227.fastq.gz\n",
      "Analysis complete for SRR11550223.fastq.gz\n",
      "Approx 95% complete for SRR11550221.fastq.gz\n",
      "Analysis complete for SRR11550229.fastq.gz\n",
      "Approx 75% complete for SRR11550231.fastq.gz\n",
      "Approx 90% complete for SRR11550227.fastq.gz\n",
      "Analysis complete for SRR11550221.fastq.gz\n",
      "Approx 95% complete for SRR11550227.fastq.gz\n",
      "Approx 80% complete for SRR11550231.fastq.gz\n",
      "Analysis complete for SRR11550227.fastq.gz\n",
      "Approx 85% complete for SRR11550231.fastq.gz\n",
      "Approx 90% complete for SRR11550231.fastq.gz\n",
      "Approx 95% complete for SRR11550231.fastq.gz\n",
      "Analysis complete for SRR11550231.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "!cat accs.txt | xargs -P $THREADS -I {} fastqc \"data/raw_fastq/{}.fastq.gz\" -o data/fastqc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastqc will output the results in HTML format, as below, for all forward and reverse reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./data/fastqc/SRR11550221_fastqc.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7f3d427c10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='./data/fastqc/SRR11550221_fastqc.html', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although its best practice to look over them individually, tools like multiqc allow one to quickly look at a summary of the quality reports of the fastq files.\n",
    "\n",
    "For instance, the below table shows which warnings, passes, or failures, from each fastqc report. There are other summaries created as well by multiqc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91m///\u001b[0m \u001b]8;id=677208;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2mv1.25.1\u001b[0m\n",
      "\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/ec2-user/SageMaker/data/fastqc\n",
      "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m12/12\u001b[0m  [2mdata/fastqc/SRR11550223_fastqc.zip\u001b[0m\n",
      "\u001b[?25h\u001b[34m            fastqc\u001b[0m | Found 6 reports\n",
      "\u001b[34m     write_results\u001b[0m | Data        : multiqc_data\n",
      "\u001b[34m     write_results\u001b[0m | Report      : multiqc_report.html\n",
      "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Filename</th>\n",
       "      <th>File type</th>\n",
       "      <th>Encoding</th>\n",
       "      <th>Total Sequences</th>\n",
       "      <th>Total Bases</th>\n",
       "      <th>Sequences flagged as poor quality</th>\n",
       "      <th>Sequence length</th>\n",
       "      <th>%GC</th>\n",
       "      <th>total_deduplicated_percentage</th>\n",
       "      <th>...</th>\n",
       "      <th>basic_statistics</th>\n",
       "      <th>per_base_sequence_quality</th>\n",
       "      <th>per_sequence_quality_scores</th>\n",
       "      <th>per_base_sequence_content</th>\n",
       "      <th>per_sequence_gc_content</th>\n",
       "      <th>per_base_n_content</th>\n",
       "      <th>sequence_length_distribution</th>\n",
       "      <th>sequence_duplication_levels</th>\n",
       "      <th>overrepresented_sequences</th>\n",
       "      <th>adapter_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR11550221</td>\n",
       "      <td>SRR11550221.fastq.gz</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>46053552.0</td>\n",
       "      <td>3.5 Gbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>19.118246</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR11550223</td>\n",
       "      <td>SRR11550223.fastq.gz</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>40255612.0</td>\n",
       "      <td>3 Gbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>19.182218</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR11550225</td>\n",
       "      <td>SRR11550225.fastq.gz</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>37087937.0</td>\n",
       "      <td>2.8 Gbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.119323</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR11550227</td>\n",
       "      <td>SRR11550227.fastq.gz</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>49645505.0</td>\n",
       "      <td>3.7 Gbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>16.958784</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR11550229</td>\n",
       "      <td>SRR11550229.fastq.gz</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>41530740.0</td>\n",
       "      <td>3.1 Gbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>17.379409</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SRR11550231</td>\n",
       "      <td>SRR11550231.fastq.gz</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>53090577.0</td>\n",
       "      <td>4 Gbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>18.771109</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sample              Filename                File type  \\\n",
       "0  SRR11550221  SRR11550221.fastq.gz  Conventional base calls   \n",
       "1  SRR11550223  SRR11550223.fastq.gz  Conventional base calls   \n",
       "2  SRR11550225  SRR11550225.fastq.gz  Conventional base calls   \n",
       "3  SRR11550227  SRR11550227.fastq.gz  Conventional base calls   \n",
       "4  SRR11550229  SRR11550229.fastq.gz  Conventional base calls   \n",
       "5  SRR11550231  SRR11550231.fastq.gz  Conventional base calls   \n",
       "\n",
       "                Encoding  Total Sequences Total Bases  \\\n",
       "0  Sanger / Illumina 1.9       46053552.0     3.5 Gbp   \n",
       "1  Sanger / Illumina 1.9       40255612.0       3 Gbp   \n",
       "2  Sanger / Illumina 1.9       37087937.0     2.8 Gbp   \n",
       "3  Sanger / Illumina 1.9       49645505.0     3.7 Gbp   \n",
       "4  Sanger / Illumina 1.9       41530740.0     3.1 Gbp   \n",
       "5  Sanger / Illumina 1.9       53090577.0       4 Gbp   \n",
       "\n",
       "   Sequences flagged as poor quality  Sequence length   %GC  \\\n",
       "0                                0.0             76.0  47.0   \n",
       "1                                0.0             76.0  47.0   \n",
       "2                                0.0             76.0  47.0   \n",
       "3                                0.0             76.0  47.0   \n",
       "4                                0.0             76.0  47.0   \n",
       "5                                0.0             76.0  46.0   \n",
       "\n",
       "   total_deduplicated_percentage  ...  basic_statistics  \\\n",
       "0                      19.118246  ...              pass   \n",
       "1                      19.182218  ...              pass   \n",
       "2                      22.119323  ...              pass   \n",
       "3                      16.958784  ...              pass   \n",
       "4                      17.379409  ...              pass   \n",
       "5                      18.771109  ...              pass   \n",
       "\n",
       "   per_base_sequence_quality per_sequence_quality_scores  \\\n",
       "0                       pass                        pass   \n",
       "1                       pass                        pass   \n",
       "2                       pass                        pass   \n",
       "3                       pass                        pass   \n",
       "4                       pass                        pass   \n",
       "5                       pass                        pass   \n",
       "\n",
       "  per_base_sequence_content per_sequence_gc_content per_base_n_content  \\\n",
       "0                      fail                    warn               pass   \n",
       "1                      fail                    warn               pass   \n",
       "2                      fail                    warn               pass   \n",
       "3                      fail                    warn               pass   \n",
       "4                      fail                    warn               pass   \n",
       "5                      fail                    warn               pass   \n",
       "\n",
       "  sequence_length_distribution sequence_duplication_levels  \\\n",
       "0                         pass                        fail   \n",
       "1                         pass                        fail   \n",
       "2                         pass                        fail   \n",
       "3                         pass                        fail   \n",
       "4                         pass                        fail   \n",
       "5                         pass                        fail   \n",
       "\n",
       "  overrepresented_sequences adapter_content  \n",
       "0                      warn            pass  \n",
       "1                      warn            pass  \n",
       "2                      warn            pass  \n",
       "3                      warn            pass  \n",
       "4                      warn            pass  \n",
       "5                      warn            pass  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!multiqc -f data/fastqc/\n",
    "\n",
    "import pandas as pd\n",
    "dframe = pd.read_csv(\"./multiqc_data/multiqc_fastqc.txt\", sep='\\t')\n",
    "display(dframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## STEP 5: Merging our fastq files (Optional if there are multiple SRR per GSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the project used presents the multiple SRAs per GSM we can use Athena to access the SRA metadata and merging the FASTQ files, the code simplifies the subsequent analysis steps and reduces the number of files to process. This can improve efficiency and reduce computational overhead.\n",
    "In this study this step was not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26883/1769049847.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\n",
      "Failed to execute query.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyathena/common.py\", line 575, in _execute\n",
      "    query_id = retry_api_call(\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyathena/util.py\", line 84, in retry_api_call\n",
      "    return retry(func, *args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tenacity/__init__.py\", line 475, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tenacity/__init__.py\", line 376, in iter\n",
      "    result = action(retry_state)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tenacity/__init__.py\", line 478, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/botocore/client.py\", line 569, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/botocore/client.py\", line 1023, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.InvalidRequestException: An error occurred (InvalidRequestException) when calling the StartQueryExecution operation: line 3:35: mismatched input '#'. Expecting: '%', '*', '+', '-', '.', '/', 'AND', 'AT', 'EXCEPT', 'FETCH', 'GROUP', 'HAVING', 'INTERSECT', 'LIMIT', 'OFFSET', 'OR', 'ORDER', 'UNION', 'WINDOW', '[', '||', <EOF>\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql: \nSELECT *\nFROM AwsDataCatalog.srametadata.metadata\nWHERE bioproject = 'PRJNAXXXXXXX' #Change to the Bioproject number\nAND organism = 'Mus musculus'\n\nAn error occurred (InvalidRequestException) when calling the StartQueryExecution operation: line 3:35: mismatched input '#'. Expecting: '%', '*', '+', '-', '.', '/', 'AND', 'AT', 'EXCEPT', 'FETCH', 'GROUP', 'HAVING', 'INTERSECT', 'LIMIT', 'OFFSET', 'OR', 'ORDER', 'UNION', 'WINDOW', '[', '||', <EOF>\nunable to rollback",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestException\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyathena/common.py:575\u001b[0m, in \u001b[0;36mBaseCursor._execute\u001b[0;34m(self, operation, parameters, work_group, s3_staging_dir, cache_size, cache_expiration_time, result_reuse_enable, result_reuse_minutes)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 575\u001b[0m     query_id \u001b[38;5;241m=\u001b[39m \u001b[43mretry_api_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_query_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_logger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryExecutionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyathena/util.py:84\u001b[0m, in \u001b[0;36mretry_api_call\u001b[0;34m(func, config, logger, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m retry \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\n\u001b[1;32m     70\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry_if_exception(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m e: \u001b[38;5;28mgetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mexceptions\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     reraise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m )\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mInvalidRequestException\u001b[0m: An error occurred (InvalidRequestException) when calling the StartQueryExecution operation: line 3:35: mismatched input '#'. Expecting: '%', '*', '+', '-', '.', '/', 'AND', 'AT', 'EXCEPT', 'FETCH', 'GROUP', 'HAVING', 'INTERSECT', 'LIMIT', 'OFFSET', 'OR', 'ORDER', 'UNION', 'WINDOW', '[', '||', <EOF>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyathena/cursor.py:88\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, operation, parameters, work_group, s3_staging_dir, cache_size, cache_expiration_time, result_reuse_enable, result_reuse_minutes, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_state()\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwork_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwork_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_staging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_staging_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_expiration_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_expiration_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_reuse_enable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_reuse_enable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_reuse_minutes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_reuse_minutes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m query_execution \u001b[38;5;241m=\u001b[39m cast(AthenaQueryExecution, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_id))\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyathena/common.py:583\u001b[0m, in \u001b[0;36mBaseCursor._execute\u001b[0;34m(self, operation, parameters, work_group, s3_staging_dir, cache_size, cache_expiration_time, result_reuse_enable, result_reuse_minutes)\u001b[0m\n\u001b[1;32m    582\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute query.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DatabaseError(\u001b[38;5;241m*\u001b[39me\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_id\n",
      "\u001b[0;31mDatabaseError\u001b[0m: An error occurred (InvalidRequestException) when calling the StartQueryExecution operation: line 3:35: mismatched input '#'. Expecting: '%', '*', '+', '-', '.', '/', 'AND', 'AT', 'EXCEPT', 'FETCH', 'GROUP', 'HAVING', 'INTERSECT', 'LIMIT', 'OFFSET', 'OR', 'ORDER', 'UNION', 'WINDOW', '[', '||', <EOF>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotSupportedError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/io/sql.py:2678\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pyathena/connection.py:372\u001b[0m, in \u001b[0;36mConnection.rollback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrollback\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotSupportedError\n",
      "\u001b[0;31mNotSupportedError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m conn \u001b[38;5;241m=\u001b[39m connect(s3_staging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3://sra-data-athena/\u001b[39m\u001b[38;5;124m'\u001b[39m, region_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus-east-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mSELECT *\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mFROM AwsDataCatalog.srametadata.metadata\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124mWHERE bioproject = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRJNAXXXXXXX\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m #Change to the Bioproject number\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mAND organism = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMus musculus\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/io/sql.py:706\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    718\u001b[0m         _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/io/sql.py:2683\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   2680\u001b[0m     ex \u001b[38;5;241m=\u001b[39m DatabaseError(\n\u001b[1;32m   2681\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124munable to rollback\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2682\u001b[0m     )\n\u001b[0;32m-> 2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql: \nSELECT *\nFROM AwsDataCatalog.srametadata.metadata\nWHERE bioproject = 'PRJNAXXXXXXX' #Change to the Bioproject number\nAND organism = 'Mus musculus'\n\nAn error occurred (InvalidRequestException) when calling the StartQueryExecution operation: line 3:35: mismatched input '#'. Expecting: '%', '*', '+', '-', '.', '/', 'AND', 'AT', 'EXCEPT', 'FETCH', 'GROUP', 'HAVING', 'INTERSECT', 'LIMIT', 'OFFSET', 'OR', 'ORDER', 'UNION', 'WINDOW', '[', '||', <EOF>\nunable to rollback"
     ]
    }
   ],
   "source": [
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "\n",
    "# Use the correct argument name: s3_staging_dir\n",
    "conn = connect(s3_staging_dir='s3://sra-data-athena/', region_name='us-east-1')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM AwsDataCatalog.srametadata.metadata\n",
    "WHERE bioproject = 'PRJNAXXXXXXX' #Change to the Bioproject number\n",
    "AND organism = 'Mus musculus'\n",
    "\"\"\"\n",
    "df = pd.read_sql(\n",
    "    query, conn\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os so we can easily pass strings to shell commands using 'subprocess'\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "#now get the accession id's and sample id's from the created dataframe\n",
    "runs = df['acc'].values\n",
    "samples = list(set(df['acc'].values))\n",
    "\n",
    "#sort them to be in numerical order\n",
    "runs.sort()\n",
    "samples.sort()\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#now iterate through the samples, \n",
    "#because there are two SRRs to a run, \n",
    "#this means corresponding SRRs indices to an index of a GSM will be\n",
    "#gsm index *2, and *2+1 \n",
    "for index, item in enumerate(samples):\n",
    "    \n",
    "    #concatenate the two SRRs\n",
    "    os.system(f\"cat data/raw_fastq/{runs[index*2]}_1.fastq data/raw_fastq/{runs[index*2+1]}_1.fastq > data/raw_fastq/{samples[index]}_1.fastq\")\n",
    "    #delete the previous fastq files to save space\n",
    "    os.system(f\"rm data/raw_fastq/{runs[index*2]}_1.fastq\")\n",
    "    os.system(f\"rm data/raw_fastq/{runs[index*2+1]}_1.fastq\")\n",
    "    #zip the merged fastq file to save more space\n",
    "    os.system(f\"gzip data/raw_fastq/{samples[index]}_1.fastq\")\n",
    "    \n",
    "    #repeat for reverse reads\n",
    "    os.system(f\"cat data/raw_fastq/{runs[index*2]}_2.fastq data/raw_fastq/{runs[index*2+1]}_2.fastq > data/raw_fastq/{samples[index]}_2.fastq\")\n",
    "    \n",
    "    os.system(f\"rm data/raw_fastq/{runs[index*2]}_2.fastq\")\n",
    "    os.system(f\"rm data/raw_fastq/{runs[index*2+1]}_2.fastq\")  \n",
    "   \n",
    "    #its good practice to zip files to save space\n",
    "    os.system(f\"gzip data/raw_fastq/{samples[index]}_2.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since our files will now be samples, not SRRs we can write a new text file to use for downstream batch processes.\n",
    "#we can use the DF we made in the previous cell.\n",
    "with open('samples.txt', 'w') as f:\n",
    "    df = df.sort_values(by='sample_name', ascending=True)\n",
    "    samples = df['acc'].unique()\n",
    "    samples = '\\n'.join(map(str, samples))\n",
    "    f.write(samples)\n",
    "    \n",
    "!cat samples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: Run Trimmomatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmomatic will trim off any adapter sequences or low quality sequence it detects in the FASTQ files.\n",
    "\n",
    "Using piping and our original list, it is possible to queue up a batch run of trimmomatic for all our files, note that this is a different way to run a loop compared with what we did before.\n",
    "\n",
    "The below code may take approximately 30 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrimmomaticSE: Started with arguments:\n",
      " -threads 7 data/raw_fastq/SRR11550221.fastq.gz data/trimmed/SRR11550221_trimmed.fastq ILLUMINACLIP:data/trimmed/TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA'\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'\n",
      "ILLUMINACLIP: Using 0 prefix pairs, 2 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Reads: 46053552 Surviving: 46003886 (99.89%) Dropped: 49666 (0.11%)\n",
      "TrimmomaticSE: Completed successfully\n",
      "TrimmomaticSE: Started with arguments:\n",
      " -threads 7 data/raw_fastq/SRR11550223.fastq.gz data/trimmed/SRR11550223_trimmed.fastq ILLUMINACLIP:data/trimmed/TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA'\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'\n",
      "ILLUMINACLIP: Using 0 prefix pairs, 2 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Reads: 40255612 Surviving: 40196256 (99.85%) Dropped: 59356 (0.15%)\n",
      "TrimmomaticSE: Completed successfully\n",
      "TrimmomaticSE: Started with arguments:\n",
      " -threads 7 data/raw_fastq/SRR11550225.fastq.gz data/trimmed/SRR11550225_trimmed.fastq ILLUMINACLIP:data/trimmed/TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA'\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'\n",
      "ILLUMINACLIP: Using 0 prefix pairs, 2 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Reads: 37087937 Surviving: 37045030 (99.88%) Dropped: 42907 (0.12%)\n",
      "TrimmomaticSE: Completed successfully\n",
      "TrimmomaticSE: Started with arguments:\n",
      " -threads 7 data/raw_fastq/SRR11550227.fastq.gz data/trimmed/SRR11550227_trimmed.fastq ILLUMINACLIP:data/trimmed/TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA'\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'\n",
      "ILLUMINACLIP: Using 0 prefix pairs, 2 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Reads: 49645505 Surviving: 49573769 (99.86%) Dropped: 71736 (0.14%)\n",
      "TrimmomaticSE: Completed successfully\n",
      "TrimmomaticSE: Started with arguments:\n",
      " -threads 7 data/raw_fastq/SRR11550229.fastq.gz data/trimmed/SRR11550229_trimmed.fastq ILLUMINACLIP:data/trimmed/TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA'\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'\n",
      "ILLUMINACLIP: Using 0 prefix pairs, 2 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Reads: 41530740 Surviving: 41522160 (99.98%) Dropped: 8580 (0.02%)\n",
      "TrimmomaticSE: Completed successfully\n",
      "TrimmomaticSE: Started with arguments:\n",
      " -threads 7 data/raw_fastq/SRR11550231.fastq.gz data/trimmed/SRR11550231_trimmed.fastq ILLUMINACLIP:data/trimmed/TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA'\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'\n",
      "ILLUMINACLIP: Using 0 prefix pairs, 2 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Reads: 53090577 Surviving: 53030456 (99.89%) Dropped: 60121 (0.11%)\n",
      "TrimmomaticSE: Completed successfully\n"
     ]
    }
   ],
   "source": [
    "!cat accs.txt | xargs -I {} \\\n",
    "trimmomatic SE -threads $THREADS \\\n",
    "'data/raw_fastq/{}.fastq.gz' \\\n",
    "'data/trimmed/{}_trimmed.fastq' \\\n",
    "ILLUMINACLIP:data/trimmed/TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 MINLEN:36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: Run FastQC\n",
    "It's best practice to run FastQC after trimming. However, you may decide to run FastQC only once, before or after trimming.\n",
    "\n",
    "We will proceed with only the forward reads -- this is because, looking at trimmomatic, there were very few 'orphaned' reads. That is to say, most forward and reverse reads were successfully paired together. Because we are just trying to map to a transcriptome, the read lengths of the forward reads alone, in this case, around 60 millions~ basepairs, should be sufficient.\n",
    "\n",
    "The below code may take around 15-20 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "null\n",
      "null\n",
      "null\n",
      "null\n",
      "null\n",
      "Started analysis of SRR11550231_trimmed.fastq\n",
      "Started analysis of SRR11550227_trimmed.fastq\n",
      "Started analysis of SRR11550225_trimmed.fastq\n",
      "Started analysis of SRR11550221_trimmed.fastq\n",
      "Started analysis of SRR11550223_trimmed.fastq\n",
      "Started analysis of SRR11550229_trimmed.fastq\n",
      "Approx 5% complete for SRR11550225_trimmed.fastq\n",
      "Approx 5% complete for SRR11550223_trimmed.fastq\n",
      "Approx 5% complete for SRR11550229_trimmed.fastq\n",
      "Approx 5% complete for SRR11550221_trimmed.fastq\n",
      "Approx 5% complete for SRR11550227_trimmed.fastq\n",
      "Approx 5% complete for SRR11550231_trimmed.fastq\n",
      "Approx 10% complete for SRR11550225_trimmed.fastq\n",
      "Approx 10% complete for SRR11550223_trimmed.fastq\n",
      "Approx 10% complete for SRR11550229_trimmed.fastq\n",
      "Approx 10% complete for SRR11550221_trimmed.fastq\n",
      "Approx 10% complete for SRR11550227_trimmed.fastq\n",
      "Approx 10% complete for SRR11550231_trimmed.fastq\n",
      "Approx 15% complete for SRR11550225_trimmed.fastq\n",
      "Approx 15% complete for SRR11550223_trimmed.fastq\n",
      "Approx 15% complete for SRR11550229_trimmed.fastq\n",
      "Approx 15% complete for SRR11550221_trimmed.fastq\n",
      "Approx 20% complete for SRR11550225_trimmed.fastq\n",
      "Approx 15% complete for SRR11550227_trimmed.fastq\n",
      "Approx 15% complete for SRR11550231_trimmed.fastq\n",
      "Approx 20% complete for SRR11550223_trimmed.fastq\n",
      "Approx 20% complete for SRR11550229_trimmed.fastq\n",
      "Approx 25% complete for SRR11550225_trimmed.fastq\n",
      "Approx 20% complete for SRR11550221_trimmed.fastq\n",
      "Approx 20% complete for SRR11550227_trimmed.fastq\n",
      "Approx 25% complete for SRR11550223_trimmed.fastq\n",
      "Approx 25% complete for SRR11550229_trimmed.fastq\n",
      "Approx 20% complete for SRR11550231_trimmed.fastq\n",
      "Approx 30% complete for SRR11550225_trimmed.fastq\n",
      "Approx 25% complete for SRR11550221_trimmed.fastq\n",
      "Approx 30% complete for SRR11550223_trimmed.fastq\n",
      "Approx 25% complete for SRR11550227_trimmed.fastq\n",
      "Approx 35% complete for SRR11550225_trimmed.fastq\n",
      "Approx 30% complete for SRR11550229_trimmed.fastq\n",
      "Approx 25% complete for SRR11550231_trimmed.fastq\n",
      "Approx 30% complete for SRR11550221_trimmed.fastq\n",
      "Approx 35% complete for SRR11550223_trimmed.fastq\n",
      "Approx 40% complete for SRR11550225_trimmed.fastq\n",
      "Approx 35% complete for SRR11550229_trimmed.fastq\n",
      "Approx 30% complete for SRR11550227_trimmed.fastq\n",
      "Approx 40% complete for SRR11550223_trimmed.fastq\n",
      "Approx 35% complete for SRR11550221_trimmed.fastq\n",
      "Approx 30% complete for SRR11550231_trimmed.fastq\n",
      "Approx 45% complete for SRR11550225_trimmed.fastq\n",
      "Approx 40% complete for SRR11550229_trimmed.fastq\n",
      "Approx 35% complete for SRR11550227_trimmed.fastq\n",
      "Approx 45% complete for SRR11550223_trimmed.fastq\n",
      "Approx 50% complete for SRR11550225_trimmed.fastq\n",
      "Approx 40% complete for SRR11550221_trimmed.fastq\n",
      "Approx 35% complete for SRR11550231_trimmed.fastq\n",
      "Approx 45% complete for SRR11550229_trimmed.fastq\n",
      "Approx 50% complete for SRR11550223_trimmed.fastq\n",
      "Approx 55% complete for SRR11550225_trimmed.fastq\n",
      "Approx 40% complete for SRR11550227_trimmed.fastq\n",
      "Approx 45% complete for SRR11550221_trimmed.fastq\n",
      "Approx 40% complete for SRR11550231_trimmed.fastq\n",
      "Approx 50% complete for SRR11550229_trimmed.fastq\n",
      "Approx 60% complete for SRR11550225_trimmed.fastq\n",
      "Approx 55% complete for SRR11550223_trimmed.fastq\n",
      "Approx 50% complete for SRR11550221_trimmed.fastq\n",
      "Approx 45% complete for SRR11550227_trimmed.fastq\n",
      "Approx 55% complete for SRR11550229_trimmed.fastq\n",
      "Approx 45% complete for SRR11550231_trimmed.fastq\n",
      "Approx 65% complete for SRR11550225_trimmed.fastq\n",
      "Approx 60% complete for SRR11550223_trimmed.fastq\n",
      "Approx 55% complete for SRR11550221_trimmed.fastq\n",
      "Approx 50% complete for SRR11550227_trimmed.fastq\n",
      "Approx 70% complete for SRR11550225_trimmed.fastq\n",
      "Approx 60% complete for SRR11550229_trimmed.fastq\n",
      "Approx 65% complete for SRR11550223_trimmed.fastq\n",
      "Approx 50% complete for SRR11550231_trimmed.fastq\n",
      "Approx 60% complete for SRR11550221_trimmed.fastq\n",
      "Approx 75% complete for SRR11550225_trimmed.fastq\n",
      "Approx 55% complete for SRR11550227_trimmed.fastq\n",
      "Approx 70% complete for SRR11550223_trimmed.fastq\n",
      "Approx 65% complete for SRR11550229_trimmed.fastq\n",
      "Approx 55% complete for SRR11550231_trimmed.fastq\n",
      "Approx 80% complete for SRR11550225_trimmed.fastq\n",
      "Approx 65% complete for SRR11550221_trimmed.fastq\n",
      "Approx 75% complete for SRR11550223_trimmed.fastq\n",
      "Approx 60% complete for SRR11550227_trimmed.fastq\n",
      "Approx 70% complete for SRR11550229_trimmed.fastq\n",
      "Approx 85% complete for SRR11550225_trimmed.fastq\n",
      "Approx 60% complete for SRR11550231_trimmed.fastq\n",
      "Approx 80% complete for SRR11550223_trimmed.fastq\n",
      "Approx 70% complete for SRR11550221_trimmed.fastq\n",
      "Approx 75% complete for SRR11550229_trimmed.fastq\n",
      "Approx 65% complete for SRR11550227_trimmed.fastq\n",
      "Approx 90% complete for SRR11550225_trimmed.fastq\n",
      "Approx 65% complete for SRR11550231_trimmed.fastq\n",
      "Approx 85% complete for SRR11550223_trimmed.fastq\n",
      "Approx 75% complete for SRR11550221_trimmed.fastq\n",
      "Approx 80% complete for SRR11550229_trimmed.fastq\n",
      "Approx 95% complete for SRR11550225_trimmed.fastq\n",
      "Approx 70% complete for SRR11550227_trimmed.fastq\n",
      "Approx 90% complete for SRR11550223_trimmed.fastq\n",
      "Approx 70% complete for SRR11550231_trimmed.fastq\n",
      "Approx 85% complete for SRR11550229_trimmed.fastq\n",
      "Analysis complete for SRR11550225_trimmed.fastq\n",
      "Approx 80% complete for SRR11550221_trimmed.fastq\n",
      "Approx 75% complete for SRR11550227_trimmed.fastq\n",
      "Approx 95% complete for SRR11550223_trimmed.fastq\n",
      "Approx 90% complete for SRR11550229_trimmed.fastq\n",
      "Approx 75% complete for SRR11550231_trimmed.fastq\n",
      "Approx 85% complete for SRR11550221_trimmed.fastq\n",
      "Approx 80% complete for SRR11550227_trimmed.fastq\n",
      "Analysis complete for SRR11550223_trimmed.fastq\n",
      "Approx 95% complete for SRR11550229_trimmed.fastq\n",
      "Approx 90% complete for SRR11550221_trimmed.fastq\n",
      "Approx 80% complete for SRR11550231_trimmed.fastq\n",
      "Approx 85% complete for SRR11550227_trimmed.fastq\n",
      "Analysis complete for SRR11550229_trimmed.fastq\n",
      "Approx 95% complete for SRR11550221_trimmed.fastq\n",
      "Approx 85% complete for SRR11550231_trimmed.fastq\n",
      "Approx 90% complete for SRR11550227_trimmed.fastq\n",
      "Analysis complete for SRR11550221_trimmed.fastq\n",
      "Approx 90% complete for SRR11550231_trimmed.fastq\n",
      "Approx 95% complete for SRR11550227_trimmed.fastq\n",
      "Analysis complete for SRR11550227_trimmed.fastq\n",
      "Approx 95% complete for SRR11550231_trimmed.fastq\n",
      "Analysis complete for SRR11550231_trimmed.fastq\n"
     ]
    }
   ],
   "source": [
    "# Run FastQC\n",
    "!cat accs.txt | xargs -P $THREADS -I {} fastqc data/trimmed/{}_trimmed.fastq -o data/fastqc_samples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 8: Run MultiQC\n",
    "MultiQC reads in the FastQC reports and generate a compiled report for all the analyzed FASTQ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91m///\u001b[0m \u001b]8;id=537580;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2mv1.25.1\u001b[0m\n",
      "\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/ec2-user/SageMaker/data/fastqc_samples\n",
      "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m12/12\u001b[0m  l\u001b[0mm  \n",
      "\u001b[?25h\u001b[34m            fastqc\u001b[0m | Found 6 reports\n",
      "\u001b[34m     write_results\u001b[0m | Data        : data/multiqc_samples/multiqc_data\n",
      "\u001b[34m     write_results\u001b[0m | Report      : data/multiqc_samples/multiqc_report.html\n",
      "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "#!multiqc -f data/fastqc_samples/\n",
    "!multiqc -f -o data/multiqc_samples/ data/fastqc_samples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 9: Preparing the STAR-Compatible RSEM Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command prepares a reference genome and annotation files for RNA-Seq analysis using RSEM (RNA-Seq by Expectation-Maximization) and STAR (Spliced Transcripts Alignment to a Reference). It generates files needed to quantify gene and isoform expression. The rsem-prepare-reference function takes a GTF file with gene annotations (mouse_annotation.gtf) and a FASTA file with the reference genome sequence (mouse_genome.fa). It processes these files to create a reference, saving the output in the mouse_reference directory. The --star option ensures the reference is compatible with STAR for efficient transcriptome alignment. The -p $THREADS option sets the number of threads used for parallel processing, speeding up the preparation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsem-extract-reference-transcripts celegans_reference 0 data/reference/celegans_annotation.gtf None 0 data/reference/celegans_genome.fa\n",
      "Parsed 200000 lines\n",
      "Parsed 400000 lines\n",
      "Parsed 600000 lines\n",
      "Parsing gtf File is done!\n",
      "data/reference/celegans_genome.fa is processed!\n",
      "56721 transcripts are extracted and 0 transcripts are omitted.\n",
      "Extracting sequences is done!\n",
      "Group File is generated!\n",
      "Transcript Information File is generated!\n",
      "Chromosome List File is generated!\n",
      "Extracted Sequences File is generated!\n",
      "\n",
      "rsem-preref celegans_reference.transcripts.fa 1 celegans_reference\n",
      "Refs.makeRefs finished!\n",
      "Refs.saveRefs finished!\n",
      "celegans_reference.idx.fa is generated!\n",
      "celegans_reference.n2g.idx.fa is generated!\n",
      "\n",
      "STAR  --runThreadN 7  --runMode genomeGenerate  --genomeDir .  --genomeFastaFiles data/reference/celegans_genome.fa  --sjdbGTFfile data/reference/celegans_annotation.gtf  --sjdbOverhang 100  --outFileNamePrefix celegans_reference\n",
      "\t/home/ec2-user/anaconda3/envs/tensorflow2_p310/bin/STAR-avx2 --runThreadN 7 --runMode genomeGenerate --genomeDir . --genomeFastaFiles data/reference/celegans_genome.fa --sjdbGTFfile data/reference/celegans_annotation.gtf --sjdbOverhang 100 --outFileNamePrefix celegans_reference\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-03T14:39:20+0000 :/opt/conda/conda-bld/star_1720017372352/work/source\n",
      "Oct 09 07:53:05 ..... started STAR run\n",
      "Oct 09 07:53:05 ... starting to generate Genome files\n",
      "Oct 09 07:53:07 ..... processing annotations GTF\n",
      "!!!!! WARNING: --genomeSAindexNbases 14 is too large for the genome size=100286401, which may cause seg-fault at the mapping step. Re-run genome generation with recommended --genomeSAindexNbases 12\n",
      "Oct 09 07:53:10 ... starting to sort Suffix Array. This may take a long time...\n",
      "Oct 09 07:53:10 ... sorting Suffix Array chunks and saving them to disk...\n",
      "Oct 09 07:53:31 ... loading chunks from disk, packing SA...\n",
      "Oct 09 07:53:34 ... finished generating suffix array\n",
      "Oct 09 07:53:34 ... generating Suffix Array index\n",
      "Oct 09 07:54:06 ... completed Suffix Array index\n",
      "Oct 09 07:54:06 ..... inserting junctions into the genome indices\n",
      "Oct 09 07:54:58 ... writing Genome to disk ...\n",
      "Oct 09 07:54:59 ... writing Suffix Array to disk ...\n",
      "Oct 09 07:55:02 ... writing SAindex to disk\n",
      "Oct 09 07:55:08 ..... finished successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rsem-prepare-reference --gtf data/reference/celegans_annotation.gtf --star -p $THREADS data/reference/celegans_genome.fa celegans_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t/home/ec2-user/anaconda3/envs/tensorflow2_p310/bin/STAR-avx2 --runThreadN 7 --runMode genomeGenerate --genomeDir . --genomeFastaFiles data/reference/celegans_genome.fa --sjdbGTFfile data/reference/celegans_annotation.gtf --sjdbOverhang 100 --genomeSAindexNbases 12 --outFileNamePrefix celegans_reference\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-03T14:39:20+0000 :/opt/conda/conda-bld/star_1720017372352/work/source\n",
      "Oct 09 07:55:09 ..... started STAR run\n",
      "Oct 09 07:55:09 ... starting to generate Genome files\n",
      "Oct 09 07:55:10 ..... processing annotations GTF\n",
      "Oct 09 07:55:13 ... starting to sort Suffix Array. This may take a long time...\n",
      "Oct 09 07:55:14 ... sorting Suffix Array chunks and saving them to disk...\n",
      "Oct 09 07:55:34 ... loading chunks from disk, packing SA...\n",
      "Oct 09 07:55:37 ... finished generating suffix array\n",
      "Oct 09 07:55:37 ... generating Suffix Array index\n",
      "Oct 09 07:55:47 ... completed Suffix Array index\n",
      "Oct 09 07:55:47 ..... inserting junctions into the genome indices\n",
      "Oct 09 07:56:28 ... writing Genome to disk ...\n",
      "Oct 09 07:56:28 ... writing Suffix Array to disk ...\n",
      "Oct 09 07:56:32 ... writing SAindex to disk\n",
      "Oct 09 07:56:32 ..... finished successfully\n"
     ]
    }
   ],
   "source": [
    "!STAR --runThreadN $THREADS --runMode genomeGenerate --genomeDir . \\\n",
    "--genomeFastaFiles data/reference/celegans_genome.fa \\\n",
    "--sjdbGTFfile data/reference/celegans_annotation.gtf \\\n",
    "--sjdbOverhang 100 \\\n",
    "--genomeSAindexNbases 12 \\\n",
    "--outFileNamePrefix celegans_reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 10: Run STAR for Alignment, Prepare and Run RSEM for Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script automates RNA-Seq gene expression quantification using RSEM and STAR. It reads SRR accession IDs from accs.txt, saves results in data/rsem_output, and runs rsem-calculate-expression for each ID. It uses paired-end trimmed FASTQ files from data/trimmed/ and a STAR-aligned RSEM reference (mouse_reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550221celegans.temp/SRR11550221celegans  --readFilesIn data/trimmed/SRR11550221_trimmed.fastq \n",
      "\t/home/ec2-user/anaconda3/envs/tensorflow2_p310/bin/STAR-avx2 --genomeDir . --outSAMunmapped Within --outFilterType BySJout --outSAMattributes NH HI AS NM MD --outFilterMultimapNmax 20 --outFilterMismatchNmax 999 --outFilterMismatchNoverLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --sjdbScore 1 --runThreadN 7 --genomeLoad NoSharedMemory --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMheaderHD @HD VN:1.4 SO:unsorted --outFileNamePrefix data/rsem_output/SRR11550221celegans.temp/SRR11550221celegans --readFilesIn data/trimmed/SRR11550221_trimmed.fastq\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-03T14:39:20+0000 :/opt/conda/conda-bld/star_1720017372352/work/source\n",
      "Oct 09 07:56:32 ..... started STAR run\n",
      "Oct 09 07:56:32 ..... loading genome\n",
      "Oct 09 07:56:33 ..... started mapping\n",
      "Oct 09 08:00:27 ..... finished mapping\n",
      "Oct 09 08:00:28 ..... finished successfully\n",
      "\n",
      "rsem-parse-alignments celegans_reference data/rsem_output/SRR11550221celegans.temp/SRR11550221celegans data/rsem_output/SRR11550221celegans.stat/SRR11550221celegans data/rsem_output/SRR11550221celegans.temp/SRR11550221celegans.bam 1 -tag XM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSEM's indices might be corrupted, unassigned_transcript_572 appears more than once!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The SAM/BAM file declares less reference sequences (56719) than RSEM knows (56721)!\n",
      "\"rsem-parse-alignments celegans_reference data/rsem_output/SRR11550221celegans.temp/SRR11550221celegans data/rsem_output/SRR11550221celegans.stat/SRR11550221celegans data/rsem_output/SRR11550221celegans.temp/SRR11550221celegans.bam 1 -tag XM\" failed! Plase check if you provide correct parameters/options for the pipeline!\n",
      "STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550223celegans.temp/SRR11550223celegans  --readFilesIn data/trimmed/SRR11550223_trimmed.fastq \n",
      "\t/home/ec2-user/anaconda3/envs/tensorflow2_p310/bin/STAR-avx2 --genomeDir . --outSAMunmapped Within --outFilterType BySJout --outSAMattributes NH HI AS NM MD --outFilterMultimapNmax 20 --outFilterMismatchNmax 999 --outFilterMismatchNoverLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --sjdbScore 1 --runThreadN 7 --genomeLoad NoSharedMemory --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMheaderHD @HD VN:1.4 SO:unsorted --outFileNamePrefix data/rsem_output/SRR11550223celegans.temp/SRR11550223celegans --readFilesIn data/trimmed/SRR11550223_trimmed.fastq\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-03T14:39:20+0000 :/opt/conda/conda-bld/star_1720017372352/work/source\n",
      "Oct 09 08:00:29 ..... started STAR run\n",
      "Oct 09 08:00:29 ..... loading genome\n",
      "Oct 09 08:00:30 ..... started mapping\n",
      "Oct 09 08:03:48 ..... finished mapping\n",
      "Oct 09 08:03:49 ..... finished successfully\n",
      "\n",
      "rsem-parse-alignments celegans_reference data/rsem_output/SRR11550223celegans.temp/SRR11550223celegans data/rsem_output/SRR11550223celegans.stat/SRR11550223celegans data/rsem_output/SRR11550223celegans.temp/SRR11550223celegans.bam 1 -tag XM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSEM's indices might be corrupted, unassigned_transcript_572 appears more than once!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The SAM/BAM file declares less reference sequences (56719) than RSEM knows (56721)!\n",
      "\"rsem-parse-alignments celegans_reference data/rsem_output/SRR11550223celegans.temp/SRR11550223celegans data/rsem_output/SRR11550223celegans.stat/SRR11550223celegans data/rsem_output/SRR11550223celegans.temp/SRR11550223celegans.bam 1 -tag XM\" failed! Plase check if you provide correct parameters/options for the pipeline!\n",
      "STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550225celegans.temp/SRR11550225celegans  --readFilesIn data/trimmed/SRR11550225_trimmed.fastq \n",
      "\t/home/ec2-user/anaconda3/envs/tensorflow2_p310/bin/STAR-avx2 --genomeDir . --outSAMunmapped Within --outFilterType BySJout --outSAMattributes NH HI AS NM MD --outFilterMultimapNmax 20 --outFilterMismatchNmax 999 --outFilterMismatchNoverLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --sjdbScore 1 --runThreadN 7 --genomeLoad NoSharedMemory --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMheaderHD @HD VN:1.4 SO:unsorted --outFileNamePrefix data/rsem_output/SRR11550225celegans.temp/SRR11550225celegans --readFilesIn data/trimmed/SRR11550225_trimmed.fastq\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-03T14:39:20+0000 :/opt/conda/conda-bld/star_1720017372352/work/source\n",
      "Oct 09 08:03:49 ..... started STAR run\n",
      "Oct 09 08:03:49 ..... loading genome\n",
      "Oct 09 08:03:50 ..... started mapping\n",
      "\"STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550225celegans.temp/SRR11550225celegans  --readFilesIn data/trimmed/SRR11550225_trimmed.fastq \" failed! Plase check if you provide correct parameters/options for the pipeline!\n",
      "STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550227celegans.temp/SRR11550227celegans  --readFilesIn data/trimmed/SRR11550227_trimmed.fastq \n",
      "\"STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550227celegans.temp/SRR11550227celegans  --readFilesIn data/trimmed/SRR11550227_trimmed.fastq \" failed! Plase check if you provide correct parameters/options for the pipeline!\n",
      "STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550229celegans.temp/SRR11550229celegans  --readFilesIn data/trimmed/SRR11550229_trimmed.fastq \n",
      "\t/home/ec2-user/anaconda3/envs/tensorflow2_p310/bin/STAR-avx2 --genomeDir . --outSAMunmapped Within --outFilterType BySJout --outSAMattributes NH HI AS NM MD --outFilterMultimapNmax 20 --outFilterMismatchNmax 999 --outFilterMismatchNoverLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --sjdbScore 1 --runThreadN 7 --genomeLoad NoSharedMemory --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMheaderHD @HD VN:1.4 SO:unsorted --outFileNamePrefix data/rsem_output/SRR11550229celegans.temp/SRR11550229celegans --readFilesIn data/trimmed/SRR11550229_trimmed.fastq\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-03T14:39:20+0000 :/opt/conda/conda-bld/star_1720017372352/work/source\n",
      "Oct 09 08:03:55 ..... started STAR run\n",
      "Oct 09 08:03:55 ..... loading genome\n",
      "\"STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550229celegans.temp/SRR11550229celegans  --readFilesIn data/trimmed/SRR11550229_trimmed.fastq \" failed! Plase check if you provide correct parameters/options for the pipeline!\n",
      "STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550231celegans.temp/SRR11550231celegans  --readFilesIn data/trimmed/SRR11550231_trimmed.fastq \n",
      "\t/home/ec2-user/anaconda3/envs/tensorflow2_p310/bin/STAR-avx2 --genomeDir . --outSAMunmapped Within --outFilterType BySJout --outSAMattributes NH HI AS NM MD --outFilterMultimapNmax 20 --outFilterMismatchNmax 999 --outFilterMismatchNoverLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --sjdbScore 1 --runThreadN 7 --genomeLoad NoSharedMemory --outSAMtype BAM Unsorted --quantMode TranscriptomeSAM --outSAMheaderHD @HD VN:1.4 SO:unsorted --outFileNamePrefix data/rsem_output/SRR11550231celegans.temp/SRR11550231celegans --readFilesIn data/trimmed/SRR11550231_trimmed.fastq\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-03T14:39:20+0000 :/opt/conda/conda-bld/star_1720017372352/work/source\n",
      "Oct 09 08:03:55 ..... started STAR run\n",
      "Oct 09 08:03:55 ..... loading genome\n",
      "\"STAR --genomeDir .  --outSAMunmapped Within  --outFilterType BySJout  --outSAMattributes NH HI AS NM MD  --outFilterMultimapNmax 20  --outFilterMismatchNmax 999  --outFilterMismatchNoverLmax 0.04  --alignIntronMin 20  --alignIntronMax 1000000  --alignMatesGapMax 1000000  --alignSJoverhangMin 8  --alignSJDBoverhangMin 1  --sjdbScore 1  --runThreadN 7  --genomeLoad NoSharedMemory  --outSAMtype BAM Unsorted  --quantMode TranscriptomeSAM  --outSAMheaderHD \\@HD VN:1.4 SO:unsorted  --outFileNamePrefix data/rsem_output/SRR11550231celegans.temp/SRR11550231celegans  --readFilesIn data/trimmed/SRR11550231_trimmed.fastq \" failed! Plase check if you provide correct parameters/options for the pipeline!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure you've set the path to the RSEM binary\n",
    "with open('accs.txt', 'r') as f:\n",
    "    srr_accessions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "THREADS = 7  # Define number of threads\n",
    "output_dir = \"data/rsem_output\"\n",
    "\n",
    "for srr in srr_accessions:\n",
    "    os.system(f\"rsem-calculate-expression -p {THREADS} --star \"\n",
    "              f\"data/trimmed/{srr}_trimmed.fastq celegans_reference \"\n",
    "              f\"{output_dir}/{srr}celegans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 11: Report the top 10 most highly expressed genes in the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in each wild-type sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to RSEM results directory\n",
    "rsem_results_dir = 'data/rsem_output'\n",
    "\n",
    "# Loop through each file in accs.txt\n",
    "for srr_id in open('accs.txt'):\n",
    "    srr_id = srr_id.strip()  # Remove newline character\n",
    "    rsem_result_file = f'{rsem_results_dir}/{srr_id}.genes.results'\n",
    "\n",
    "    # Load the RSEM results into a Pandas DataFrame\n",
    "    df = pd.read_csv(rsem_result_file, sep='\\t')\n",
    "\n",
    "    # Sort the DataFrame by TPM values in descending order and get the top 10 genes\n",
    "    top_10_genes = df.sort_values(by='TPM', ascending=False).head(10)\n",
    "\n",
    "    # Print the top 10 genes with their TPM values\n",
    "    print(f\"Top 10 Genes by TPM for {srr_id}:\")\n",
    "    print(top_10_genes[['gene_id', 'TPM']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 12: Report the expression of ENSMUSG00000064351 for each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the wild-type sample. The fields in the RSEM `genes.results` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to RSEM results directory\n",
    "rsem_results_dir = 'data/rsem_output'\n",
    "\n",
    "# Target gene ID\n",
    "target_gene = 'ENSMUSG00000064351'\n",
    "\n",
    "# Loop through each file in accs.txt\n",
    "for srr_id in open('accs.txt'):\n",
    "    srr_id = srr_id.strip()  # Remove newline character\n",
    "    rsem_result_file = f'{rsem_results_dir}/{srr_id}.genes.results'\n",
    "\n",
    "    # Load the RSEM results into a Pandas DataFrame\n",
    "    df = pd.read_csv(rsem_result_file, sep='\\t')\n",
    "\n",
    "    # Filter for the target gene\n",
    "    target_gene_data = df[df['gene_id'] == target_gene]\n",
    "\n",
    "    # Print the target gene's TPM value for the SRR ID\n",
    "    print(f\"TPM for {target_gene} in {srr_id}: {target_gene_data['TPM'].values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 13: Export Read counts to S3 Bucket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code effectively extracts gene expression data from RSEM output files and stores them in a structured format on an S3 bucket. This data will be accessible for further analysis in Tutorial 2 and Tutorial 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "# Define the path to your RSEM output directory\n",
    "rsem_output_path = \"data/rsem_output\"\n",
    "\n",
    "# Define the S3 bucket and output path\n",
    "s3_bucket = \"sra-data-athena\"\n",
    "s3_output_path = \"readcounts/\"\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Get a list of all .genes.results files in the directory\n",
    "genes_files = [f for f in os.listdir(rsem_output_path) if f.endswith('.genes.results')]\n",
    "\n",
    "# Loop through each file to extract gene ID, expected counts, and gene length\n",
    "for file in genes_files:\n",
    "    file_path = os.path.join(rsem_output_path, file)\n",
    "    \n",
    "    # Read the .genes.results file\n",
    "    rsem_data = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "    # Check if the necessary columns exist\n",
    "    if all(col in rsem_data.columns for col in [\"gene_id\", \"expected_count\", \"length\"]):\n",
    "        # Create a new dataframe with required columns\n",
    "        result_data = rsem_data[[\"gene_id\", \"expected_count\", \"length\"]]\n",
    "        result_data.columns = [\"GeneID\", \"Count\", \"GeneLength\"]\n",
    "\n",
    "        # Define the output filename based on the input file name\n",
    "        output_file_name = f\"{os.path.splitext(file)[0]}.txt\"\n",
    "        s3_output_file_path = f\"{s3_output_path}{output_file_name}\"\n",
    "\n",
    "        # Convert the DataFrame to a CSV string\n",
    "        csv_buffer = result_data.to_csv(sep=\"\\t\", index=False)\n",
    "\n",
    "        # Upload the result directly to S3\n",
    "        s3_client.put_object(Bucket=s3_bucket, Key=s3_output_file_path, Body=csv_buffer)\n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: Required columns are missing in file: {file}\")\n",
    "\n",
    "# Optionally, print a message indicating completion\n",
    "print(\"Extraction and file creation complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 14: Save Merged Read Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code combines multiple RSEM gene count files into a single, unified file, making it easier to analyze and visualize the gene expression data. This files was also uploaded to S3 Bucket to allow further analysis in other Tutorials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure the RSEM quantification results directory exists\n",
    "!mkdir -p data/rsem_output\n",
    "\n",
    "# Merge RSEM results by gene counts (similar to Salmon's numreads merge)\n",
    "!rsem-generate-data-matrix data/rsem_output/*.genes.results > data/rsem_output/merged_gene_counts.txt\n",
    "\n",
    "# Optionally, rename the columns based on the samples\n",
    "# If you want to assign your GSM identifiers or any other custom names, edit the header.\n",
    "!sed -i \"1s/.*/Name\\tGSM6658439\\tGSM6658438\\tGSM6658435\\tGSM6658441\\tGSM6658433\\tGSM6658431\\tGSM6658429\\tGSM6658427/\" data/rsem_output/merged_gene_counts.txt\n",
    "\n",
    "# Remove any unnecessary prefixes like 'gene-' or 'rna-' for easier formatting\n",
    "!sed -i \"s/gene-//g\" data/rsem_output/merged_gene_counts.txt\n",
    "!sed -i \"s/rna-//g\" data/rsem_output/merged_gene_counts.txt\n",
    "\n",
    "# Show a preview of the merged quantification file\n",
    "!head data/rsem_output/merged_gene_counts.txt\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# Define the file path and S3 bucket details\n",
    "file_path = \"data/rsem_output/merged_gene_counts.txt\"\n",
    "bucket_name = \"sra-data-athena\"\n",
    "s3_key = \"readcounts/merged_gene_counts.txt\"\n",
    "\n",
    "# Initialize an S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Upload the file to the specified S3 bucket\n",
    "try:\n",
    "    s3_client.upload_file(file_path, bucket_name, s3_key)\n",
    "    print(f\"File {file_path} uploaded successfully to {bucket_name}/{s3_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading file: {e}\")\n",
    "\n",
    "# Define the file paths and S3 bucket details\n",
    "rsem_output_path = \"data/rsem_output\"\n",
    "feature_table_path = \"data/reference/celegans_feature_table.txt\"\n",
    "bucket_name = \"sra-data-athena\"\n",
    "s3_output_path = \"readcounts/\"\n",
    "s3_feature_table_path = \"reference/celegans_feature_table.txt\"\n",
    "\n",
    "# ... (rest of the code remains the same)\n",
    "\n",
    "# Upload the gene count file\n",
    "s3_client.upload_file(file_path, bucket_name, s3_key)\n",
    "\n",
    "# Upload the feature table file\n",
    "s3_client.upload_file(feature_table_path, bucket_name, s3_feature_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 15: Save RSEM reference and STAR index to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp data/rsem_reference s3://sra-data-athena/reference/rsem_reference/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a name=\"workflow\">Additional Workflows</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have read counts per gene, feel free to explore the R workflow which creates plots and analyses using these readcount files, or try other alternate workflows for creating read count files, such as using snakemake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Workflow One:](Tutorial_1_subsampling_mouse-miniforge.ipynb) A short introduction to downloading and mapping sequences to a mouse genome using STAR and RSEM.\n",
    "\n",
    "\n",
    "[Workflow Two (DEG Analysis):](Tutorial_2_DEG_Analysis_mouse.ipynb) Using Deseq2 and R to conduct clustering and differential gene expression analysis.\n",
    "\n",
    "[Workflow Three (Network Analysis):](Tutorial_3_NetAct.ipynb) Using NetAct and R to conduct transcription factor network analysis.\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m112"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
