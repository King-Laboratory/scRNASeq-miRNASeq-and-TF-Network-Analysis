{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extended RNA-Seq Analysis Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity and time, The short tutorial workflow uses truncated and partial run data from the Cushman et al., project.\n",
    "\n",
    "The tutorial repeats the short tutorial, but with the full fastq files and includes some extra steps, such as how to download and prepare the transcriptome files used by salmon, alternate ways to navigate the NCBI databases for annotation or reference files you might need, and how to combine salmon outputs at the end into a single genecount file.\n",
    "\n",
    "Full fastq files can be rather large, and so the downloading, extracting, and analysis of them means this tutorial can take over 1 hour 45 minutes to run the code fully. This is part of the reason we have a short and easy introductory tutorial, and this longer more full tutorial for those interested.\n",
    "\n",
    "If this is too lengthy feel free to move on to the snakemake tutorial or the DEG analysis tutorial -- all the files used in the DEG tutorial were created using this extended tutorial workflow.\n",
    "\n",
    "![RNA-Seq workflow](images/rnaseq-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 1: Install Mambaforge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install Mambaforge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\n",
    "!bash Mambaforge-$(uname)-$(uname -m).sh -b -u -p $HOME/mambaforge\n",
    "!date +\"%T\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using mambaforge and bioconda, install the tools that will be used in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tell the computer where the mambaforge bin files are located\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + os.environ[\"HOME\"]+\"/mambaforge/bin\"\n",
    "\n",
    "#now we can easily use 'mamba' command to install software \n",
    "!mamba install -y -c conda-forge -c bioconda trimmomatic fastqc multiqc salmon gsutil sql-magic entrez-direct gffread parallel-fastq-dump sra-tools sql-magic pyathena samtools star rsem entrez-direct subread pigz -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 2: Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of directories in the sra-data-athena to store the reads, reference sequence files, and output files. Notice that first we remove the `data` directory to clean up files from Tutorial_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd $HOMEDIR\n",
    "!echo $PWD\n",
    "!mkdir -p data\n",
    "!mkdir -p data/trunc_rawfastq\n",
    "!mkdir -p data/trimmed\n",
    "!mkdir -p data/fastqc\n",
    "!mkdir -p data/fastqc_samples/\n",
    "!mkdir -p data/reference\n",
    "!mkdir -p data/star_alignments\n",
    "!mkdir -p data/quants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set # THREADS depending on your VM size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numthreads=!lscpu | grep '^CPU(s)'| awk '{print $2-1}'\n",
    "\n",
    "#python variable to hold the amount of threads your cpu has,\n",
    "#useful for downstream tools like STAR, trimmomatic, etc\n",
    "threads = int(numthreads[0])\n",
    "\n",
    "#its also good to have a shell version of the variable for commands that use piping, \n",
    "#in jupyter, shell commandds with piping sometimes causes python variables to not work and generally be wonky.\n",
    "%env THREADS=$threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3: Downloading relevant FASTQ files using SRA Tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.1: Finding run accession numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!esearch -db sra -query \"PRJNA892075\" | efetch -format runinfo | cut -d',' -f1 | tail -n +2 > accs.txt\n",
    "!cat accs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "\n",
    "# Use the correct argument name: s3_staging_dir\n",
    "conn = connect(s3_staging_dir='s3://sra-data-athena/', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the Glue client\n",
    "glue_client = boto3.client('glue', region_name='us-east-1')\n",
    "\n",
    "# Run the crawler\n",
    "crawler_name = 'sra_crawler'  # Use your crawler's name\n",
    "glue_client.start_crawler(Name=crawler_name)\n",
    "\n",
    "print(f\"Crawler {crawler_name} started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM AwsDataCatalog.srametadata.metadata\n",
    "WHERE bioproject = 'PRJNA892075'\n",
    "AND acc IN ('SRR21972729', 'SRR21972728', 'SRR21972725', 'SRR21972724')\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#write the SRR column to a text file\n",
    "with open('accs.txt', 'w') as f:\n",
    "    accs = df['acc'].to_string(header=False, index=False)\n",
    "    f.write(accs)\n",
    "    \n",
    "#print the text file\n",
    "!cat accs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.2: Using the SRA-toolkit for a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage for SRA download:\n",
    "!prefetch SRR21972724 -O data/raw_fastq -f yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mamba install -c conda-forge pigz -y\n",
    "\n",
    "#convert sra to fastq\n",
    "!fasterq-dump data/raw_fastq/SRR21972724 -f -O data/raw_fastq/ -e $THREADS\n",
    "#compress fastq to fastq.gz to save space\n",
    "!pigz -p $THREADS data/raw_fastq/SRR21972724_1.fastq\n",
    "!pigz -p $THREADS data/raw_fastq/SRR21972724_2.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3.3 Downloading multiple files using the SRA-toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat accs.txt | xargs -P $THREADS -I {} prefetch {} -O data/raw_fastq -f yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3.4 Converting Multiple SRA files to Fastq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!for x in `cat accs.txt`; do fasterq-dump -f -O data/raw_fastq -e $THREADS -m 4G data/raw_fastq/$x/$x.sra; done\n",
    "\n",
    "##example of how to alternatively do the above process with parallel-fastq-dump using piping\n",
    "!cat accs.txt | xargs -I {} parallel-fastq-dump -O data/raw_fastq/ --tmpdir . --threads $THREADS --gzip --split-files --sra-id {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 4: Download reference transcriptome files that will be used by STAR using E-Direct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget ftp://ftp.ensembl.org/pub/release-104/fasta/mus_musculus/dna/Mus_musculus.GRCm39.dna.primary_assembly.fa.gz -O data/reference/mouse_genome.fa.gz\n",
    "! wget ftp://ftp.ensembl.org/pub/release-104/gtf/mus_musculus/Mus_musculus.GRCm39.104.gtf.gz -O data/reference/mouse_annotation.gtf.gz\n",
    "! wget -O data/reference/mouse_feature_table.txt.gz https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/635/GCF_000001635.27_GRCm39/GCF_000001635.27_GRCm39_feature_table.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gunzip -f data/reference/mouse_genome.fa.gz \n",
    "!gunzip -f data/reference/mouse_annotation.gtf.gz\n",
    "!gunzip -f data/reference/mouse_feature_table.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: Run FastQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run fastqc for forward reads in parallel\n",
    "!cat accs.txt | xargs -P $THREADS -I {} fastqc \"data/raw_fastq/{}_1.fastq.gz\" -o data/fastqc/\n",
    "\n",
    "# Run fastqc for reverse reads in parallel\n",
    "!cat accs.txt | xargs -P $THREADS -I {} fastqc \"data/raw_fastq/{}_2.fastq.gz\" -o data/fastqc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='./data/fastqc/SRR21972724.html', width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!multiqc -f data/fastqc/\n",
    "\n",
    "import pandas as pd\n",
    "dframe = pd.read_csv(\"./multiqc_data/multiqc_fastqc.txt\", sep='\\t')\n",
    "display(dframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 5.1 Merging our fastq files (Optional if there are multiple SRR per GSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "\n",
    "# Use the correct argument name: s3_staging_dir\n",
    "conn = connect(s3_staging_dir='s3://sra-data-athena/', region_name='us-east-1')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM AwsDataCatalog.srametadata.metadata\n",
    "WHERE bioproject = 'PRJNA1132229'\n",
    "AND organism = 'Mus musculus'\n",
    "\"\"\"\n",
    "df = pd.read_sql(\n",
    "    query, conn\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os so we can easily pass strings to shell commands using 'subprocess'\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "#now get the accession id's and sample id's from the created dataframe\n",
    "runs = df['acc'].values\n",
    "samples = list(set(df['acc'].values))\n",
    "\n",
    "#sort them to be in numerical order\n",
    "runs.sort()\n",
    "samples.sort()\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now iterate through the samples, \n",
    "#because there are two SRRs to a run, \n",
    "#this means corresponding SRRs indices to an index of a GSM will be\n",
    "#gsm index *2, and *2+1 \n",
    "for index, item in enumerate(samples):\n",
    "    \n",
    "    #concatenate the two SRRs\n",
    "    os.system(f\"cat data/raw_fastq/{runs[index*2]}_1.fastq data/raw_fastq/{runs[index*2+1]}_1.fastq > data/raw_fastq/{samples[index]}_1.fastq\")\n",
    "    #delete the previous fastq files to save space\n",
    "    os.system(f\"rm data/raw_fastq/{runs[index*2]}_1.fastq\")\n",
    "    os.system(f\"rm data/raw_fastq/{runs[index*2+1]}_1.fastq\")\n",
    "    #zip the merged fastq file to save more space\n",
    "    os.system(f\"gzip data/raw_fastq/{samples[index]}_1.fastq\")\n",
    "    \n",
    "    #repeat for reverse reads\n",
    "    os.system(f\"cat data/raw_fastq/{runs[index*2]}_2.fastq data/raw_fastq/{runs[index*2+1]}_2.fastq > data/raw_fastq/{samples[index]}_2.fastq\")\n",
    "    \n",
    "    os.system(f\"rm data/raw_fastq/{runs[index*2]}_2.fastq\")\n",
    "    os.system(f\"rm data/raw_fastq/{runs[index*2+1]}_2.fastq\")  \n",
    "   \n",
    "    #its good practice to zip files to save space\n",
    "    os.system(f\"gzip data/raw_fastq/{samples[index]}_2.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since our files will now be samples, not SRRs we can write a new text file to use for downstream batch processes.\n",
    "#we can use the DF we made in the previous cell.\n",
    "with open('samples.txt', 'w') as f:\n",
    "    df = df.sort_values(by='sample_name', ascending=True)\n",
    "    samples = df['acc'].unique()\n",
    "    samples = '\\n'.join(map(str, samples))\n",
    "    f.write(samples)\n",
    "    \n",
    "!cat samples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 5.3: Copy data file for Trimmomatic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp -r gs://nigms-sandbox/me-inbre-rnaseq-pipelinev2/config/TruSeq3-PE.fa .\n",
    "!head TruSeq3-PE.fa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: Run Trimmomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat accs.txt | xargs -I {} \\\n",
    "trimmomatic PE -threads $THREADS \\\n",
    "'data/raw_fastq/{}_1.fastq.gz' 'data/raw_fastq/{}_2.fastq.gz' \\\n",
    "'data/trimmed/{}_1_trimmed.fastq.gz' 'data/trimmed/{}_1_trimmed_unpaired.fastq.gz' \\\n",
    "'data/trimmed/{}_2_trimmed.fastq.gz' 'data/trimmed/{}_2_trimmed_unpaired.fastq.gz' \\\n",
    "ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 7: Run FastQC\n",
    "FastQC is an invaluable tool that allows you to evaluate whether there are problems with a set of reads. For example, it will provide a report of whether there is any bias in the sequence composition of the reads.\n",
    "\n",
    "Because jupyter is at its core a python editor, we can use python code and html support to display results in-line.\n",
    "\n",
    "FastQC looks for different characteristics of quality in reads. It is very rare that every metric will pass. In many cases, they serve as warnings, which should be compared to the context of the experiment. For instance, here, per base sequence content, sequence length distribution, sequence duplication levels, and overrepresented sequences all throw warnings. Per base sequence content routinely fails in RNA-sequencing in the first 15~ or so bases due to biased fragmentation. In most of our samples, this is where we see the failure (20% or more difference between A/T or G/C), and so is not unexpected. The overrepresented sequences can be BLASTed to show the majority of them are ribosomal RNA. Ribosomal RNA contamination is also common and will not be indexed later, and so not a large concern. Other metrics look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run FastQC\n",
    "!cat accs.txt | xargs -P $THREADS -I {} fastqc data/trimmed/{}_1_trimmed.fastq.gz data/trimmed/{}_2_trimmed.fastq.gz -o data/fastqc_samples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 8: Run MultiQC\n",
    "MultiQC reads in the FastQC reports and generate a compiled report for all the analyzed FASTQ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!multiqc -f data/fastqc_samples/\n",
    "!multiqc -f -o data/multiqc_samples/ data/fastqc_samples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 9: STAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "# Get the number of threads from the shell command\n",
    "numthreads = !lscpu | grep '^CPU(s)' | awk '{print $2-1}'\n",
    "threads = int(numthreads[0])\n",
    "\n",
    "os.environ['THREADS'] = str(threads)\n",
    "\n",
    "!/usr/bin/time -v STAR --runThreadN $THREADS --runMode genomeGenerate \\\n",
    "    --genomeDir data/reference/STAR_index \\\n",
    "    --genomeFastaFiles data/reference/mouse_genome.fa \\\n",
    "    --sjdbGTFfile data/reference/mouse_annotation.gtf \\\n",
    "    --sjdbOverhang 100 \\\n",
    "    --limitGenomeGenerateRAM 60000000000 \\\n",
    "    --genomeSAsparseD 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 10: Run STAR for Alignment, Prepare and Run RSEM for Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a directory to store STAR alignment output\n",
    "!mkdir -p data/aligned_bam\n",
    "\n",
    "# Align each sample\n",
    "!cat accs.txt | xargs -I {} \\\n",
    "    STAR --runThreadN $THREADS \\\n",
    "      --genomeDir data/reference/STAR_index \\\n",
    "      --readFilesIn data/trimmed/{}_1_trimmed.fastq.gz data/trimmed/{}_2_trimmed.fastq.gz \\\n",
    "      --readFilesCommand zcat \\\n",
    "      --outFileNamePrefix data/aligned_bam/{}_ \\\n",
    "      --outSAMtype BAM SortedByCoordinate \\\n",
    "      --quantMode TranscriptomeSAM GeneCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p data/rsem_reference/mouse_rsem_reference\n",
    "!rsem-prepare-reference --gtf data/reference/mouse_annotation.gtf \\\n",
    "                        --star \\\n",
    "                        --star-path /sw/STAR \\\n",
    "                        data/reference/mouse_genome.fa \\\n",
    "                        data/rsem_reference/mouse_rsem_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a directory to store RSEM quantification results\n",
    "!mkdir -p data/rsem_output\n",
    "\n",
    "# Run RSEM quantification for each sample listed in accs.txt\n",
    "!cat accs.txt | xargs -I {} bash -c \n",
    "rsem-calculate-expression --paired-end \\\n",
    "    --alignments \\\n",
    "    --bam \\\n",
    "    --star \\\n",
    "    -p $THREADS \\\n",
    "    data/aligned_bam/{}_Aligned.toTranscriptome.out.bam \\\n",
    "    data/rsem_reference/mouse_rsem_reference \\\n",
    "    data/rsem_output/{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "# Get the number of threads from the shell command\n",
    "numthreads = !lscpu | grep '^CPU(s)' | awk '{print $2-1}'\n",
    "threads = int(numthreads[0])\n",
    "\n",
    "os.environ['THREADS'] = str(threads)\n",
    "\n",
    "!/usr/bin/time -v STAR --runThreadN $THREADS --runMode genomeGenerate --genomeDir data/reference/STAR_index --genomeFastaFiles data/reference/mouse_genome.fa --sjdbGTFfile data/reference/mouse_annotation.gtf --sjdbOverhang 100 --limitGenomeGenerateRAM 60000000000 --genomeSAsparseD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a directory to store STAR alignment output\n",
    "!mkdir -p data/aligned_bam\n",
    "\n",
    "# Align each sample\n",
    "!cat accs.txt | xargs -I {} STAR --runThreadN $THREADS --genomeDir data/reference/STAR_index --readFilesIn data/trimmed/{}_1_trimmed.fastq.gz data/trimmed/{}_2_trimmed.fastq.gz --readFilesCommand zcat --outFileNamePrefix data/aligned_bam/{}_ --outSAMtype BAM SortedByCoordinate --quantMode TranscriptomeSAM GeneCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p data/rsem_reference/mouse_rsem_reference\n",
    "!rsem-prepare-reference --gtf data/reference/mouse_annotation.gtf --star --star-path /sw/STAR data/reference/mouse_genome.fa data/rsem_reference/mouse_rsem_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a directory to store RSEM quantification results\n",
    "!mkdir -p data/rsem_output\n",
    "\n",
    "# Run RSEM quantification for each sample listed in accs.txt\n",
    "!cat accs.txt | xargs -I {} bash -c \"rsem-calculate-expression --paired-end --alignments --bam --star -p $THREADS data/aligned_bam/{}_Aligned.toTranscriptome.out.bam data/rsem_reference/mouse_rsem_reference data/rsem_output/{}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 11: Report the top 10 most highly expressed genes in the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in each wild-type sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to RSEM results directory\n",
    "rsem_results_dir = 'data/rsem_output'\n",
    "\n",
    "# Loop through each file in accs.txt\n",
    "for srr_id in open('accs.txt'):\n",
    "    srr_id = srr_id.strip()  # Remove newline character\n",
    "    rsem_result_file = f'{rsem_results_dir}/{srr_id}.genes.results'\n",
    "\n",
    "    # Load the RSEM results into a Pandas DataFrame\n",
    "    df = pd.read_csv(rsem_result_file, sep='\\t')\n",
    "\n",
    "    # Sort the DataFrame by TPM values in descending order and get the top 10 genes\n",
    "    top_10_genes = df.sort_values(by='TPM', ascending=False).head(10)\n",
    "\n",
    "    # Print the top 10 genes with their TPM values\n",
    "    print(f\"Top 10 Genes by TPM for {srr_id}:\")\n",
    "    print(top_10_genes[['gene_id', 'TPM']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in the double lysogen samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 12: Report the expression of ENSMUSG00000064356 for each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the wild-type sample. The fields in the Salmon `quant.sf` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to RSEM results directory\n",
    "rsem_results_dir = 'data/rsem_output'\n",
    "\n",
    "# Target gene ID\n",
    "target_gene = 'ENSMUSG00000064356'\n",
    "\n",
    "# Loop through each file in accs.txt\n",
    "for srr_id in open('accs.txt'):\n",
    "    srr_id = srr_id.strip()  # Remove newline character\n",
    "    rsem_result_file = f'{rsem_results_dir}/{srr_id}.genes.results'\n",
    "\n",
    "    # Load the RSEM results into a Pandas DataFrame\n",
    "    df = pd.read_csv(rsem_result_file, sep='\\t')\n",
    "\n",
    "    # Filter for the target gene\n",
    "    target_gene_data = df[df['gene_id'] == target_gene]\n",
    "\n",
    "    # Print the target gene's TPM value for the SRR ID\n",
    "    print(f\"TPM for {target_gene} in {srr_id}: {target_gene_data['TPM'].values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the double lysogen sample. The fields in the Salmon `quant.sf` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 12: Combine Genecounts to a Single Genecount File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure the RSEM quantification results directory exists\n",
    "!mkdir -p data/rsem_output\n",
    "\n",
    "# Merge RSEM results by gene counts (similar to Salmon's numreads merge)\n",
    "!rsem-generate-data-matrix data/rsem_output/*.genes.results > data/rsem_output/merged_gene_counts.txt\n",
    "\n",
    "# Optionally, rename the columns based on the samples\n",
    "# If you want to assign your GSM identifiers or any other custom names, edit the header.\n",
    "!sed -i \"1s/.*/Name\\tGSM6658437\\tGSM6658435\\tGSM6658431\\tGSM6658429/\" data/rsem_output/merged_gene_counts.txt\n",
    "\n",
    "# Remove any unnecessary prefixes like 'gene-' or 'rna-' for easier formatting\n",
    "!sed -i \"s/gene-//g\" data/rsem_output/merged_gene_counts.txt\n",
    "!sed -i \"s/rna-//g\" data/rsem_output/merged_gene_counts.txt\n",
    "\n",
    "# Show a preview of the merged quantification file\n",
    "!head data/rsem_output/merged_gene_counts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a name=\"workflow\">Additional Workflows</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have read counts per gene, feel free to explore the R workflow which creates plots and analyses using these readcount files, or try other alternate workflows for creating read count files, such as using snakemake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Workflow One:](Tutorial_1.ipynb) A short introduction to downloading and mapping sequences to a transcriptome using Trimmomatic and Salmon. Here is a link to the YouTube video demonstrating the tutorial: <https://youtu.be/ChGfBR4do_Y>.\n",
    "\n",
    "[Workflow One (Extended):](Tutorial_1B_Extended.ipynb) An extended version of workflow one. Once you have got your feet wet, you can retry workflow one with this extended version that covers the entire dataset, and includes elaboration such as using SRA tools for sequence downloading, and examples of running batches of fastq files through the pipeline. This workflow may take around an hour to run.\n",
    "\n",
    "[Workflow One (Using Snakemake):](Tutorial_2_Snakemake.ipynb) Using snakemake to run workflow one.\n",
    "\n",
    "[Workflow Two (DEG Analysis):](Tutorial_3_DEG_Analysis.ipynb) Using Deseq2 and R to conduct clustering and differential gene expression analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNA-Seq workflow](images/RNA-Seq_Notebook_Homepage.png)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m112"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
