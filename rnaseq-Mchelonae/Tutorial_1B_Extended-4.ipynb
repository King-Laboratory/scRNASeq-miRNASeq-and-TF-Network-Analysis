{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extended RNA-Seq Analysis Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity and time, The short tutorial workflow uses truncated and partial run data from the Cushman et al., project.\n",
    "\n",
    "The tutorial repeats the short tutorial, but with the full fastq files and includes some extra steps, such as how to download and prepare the transcriptome files used by salmon, alternate ways to navigate the NCBI databases for annotation or reference files you might need, and how to combine salmon outputs at the end into a single genecount file.\n",
    "\n",
    "Full fastq files can be rather large, and so the downloading, extracting, and analysis of them means this tutorial can take over 1 hour 45 minutes to run the code fully. This is part of the reason we have a short and easy introductory tutorial, and this longer more full tutorial for those interested.\n",
    "\n",
    "If this is too lengthy feel free to move on to the snakemake tutorial or the DEG analysis tutorial -- all the files used in the DEG tutorial were created using this extended tutorial workflow.\n",
    "\n",
    "![RNA-Seq workflow](images/rnaseq-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Install Mambaforge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install Mambaforge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9G\t/home/ec2-user/SageMaker/rnaseq-myco-notebook\n",
      "24K\t/home/ec2-user/SageMaker/.virtual_documents\n",
      "4.0K\t/home/ec2-user/SageMaker/.Trash-1000\n",
      "du: cannot read directory ‘/home/ec2-user/SageMaker/lost+found’: Permission denied\n",
      "16K\t/home/ec2-user/SageMaker/lost+found\n",
      "4.0K\t/home/ec2-user/SageMaker/.sparkmagic\n",
      "2.9G\t/home/ec2-user/SageMaker\n",
      "total 40K\n",
      "drwxr-xr-x  7 ec2-user ec2-user 4.0K Sep 13 04:59 .\n",
      "drwx------ 21 ec2-user ec2-user 4.0K Sep 13 04:57 ..\n",
      "drwx------  2 root     root      16K Sep  5 17:19 lost+found\n",
      "drwxrwxr-x  5 ec2-user ec2-user 4.0K Sep 13 05:00 rnaseq-myco-notebook\n",
      "drwxr-xr-x  2 ec2-user ec2-user 4.0K Sep  5 17:19 .sparkmagic\n",
      "drwx------  2 ec2-user ec2-user 4.0K Sep 13 05:00 .Trash-1000\n",
      "drwxrwxr-x  3 ec2-user ec2-user 4.0K Sep 13 04:59 .virtual_documents\n"
     ]
    }
   ],
   "source": [
    "#clean system: \n",
    "!rm -rf /home/ec2-user/SageMaker/.Trash-1000/*\n",
    "\n",
    "!du -h --max-depth=1 /home/ec2-user/SageMaker\n",
    "!ls -lah /home/ec2-user/SageMaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "devtmpfs        1.9G     0  1.9G   0% /dev\n",
      "tmpfs           1.9G     0  1.9G   0% /dev/shm\n",
      "tmpfs           1.9G  584K  1.9G   1% /run\n",
      "tmpfs           1.9G     0  1.9G   0% /sys/fs/cgroup\n",
      "/dev/nvme0n1p1  135G   79G   57G  58% /\n",
      "/dev/nvme1n1    148G   44G   98G  32% /home/ec2-user/SageMaker\n",
      "tmpfs           386M     0  386M   0% /run/user/1002\n",
      "tmpfs           386M     0  386M   0% /run/user/1001\n",
      "tmpfs           386M     0  386M   0% /run/user/1000\n"
     ]
    }
   ],
   "source": [
    "#check disk usage \n",
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 86.8M  100 86.8M    0     0   106M      0 --:--:-- --:--:-- --:--:--  106M\n",
      "PREFIX=/home/ec2-user/mambaforge\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/ec2-user/mambaforge/envs/_virtual_specs_checks\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "Dry run. Not executing the transaction.\n",
      "Unpacking payload ...\n",
      "Extracting _libgcc_mutex-0.1-conda_forge.tar.bz2\n",
      "Extracting ca-certificates-2024.8.30-hbcca054_0.conda\n",
      "Extracting ld_impl_linux-64-2.40-hf3520f5_7.conda\n",
      "Extracting pybind11-abi-4-hd8ed1ab_3.tar.bz2\n",
      "Extracting python_abi-3.12-5_cp312.conda\n",
      "Extracting tzdata-2024a-h8827d51_1.conda\n",
      "Extracting libgomp-14.1.0-h77fa898_1.conda\n",
      "Extracting _openmp_mutex-4.5-2_gnu.tar.bz2\n",
      "Extracting libgcc-14.1.0-h77fa898_1.conda\n",
      "Extracting libgcc-ng-14.1.0-h69a702a_1.conda\n",
      "Extracting libstdcxx-14.1.0-hc0a3c3a_1.conda\n",
      "Extracting bzip2-1.0.8-h4bc722e_7.conda\n",
      "Extracting c-ares-1.32.3-h4bc722e_0.conda\n",
      "Extracting keyutils-1.6.1-h166bdaf_0.tar.bz2\n",
      "Extracting libev-4.33-hd590300_2.conda\n",
      "Extracting libexpat-2.6.2-h59595ed_0.conda\n",
      "Extracting libffi-3.4.2-h7f98852_5.tar.bz2\n",
      "Extracting libiconv-1.17-hd590300_2.conda\n",
      "Extracting libnsl-2.0.1-hd590300_0.conda\n",
      "Extracting libstdcxx-ng-14.1.0-h4852527_1.conda\n",
      "Extracting libuuid-2.38.1-h0b41bf4_0.conda\n",
      "Extracting libxcrypt-4.4.36-hd590300_1.conda\n",
      "Extracting libzlib-1.3.1-h4ab18f5_1.conda\n",
      "Extracting lzo-2.10-hd590300_1001.conda\n",
      "Extracting ncurses-6.5-he02047a_1.conda\n",
      "Extracting openssl-3.3.1-hb9d3cd8_3.conda\n",
      "Extracting reproc-14.2.4.post0-hd590300_1.conda\n",
      "Extracting xz-5.2.6-h166bdaf_0.tar.bz2\n",
      "Extracting fmt-10.2.1-h00ab1b0_0.conda\n",
      "Extracting icu-75.1-he02047a_0.conda\n",
      "Extracting libedit-3.1.20191231-he28a2e2_2.tar.bz2\n",
      "Extracting libnghttp2-1.58.0-h47da74e_1.conda\n",
      "Extracting libsolv-0.7.30-h3509ff9_0.conda\n",
      "Extracting libsqlite-3.46.1-hadc24fc_0.conda\n",
      "Extracting libssh2-1.11.0-h0841786_0.conda\n",
      "Extracting lz4-c-1.9.4-hcb278e6_0.conda\n",
      "Extracting readline-8.2-h8228510_1.conda\n",
      "Extracting reproc-cpp-14.2.4.post0-h59595ed_1.conda\n",
      "Extracting tk-8.6.13-noxft_h4845f30_101.conda\n",
      "Extracting yaml-cpp-0.8.0-h59595ed_0.conda\n",
      "Extracting zstd-1.5.6-ha6fb4c9_0.conda\n",
      "Extracting krb5-1.21.3-h659f571_0.conda\n",
      "Extracting libxml2-2.12.7-he7c6b58_4.conda\n",
      "Extracting python-3.12.5-h2ad013b_0_cpython.conda\n",
      "Extracting libarchive-3.7.4-hfca40fe_0.conda\n",
      "Extracting libcurl-8.9.1-hdb1bdb2_0.conda\n",
      "Extracting menuinst-2.1.2-py312h7900ff3_1.conda\n",
      "Extracting archspec-0.2.3-pyhd8ed1ab_0.conda\n",
      "Extracting boltons-24.0.0-pyhd8ed1ab_0.conda\n",
      "Extracting brotli-python-1.1.0-py312h2ec8cdc_2.conda\n",
      "Extracting certifi-2024.8.30-pyhd8ed1ab_0.conda\n",
      "Extracting charset-normalizer-3.3.2-pyhd8ed1ab_0.conda\n",
      "Extracting colorama-0.4.6-pyhd8ed1ab_0.tar.bz2\n",
      "Extracting distro-1.9.0-pyhd8ed1ab_0.conda\n",
      "Extracting frozendict-2.4.4-py312h9a8786e_0.conda\n",
      "Extracting hpack-4.0.0-pyh9f0ad1d_0.tar.bz2\n",
      "Extracting hyperframe-6.0.1-pyhd8ed1ab_0.tar.bz2\n",
      "Extracting idna-3.8-pyhd8ed1ab_0.conda\n",
      "Extracting jsonpointer-3.0.0-py312h7900ff3_1.conda\n",
      "Extracting libmamba-1.5.9-h4cc3d14_0.conda\n",
      "Extracting packaging-24.1-pyhd8ed1ab_0.conda\n",
      "Extracting platformdirs-4.2.2-pyhd8ed1ab_0.conda\n",
      "Extracting pluggy-1.5.0-pyhd8ed1ab_0.conda\n",
      "Extracting pycosat-0.6.6-py312h98912ed_0.conda\n",
      "Extracting pycparser-2.22-pyhd8ed1ab_0.conda\n",
      "Extracting pysocks-1.7.1-pyha2e5f31_6.tar.bz2\n",
      "Extracting ruamel.yaml.clib-0.2.8-py312h98912ed_0.conda\n",
      "Extracting setuptools-73.0.1-pyhd8ed1ab_0.conda\n",
      "Extracting truststore-0.9.2-pyhd8ed1ab_0.conda\n",
      "Extracting wheel-0.44.0-pyhd8ed1ab_0.conda\n",
      "Extracting cffi-1.17.0-py312h06ac9bb_1.conda\n",
      "Extracting h2-4.1.0-pyhd8ed1ab_0.tar.bz2\n",
      "Extracting jsonpatch-1.33-pyhd8ed1ab_0.conda\n",
      "Extracting libmambapy-1.5.9-py312h7fb9e8e_0.conda\n",
      "Extracting pip-24.2-pyh8b19718_1.conda\n",
      "Extracting ruamel.yaml-0.18.6-py312h98912ed_0.conda\n",
      "Extracting tqdm-4.66.5-pyhd8ed1ab_0.conda\n",
      "Extracting zstandard-0.23.0-py312hef9b889_1.conda\n",
      "Extracting conda-package-streaming-0.10.0-pyhd8ed1ab_0.conda\n",
      "Extracting urllib3-2.2.2-pyhd8ed1ab_1.conda\n",
      "Extracting conda-package-handling-2.3.0-pyh7900ff3_0.conda\n",
      "Extracting requests-2.32.3-pyhd8ed1ab_0.conda\n",
      "Extracting conda-24.7.1-py312h7900ff3_0.conda\n",
      "Extracting conda-libmamba-solver-24.7.0-pyhd8ed1ab_0.conda\n",
      "Extracting mamba-1.5.9-py312h9460a1c_0.conda\n",
      "!!!!!! Mambaforge is now deprecated !!!!!\n",
      "Future Miniforge releases will NOT build Mambaforge installers.\n",
      "We advise you switch to Miniforge at your earliest convenience.\n",
      "More details at https://conda-forge.org/news/2024/07/29/sunsetting-mambaforge/.\n",
      "If you are unable to switch to Miniforge, you may pin your installer version to one found in \n",
      "https://github.com/conda-forge/miniforge/releases/tag/24.5.0-1\n",
      "or if you lack the system requirements (Linux glibc >= 2.17, or macOS + x86-64bit >= 10.13)\n",
      "you may pin your installer to one older version found in \n",
      "https://github.com/conda-forge/miniforge/releases/tag/24.3.0-0\n",
      "\n",
      "Installing base environment...\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/ec2-user/mambaforge\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - conda-forge/linux-64::_libgcc_mutex==0.1=conda_forge[md5=d7c89558ba9fa0495403155b64376d81]\n",
      "   - conda-forge/linux-64::ca-certificates==2024.8.30=hbcca054_0[md5=c27d1c142233b5bc9ca570c6e2e0c244]\n",
      "   - conda-forge/linux-64::ld_impl_linux-64==2.40=hf3520f5_7[md5=b80f2f396ca2c28b8c14c437a4ed1e74]\n",
      "   - conda-forge/noarch::pybind11-abi==4=hd8ed1ab_3[md5=878f923dd6acc8aeb47a75da6c4098be]\n",
      "   - conda-forge/linux-64::python_abi==3.12=5_cp312[md5=0424ae29b104430108f5218a66db7260]\n",
      "   - conda-forge/noarch::tzdata==2024a=h8827d51_1[md5=8bfdead4e0fff0383ae4c9c50d0531bd]\n",
      "   - conda-forge/linux-64::libgomp==14.1.0=h77fa898_1[md5=23c255b008c4f2ae008f81edcabaca89]\n",
      "   - conda-forge/linux-64::_openmp_mutex==4.5=2_gnu[md5=73aaf86a425cc6e73fcf236a5a46396d]\n",
      "   - conda-forge/linux-64::libgcc==14.1.0=h77fa898_1[md5=002ef4463dd1e2b44a94a4ace468f5d2]\n",
      "   - conda-forge/linux-64::libgcc-ng==14.1.0=h69a702a_1[md5=1efc0ad219877a73ef977af7dbb51f17]\n",
      "   - conda-forge/linux-64::libstdcxx==14.1.0=hc0a3c3a_1[md5=9dbb9699ea467983ba8a4ba89b08b066]\n",
      "   - conda-forge/linux-64::bzip2==1.0.8=h4bc722e_7[md5=62ee74e96c5ebb0af99386de58cf9553]\n",
      "   - conda-forge/linux-64::c-ares==1.32.3=h4bc722e_0[md5=7624e34ee6baebfc80d67bac76cc9d9d]\n",
      "   - conda-forge/linux-64::keyutils==1.6.1=h166bdaf_0[md5=30186d27e2c9fa62b45fb1476b7200e3]\n",
      "   - conda-forge/linux-64::libev==4.33=hd590300_2[md5=172bf1cd1ff8629f2b1179945ed45055]\n",
      "   - conda-forge/linux-64::libexpat==2.6.2=h59595ed_0[md5=e7ba12deb7020dd080c6c70e7b6f6a3d]\n",
      "   - conda-forge/linux-64::libffi==3.4.2=h7f98852_5[md5=d645c6d2ac96843a2bfaccd2d62b3ac3]\n",
      "   - conda-forge/linux-64::libiconv==1.17=hd590300_2[md5=d66573916ffcf376178462f1b61c941e]\n",
      "   - conda-forge/linux-64::libnsl==2.0.1=hd590300_0[md5=30fd6e37fe21f86f4bd26d6ee73eeec7]\n",
      "   - conda-forge/linux-64::libstdcxx-ng==14.1.0=h4852527_1[md5=bd2598399a70bb86d8218e95548d735e]\n",
      "   - conda-forge/linux-64::libuuid==2.38.1=h0b41bf4_0[md5=40b61aab5c7ba9ff276c41cfffe6b80b]\n",
      "   - conda-forge/linux-64::libxcrypt==4.4.36=hd590300_1[md5=5aa797f8787fe7a17d1b0821485b5adc]\n",
      "   - conda-forge/linux-64::libzlib==1.3.1=h4ab18f5_1[md5=57d7dc60e9325e3de37ff8dffd18e814]\n",
      "   - conda-forge/linux-64::lzo==2.10=hd590300_1001[md5=ec7398d21e2651e0dcb0044d03b9a339]\n",
      "   - conda-forge/linux-64::ncurses==6.5=he02047a_1[md5=70caf8bb6cf39a0b6b7efc885f51c0fe]\n",
      "   - conda-forge/linux-64::openssl==3.3.1=hb9d3cd8_3[md5=6c566a46baae794daf34775d41eb180a]\n",
      "   - conda-forge/linux-64::reproc==14.2.4.post0=hd590300_1[md5=82ca53502dfd5a64a80dee76dae14685]\n",
      "   - conda-forge/linux-64::xz==5.2.6=h166bdaf_0[md5=2161070d867d1b1204ea749c8eec4ef0]\n",
      "   - conda-forge/linux-64::fmt==10.2.1=h00ab1b0_0[md5=35ef8bc24bd34074ebae3c943d551728]\n",
      "   - conda-forge/linux-64::icu==75.1=he02047a_0[md5=8b189310083baabfb622af68fd9d3ae3]\n",
      "   - conda-forge/linux-64::libedit==3.1.20191231=he28a2e2_2[md5=4d331e44109e3f0e19b4cb8f9b82f3e1]\n",
      "   - conda-forge/linux-64::libnghttp2==1.58.0=h47da74e_1[md5=700ac6ea6d53d5510591c4344d5c989a]\n",
      "   - conda-forge/linux-64::libsolv==0.7.30=h3509ff9_0[md5=02539b77d25aa4f65b20246549e256c3]\n",
      "   - conda-forge/linux-64::libsqlite==3.46.1=hadc24fc_0[md5=36f79405ab16bf271edb55b213836dac]\n",
      "   - conda-forge/linux-64::libssh2==1.11.0=h0841786_0[md5=1f5a58e686b13bcfde88b93f547d23fe]\n",
      "   - conda-forge/linux-64::lz4-c==1.9.4=hcb278e6_0[md5=318b08df404f9c9be5712aaa5a6f0bb0]\n",
      "   - conda-forge/linux-64::readline==8.2=h8228510_1[md5=47d31b792659ce70f470b5c82fdfb7a4]\n",
      "   - conda-forge/linux-64::reproc-cpp==14.2.4.post0=h59595ed_1[md5=715e1d720ec1a03715bebd237972fca5]\n",
      "   - conda-forge/linux-64::tk==8.6.13=noxft_h4845f30_101[md5=d453b98d9c83e71da0741bb0ff4d76bc]\n",
      "   - conda-forge/linux-64::yaml-cpp==0.8.0=h59595ed_0[md5=965eaacd7c18eb8361fd12bb9e7a57d7]\n",
      "   - conda-forge/linux-64::zstd==1.5.6=ha6fb4c9_0[md5=4d056880988120e29d75bfff282e0f45]\n",
      "   - conda-forge/linux-64::krb5==1.21.3=h659f571_0[md5=3f43953b7d3fb3aaa1d0d0723d91e368]\n",
      "   - conda-forge/linux-64::libxml2==2.12.7=he7c6b58_4[md5=08a9265c637230c37cb1be4a6cad4536]\n",
      "   - conda-forge/linux-64::python==3.12.5=h2ad013b_0_cpython[md5=9c56c4df45f6571b13111d8df2448692]\n",
      "   - conda-forge/linux-64::libarchive==3.7.4=hfca40fe_0[md5=32ddb97f897740641d8d46a829ce1704]\n",
      "   - conda-forge/linux-64::libcurl==8.9.1=hdb1bdb2_0[md5=7da1d242ca3591e174a3c7d82230d3c0]\n",
      "   - conda-forge/linux-64::menuinst==2.1.2=py312h7900ff3_1[md5=c6575ae996f2bc0369c73b632db5ca61]\n",
      "   - conda-forge/noarch::archspec==0.2.3=pyhd8ed1ab_0[md5=192278292e20704f663b9c766909d67b]\n",
      "   - conda-forge/noarch::boltons==24.0.0=pyhd8ed1ab_0[md5=61de176bd62041f9cd5bd4fcd09eb0ff]\n",
      "   - conda-forge/linux-64::brotli-python==1.1.0=py312h2ec8cdc_2[md5=b0b867af6fc74b2a0aa206da29c0f3cf]\n",
      "   - conda-forge/noarch::certifi==2024.8.30=pyhd8ed1ab_0[md5=12f7d00853807b0531775e9be891cb11]\n",
      "   - conda-forge/noarch::charset-normalizer==3.3.2=pyhd8ed1ab_0[md5=7f4a9e3fcff3f6356ae99244a014da6a]\n",
      "   - conda-forge/noarch::colorama==0.4.6=pyhd8ed1ab_0[md5=3faab06a954c2a04039983f2c4a50d99]\n",
      "   - conda-forge/noarch::distro==1.9.0=pyhd8ed1ab_0[md5=bbdb409974cd6cb30071b1d978302726]\n",
      "   - conda-forge/linux-64::frozendict==2.4.4=py312h9a8786e_0[md5=ff14ec1103a0817d45e7cf012742ce60]\n",
      "   - conda-forge/noarch::hpack==4.0.0=pyh9f0ad1d_0[md5=914d6646c4dbb1fd3ff539830a12fd71]\n",
      "   - conda-forge/noarch::hyperframe==6.0.1=pyhd8ed1ab_0[md5=9f765cbfab6870c8435b9eefecd7a1f4]\n",
      "   - conda-forge/noarch::idna==3.8=pyhd8ed1ab_0[md5=99e164522f6bdf23c177c8d9ae63f975]\n",
      "   - conda-forge/linux-64::jsonpointer==3.0.0=py312h7900ff3_1[md5=6b51f7459ea4073eeb5057207e2e1e3d]\n",
      "   - conda-forge/linux-64::libmamba==1.5.9=h4cc3d14_0[md5=896cece5b883ad86e9dd88b1f4d23c99]\n",
      "   - conda-forge/noarch::packaging==24.1=pyhd8ed1ab_0[md5=cbe1bb1f21567018ce595d9c2be0f0db]\n",
      "   - conda-forge/noarch::platformdirs==4.2.2=pyhd8ed1ab_0[md5=6f6cf28bf8e021933869bae3f84b8fc9]\n",
      "   - conda-forge/noarch::pluggy==1.5.0=pyhd8ed1ab_0[md5=d3483c8fc2dc2cc3f5cf43e26d60cabf]\n",
      "   - conda-forge/linux-64::pycosat==0.6.6=py312h98912ed_0[md5=8f1c372e7b843167be885dc8229931c1]\n",
      "   - conda-forge/noarch::pycparser==2.22=pyhd8ed1ab_0[md5=844d9eb3b43095b031874477f7d70088]\n",
      "   - conda-forge/noarch::pysocks==1.7.1=pyha2e5f31_6[md5=2a7de29fb590ca14b5243c4c812c8025]\n",
      "   - conda-forge/linux-64::ruamel.yaml.clib==0.2.8=py312h98912ed_0[md5=05f31c2a79ba61df8d6d903ce4a4ce7b]\n",
      "   - conda-forge/noarch::setuptools==73.0.1=pyhd8ed1ab_0[md5=f0b618d7673d1b2464f600b34d912f6f]\n",
      "   - conda-forge/noarch::truststore==0.9.2=pyhd8ed1ab_0[md5=f14e46d1bf271e748ff556d8b872e28a]\n",
      "   - conda-forge/noarch::wheel==0.44.0=pyhd8ed1ab_0[md5=d44e3b085abcaef02983c6305b84b584]\n",
      "   - conda-forge/linux-64::cffi==1.17.0=py312h06ac9bb_1[md5=db9bdbaee0f524ead0471689f002781e]\n",
      "   - conda-forge/noarch::h2==4.1.0=pyhd8ed1ab_0[md5=b748fbf7060927a6e82df7cb5ee8f097]\n",
      "   - conda-forge/noarch::jsonpatch==1.33=pyhd8ed1ab_0[md5=bfdb7c5c6ad1077c82a69a8642c87aff]\n",
      "   - conda-forge/linux-64::libmambapy==1.5.9=py312h7fb9e8e_0[md5=ccaeeb6e3caaf0c744480393791aa366]\n",
      "   - conda-forge/noarch::pip==24.2=pyh8b19718_1[md5=6c78fbb8ddfd64bcb55b5cbafd2d2c43]\n",
      "   - conda-forge/linux-64::ruamel.yaml==0.18.6=py312h98912ed_0[md5=a99a06a875138829ef65f44bbe2c30ca]\n",
      "   - conda-forge/noarch::tqdm==4.66.5=pyhd8ed1ab_0[md5=c6e94fc2b2ec71ea33fe7c7da259acb4]\n",
      "   - conda-forge/linux-64::zstandard==0.23.0=py312hef9b889_1[md5=8b7069e9792ee4e5b4919a7a306d2e67]\n",
      "   - conda-forge/noarch::conda-package-streaming==0.10.0=pyhd8ed1ab_0[md5=3480386e00995f7a1dfb3b9aa2fe70fd]\n",
      "   - conda-forge/noarch::urllib3==2.2.2=pyhd8ed1ab_1[md5=e804c43f58255e977093a2298e442bb8]\n",
      "   - conda-forge/noarch::conda-package-handling==2.3.0=pyh7900ff3_0[md5=0a7dce281ae2be81acab0aa963e6bb99]\n",
      "   - conda-forge/noarch::requests==2.32.3=pyhd8ed1ab_0[md5=5ede4753180c7a550a443c430dc8ab52]\n",
      "   - conda-forge/linux-64::conda==24.7.1=py312h7900ff3_0[md5=e1bf59014e88eaff036101358f63a496]\n",
      "   - conda-forge/noarch::conda-libmamba-solver==24.7.0=pyhd8ed1ab_0[md5=857c9e25f0a77c0bd7eb622d46d9418f]\n",
      "   - conda-forge/linux-64::mamba==1.5.9=py312h9460a1c_0[md5=a8525c8a1647b4f5967fa6b552722851]\n",
      "\n",
      "\n",
      "  Package                         Version  Build               Channel         Size\n",
      "─────────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "─────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  \u001b[32m+ _libgcc_mutex          \u001b[0m           0.1  conda_forge         conda-forge         \n",
      "  \u001b[32m+ ca-certificates        \u001b[0m     2024.8.30  hbcca054_0          conda-forge         \n",
      "  \u001b[32m+ ld_impl_linux-64       \u001b[0m          2.40  hf3520f5_7          conda-forge         \n",
      "  \u001b[32m+ pybind11-abi           \u001b[0m             4  hd8ed1ab_3          conda-forge         \n",
      "  \u001b[32m+ python_abi             \u001b[0m          3.12  5_cp312             conda-forge         \n",
      "  \u001b[32m+ tzdata                 \u001b[0m         2024a  h8827d51_1          conda-forge         \n",
      "  \u001b[32m+ libgomp                \u001b[0m        14.1.0  h77fa898_1          conda-forge         \n",
      "  \u001b[32m+ _openmp_mutex          \u001b[0m           4.5  2_gnu               conda-forge         \n",
      "  \u001b[32m+ libgcc                 \u001b[0m        14.1.0  h77fa898_1          conda-forge         \n",
      "  \u001b[32m+ libgcc-ng              \u001b[0m        14.1.0  h69a702a_1          conda-forge         \n",
      "  \u001b[32m+ libstdcxx              \u001b[0m        14.1.0  hc0a3c3a_1          conda-forge         \n",
      "  \u001b[32m+ bzip2                  \u001b[0m         1.0.8  h4bc722e_7          conda-forge         \n",
      "  \u001b[32m+ c-ares                 \u001b[0m        1.32.3  h4bc722e_0          conda-forge         \n",
      "  \u001b[32m+ keyutils               \u001b[0m         1.6.1  h166bdaf_0          conda-forge         \n",
      "  \u001b[32m+ libev                  \u001b[0m          4.33  hd590300_2          conda-forge         \n",
      "  \u001b[32m+ libexpat               \u001b[0m         2.6.2  h59595ed_0          conda-forge         \n",
      "  \u001b[32m+ libffi                 \u001b[0m         3.4.2  h7f98852_5          conda-forge         \n",
      "  \u001b[32m+ libiconv               \u001b[0m          1.17  hd590300_2          conda-forge         \n",
      "  \u001b[32m+ libnsl                 \u001b[0m         2.0.1  hd590300_0          conda-forge         \n",
      "  \u001b[32m+ libstdcxx-ng           \u001b[0m        14.1.0  h4852527_1          conda-forge         \n",
      "  \u001b[32m+ libuuid                \u001b[0m        2.38.1  h0b41bf4_0          conda-forge         \n",
      "  \u001b[32m+ libxcrypt              \u001b[0m        4.4.36  hd590300_1          conda-forge         \n",
      "  \u001b[32m+ libzlib                \u001b[0m         1.3.1  h4ab18f5_1          conda-forge         \n",
      "  \u001b[32m+ lzo                    \u001b[0m          2.10  hd590300_1001       conda-forge         \n",
      "  \u001b[32m+ ncurses                \u001b[0m           6.5  he02047a_1          conda-forge         \n",
      "  \u001b[32m+ openssl                \u001b[0m         3.3.1  hb9d3cd8_3          conda-forge         \n",
      "  \u001b[32m+ reproc                 \u001b[0m  14.2.4.post0  hd590300_1          conda-forge         \n",
      "  \u001b[32m+ xz                     \u001b[0m         5.2.6  h166bdaf_0          conda-forge         \n",
      "  \u001b[32m+ fmt                    \u001b[0m        10.2.1  h00ab1b0_0          conda-forge         \n",
      "  \u001b[32m+ icu                    \u001b[0m          75.1  he02047a_0          conda-forge         \n",
      "  \u001b[32m+ libedit                \u001b[0m  3.1.20191231  he28a2e2_2          conda-forge         \n",
      "  \u001b[32m+ libnghttp2             \u001b[0m        1.58.0  h47da74e_1          conda-forge         \n",
      "  \u001b[32m+ libsolv                \u001b[0m        0.7.30  h3509ff9_0          conda-forge         \n",
      "  \u001b[32m+ libsqlite              \u001b[0m        3.46.1  hadc24fc_0          conda-forge         \n",
      "  \u001b[32m+ libssh2                \u001b[0m        1.11.0  h0841786_0          conda-forge         \n",
      "  \u001b[32m+ lz4-c                  \u001b[0m         1.9.4  hcb278e6_0          conda-forge         \n",
      "  \u001b[32m+ readline               \u001b[0m           8.2  h8228510_1          conda-forge         \n",
      "  \u001b[32m+ reproc-cpp             \u001b[0m  14.2.4.post0  h59595ed_1          conda-forge         \n",
      "  \u001b[32m+ tk                     \u001b[0m        8.6.13  noxft_h4845f30_101  conda-forge         \n",
      "  \u001b[32m+ yaml-cpp               \u001b[0m         0.8.0  h59595ed_0          conda-forge         \n",
      "  \u001b[32m+ zstd                   \u001b[0m         1.5.6  ha6fb4c9_0          conda-forge         \n",
      "  \u001b[32m+ krb5                   \u001b[0m        1.21.3  h659f571_0          conda-forge         \n",
      "  \u001b[32m+ libxml2                \u001b[0m        2.12.7  he7c6b58_4          conda-forge         \n",
      "  \u001b[32m+ python                 \u001b[0m        3.12.5  h2ad013b_0_cpython  conda-forge         \n",
      "  \u001b[32m+ libarchive             \u001b[0m         3.7.4  hfca40fe_0          conda-forge         \n",
      "  \u001b[32m+ libcurl                \u001b[0m         8.9.1  hdb1bdb2_0          conda-forge         \n",
      "  \u001b[32m+ menuinst               \u001b[0m         2.1.2  py312h7900ff3_1     conda-forge         \n",
      "  \u001b[32m+ archspec               \u001b[0m         0.2.3  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ boltons                \u001b[0m        24.0.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ brotli-python          \u001b[0m         1.1.0  py312h2ec8cdc_2     conda-forge         \n",
      "  \u001b[32m+ certifi                \u001b[0m     2024.8.30  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ charset-normalizer     \u001b[0m         3.3.2  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ colorama               \u001b[0m         0.4.6  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ distro                 \u001b[0m         1.9.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ frozendict             \u001b[0m         2.4.4  py312h9a8786e_0     conda-forge         \n",
      "  \u001b[32m+ hpack                  \u001b[0m         4.0.0  pyh9f0ad1d_0        conda-forge         \n",
      "  \u001b[32m+ hyperframe             \u001b[0m         6.0.1  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ idna                   \u001b[0m           3.8  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ jsonpointer            \u001b[0m         3.0.0  py312h7900ff3_1     conda-forge         \n",
      "  \u001b[32m+ libmamba               \u001b[0m         1.5.9  h4cc3d14_0          conda-forge         \n",
      "  \u001b[32m+ packaging              \u001b[0m          24.1  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ platformdirs           \u001b[0m         4.2.2  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ pluggy                 \u001b[0m         1.5.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ pycosat                \u001b[0m         0.6.6  py312h98912ed_0     conda-forge         \n",
      "  \u001b[32m+ pycparser              \u001b[0m          2.22  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ pysocks                \u001b[0m         1.7.1  pyha2e5f31_6        conda-forge         \n",
      "  \u001b[32m+ ruamel.yaml.clib       \u001b[0m         0.2.8  py312h98912ed_0     conda-forge         \n",
      "  \u001b[32m+ setuptools             \u001b[0m        73.0.1  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ truststore             \u001b[0m         0.9.2  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ wheel                  \u001b[0m        0.44.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ cffi                   \u001b[0m        1.17.0  py312h06ac9bb_1     conda-forge         \n",
      "  \u001b[32m+ h2                     \u001b[0m         4.1.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ jsonpatch              \u001b[0m          1.33  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ libmambapy             \u001b[0m         1.5.9  py312h7fb9e8e_0     conda-forge         \n",
      "  \u001b[32m+ pip                    \u001b[0m          24.2  pyh8b19718_1        conda-forge         \n",
      "  \u001b[32m+ ruamel.yaml            \u001b[0m        0.18.6  py312h98912ed_0     conda-forge         \n",
      "  \u001b[32m+ tqdm                   \u001b[0m        4.66.5  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ zstandard              \u001b[0m        0.23.0  py312hef9b889_1     conda-forge         \n",
      "  \u001b[32m+ conda-package-streaming\u001b[0m        0.10.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ urllib3                \u001b[0m         2.2.2  pyhd8ed1ab_1        conda-forge         \n",
      "  \u001b[32m+ conda-package-handling \u001b[0m         2.3.0  pyh7900ff3_0        conda-forge         \n",
      "  \u001b[32m+ requests               \u001b[0m        2.32.3  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ conda                  \u001b[0m        24.7.1  py312h7900ff3_0     conda-forge         \n",
      "  \u001b[32m+ conda-libmamba-solver  \u001b[0m        24.7.0  pyhd8ed1ab_0        conda-forge         \n",
      "  \u001b[32m+ mamba                  \u001b[0m         1.5.9  py312h9460a1c_0     conda-forge         \n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 85 packages\n",
      "\n",
      "  Total download: 0 B\n",
      "\n",
      "─────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\n",
      "\n",
      "Transaction starting\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\n",
      "Transaction finished\n",
      "\n",
      "To activate this environment, use:\n",
      "\n",
      "    micromamba activate /home/ec2-user/mambaforge\n",
      "\n",
      "Or to execute a single command in this environment, use:\n",
      "\n",
      "    micromamba run -p /home/ec2-user/mambaforge mycommand\n",
      "\n",
      "installation finished.\n",
      "06:20:55\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\n",
    "!bash Mambaforge-$(uname)-$(uname -m).sh -b -u -p $HOME/mambaforge\n",
    "!date +\"%T\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using mambaforge and bioconda, install the tools that will be used in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for: ['trimmomatic', 'fastqc', 'multiqc', 'salmon', 'gsutil', 'sql-magic', 'entrez-direct', 'gffread', 'parallel-fastq-dump', 'sra-tools', 'sql-magic', 'pyathena']\n",
      "\n",
      "conda-forge/linux-64                                        Using cache\n",
      "conda-forge/noarch                                          Using cache\n",
      "bioconda/linux-64                                           Using cache\n",
      "bioconda/noarch                                             Using cache\n",
      "nvidia/linux-64                                             Using cache\n",
      "nvidia/noarch                                               Using cache\n",
      "pytorch/linux-64                                            Using cache\n",
      "pytorch/noarch                                              Using cache\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/.. \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   0.0 B  0.1s\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/.. \u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m   0.0 B  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ghttps://aws-ml-conda.s3.us-west-2.amazonaws.com/..            No change\n",
      "https://aws-ml-conda.s3.us-west-2.amazonaws.com/..            No change\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.10.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/ec2-user/anaconda3/envs/tensorflow2_p310\n",
      "\n",
      "  All requested packages already installed\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#tell the computer where the mambaforge bin files are located\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + os.environ[\"HOME\"]+\"/mambaforge/bin\"\n",
    "\n",
    "#now we can easily use 'mamba' command to install software \n",
    "!mamba install -y -c conda-forge -c bioconda trimmomatic fastqc multiqc salmon gsutil sql-magic entrez-direct gffread parallel-fastq-dump sra-tools sql-magic pyathena -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:\n",
      "  fasterq-dump <path> [options]\n",
      "  fasterq-dump <accession> [options]\n",
      "\n",
      "Options:\n",
      "  -F|--format                      format (special, fastq, default=fastq) \n",
      "  -o|--outfile                     output-file \n",
      "  -O|--outdir                      output-dir \n",
      "  -b|--bufsize                     size of file-buffer dflt=1MB \n",
      "  -c|--curcache                    size of cursor-cache dflt=10MB \n",
      "  -m|--mem                         memory limit for sorting dflt=100MB \n",
      "  -t|--temp                        where to put temp. files dflt=curr dir \n",
      "  -e|--threads                     how many thread dflt=6 \n",
      "  -p|--progress                    show progress \n",
      "  -x|--details                     print details \n",
      "  -s|--split-spot                  split spots into reads \n",
      "  -S|--split-files                 write reads into different files \n",
      "  -3|--split-3                     writes single reads in special file \n",
      "  --concatenate-reads              writes whole spots into one file \n",
      "  -Z|--stdout                      print output to stdout \n",
      "  -f|--force                       force to overwrite existing file(s) \n",
      "  --skip-technical                 skip technical reads \n",
      "  --include-technical              include technical reads \n",
      "  -M|--min-read-len                filter by sequence-len \n",
      "  --table                          which seq-table to use in case of pacbio \n",
      "  -B|--bases                       filter by bases \n",
      "  -A|--append                      append to output-file \n",
      "  --fasta                          produce FASTA output \n",
      "  --fasta-unsorted                 produce FASTA output, unsorted \n",
      "  --fasta-ref-tbl                  produce FASTA output from REFERENCE tbl \n",
      "  --fasta-concat-all               concatenate all rows and produce FASTA \n",
      "  --internal-ref                   extract only internal REFERENCEs \n",
      "  --external-ref                   extract only external REFERENCEs \n",
      "  --ref-name                       extract only these REFERENCEs \n",
      "  --ref-report                     enumerate references \n",
      "  --use-name                       print name instead of seq-id \n",
      "  --seq-defline                    custom defline for sequence:  $ac=accession, \n",
      "                                   $sn=spot-name,  $sg=spot-group, $si=spot-id,  \n",
      "                                   $ri=read-id, $rl=read-length \n",
      "  --qual-defline                   custom defline for qualities:  same as \n",
      "                                   seq-defline \n",
      "  -U|--only-unaligned              process only unaligned reads \n",
      "  -a|--only-aligned                process only aligned reads \n",
      "  --disk-limit                     explicitly set disk-limit \n",
      "  --disk-limit-tmp                 explicitly set disk-limit for temp. files \n",
      "  --size-check                     switch to control: on=perform size-check \n",
      "                                   (default),  off=do not perform size-check,  \n",
      "                                   only=perform size-check only \n",
      "  --ngc <PATH>                     PATH to ngc file \n",
      "\n",
      "  -h|--help                        Output brief explanation for the program. \n",
      "  -V|--version                     Display the version of the program then \n",
      "                                   quit. \n",
      "  -L|--log-level <level>           Logging level as number or enum string. One \n",
      "                                   of (fatal|sys|int|err|warn|info|debug) or \n",
      "                                   (0-6) Current/default is warn. \n",
      "  -v|--verbose                     Increase the verbosity of the program \n",
      "                                   status messages. Use multiple times for more \n",
      "                                   verbosity. Negates quiet. \n",
      "  -q|--quiet                       Turn off all status messages for the \n",
      "                                   program. Negated by verbose. \n",
      "  --option-file <file>             Read more options and parameters from the \n",
      "                                   file. \n",
      "for more information visit:\n",
      "   https://github.com/ncbi/sra-tools/wiki/HowTo:-fasterq-dump\n",
      "   https://github.com/ncbi/sra-tools/wiki/08.-prefetch-and-fasterq-dump\n",
      "\n",
      "fasterq-dump : 3.1.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! fasterq-dump -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of directories to store the reads, reference sequence files, and output files. Notice that first we remove the `data` directory to clean up files from Tutorial_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/rnaseq-myco-notebook\n"
     ]
    }
   ],
   "source": [
    "! cd $HOMEDIR\n",
    "! echo $PWD\n",
    "! rm -r data/\n",
    "! mkdir -p data\n",
    "! mkdir -p data/raw_fastq\n",
    "! mkdir -p data/trimmed\n",
    "! mkdir -p data/fastqc\n",
    "! mkdir -p data/aligned\n",
    "! mkdir -p data/reference\n",
    "! mkdir -p data/fastqc_samples\n",
    "! mkdir -p data/multiqc_samples\n",
    "! mkdir -p data data/fasterqdump/raw_fastq data/prefetch_fasterqdump/raw_fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##not run these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/rnaseq-myco-notebook/data\n"
     ]
    }
   ],
   "source": [
    "cd data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BUCKET=rnaseq-myco-athena\n"
     ]
    }
   ],
   "source": [
    "# make sure you change this name, it needs to be globally unique\n",
    "%env BUCKET=rnaseq-myco-athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# will only create the bucket if it doesn't yet exist\n",
    "# if the bucket exists you won't see any output\n",
    "! aws s3 ls s3://$BUCKET >& /dev/null || aws s3 mb s3://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set # THREADS depending on your VM size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THREADS=1\n"
     ]
    }
   ],
   "source": [
    "numthreads=!lscpu | grep '^CPU(s)'| awk '{print $2-1}'\n",
    "\n",
    "#python variable to hold the amount of threads your cpu has,\n",
    "#useful for downstream tools like salmon, trimmomatic, etc\n",
    "threads = int(numthreads[0])\n",
    "\n",
    "#its also good to have a shell version of the variable for commands that use piping, \n",
    "#in jupyter, shell commandds with piping sometimes causes python variables to not work and generally be wonky.\n",
    "%env THREADS=$threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3: Downloading relevant FASTQ files using SRA Tools\n",
    "\n",
    "Next we will need to download the relevant fastq files.\n",
    "\n",
    "Because these files can be large, the process of downloading and extracting fastq files can be quite lengthy.\n",
    "\n",
    "The sequence data for this tutorial comes from work by Cushman et al., <em><a href='https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8191103/'>Increased whiB7 expression and antibiotic resistance in Mycobacterium chelonae carrying two prophages</a><em>.\n",
    "\n",
    "We will be downloading the sample runs from this project using SRA tools, downloading from the NCBI's SRA (Sequence Run Archives).\n",
    "\n",
    "However, first we need to find the associated accession numbers in order to download.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.1: Finding run accession numbers.\n",
    "\n",
    "The SRA stores sequence data in terms of runs, (SRR stands for Sequence Read Run). To download runs, we will need the accession ID for each run we wish to download. \n",
    "\n",
    "The Cushman et al., project contains 12 runs. To make it easier, these are the run IDs associated with this project:\n",
    "\n",
    "+ SRR13349122\n",
    "+ SRR13349123\n",
    "+ SRR13349124\n",
    "+ SRR13349125\n",
    "+ SRR13349126\n",
    "+ SRR13349127\n",
    "+ SRR13349128\n",
    "+ SRR13349129\n",
    "+ SRR13349130\n",
    "+ SRR13349131\n",
    "+ SRR13349132\n",
    "+ SRR13349133\n",
    "\n",
    "\n",
    "In this case, all these runs belong to the SRP (Sequence Run Project): SRP300216.\n",
    "\n",
    "Sequence run experiments can be searched for using the SRA database on the NCBI website; and article-specific sample run information can be found in the supplementary section of that article.\n",
    "\n",
    "For instance, here, the the authors posted a link to the sequence data GSE (Gene Series number), <a href='https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE164210'>GSE164210</a>. This leads to the appropriate 'Gene Expression Omnibus' page where, among other useful files and information, the relevant SRA database link can be found. \n",
    "\n",
    "Once the accession numbers are located, one can make a text file containing the list of accession IDs however they like.\n",
    "\n",
    "Once again, to make things easier, we have made a .txt with these IDs that you can simply download here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://rnaseq-myco-bucket/reference/accs.txt...\n",
      "/ [1 files][  144.0 B/  144.0 B]                                                \n",
      "Operation completed over 1 objects/144.0 B.                                      \n",
      "SRR13349122\n",
      "SRR13349123\n",
      "SRR13349124\n",
      "SRR13349125\n",
      "SRR13349126\n",
      "SRR13349127\n",
      "SRR13349128\n",
      "SRR13349129\n",
      "SRR13349130\n",
      "SRR13349131\n",
      "SRR13349132\n",
      "SRR13349133\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://rnaseq-myco-bucket/reference/accs.txt .\n",
    "!cat accs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can can also use BigQuery to generate an accession list following the instructions outlined in [this notebook](https://github.com/STRIDES/NIHCloudLabGCP/blob/main/tutorials/notebooks/SRADownload/SRA-Download.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.1.2 (Optional): Generate the accession list file with BigQuery\n",
    "This step uses Python. We will use the BigQuery API. \n",
    "\n",
    "We will create a client the using default project. \n",
    "\n",
    "Then we will query BigQuery using the species name and a range of accession numbers associated with this particular study. \n",
    "\n",
    "Feel free to play around with the query to generate different variations of accession numbers!\n",
    "\n",
    "Please note that if you have errors to make sure you have this API enabled. You can search for BigQuery by navigating back to the Google Cloud Platform dashboard, back to the Google Cloud Platform, and using the search bar at the top, search for 'BigQuery'. On the BigQuery page, click  `Enable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aws sts get-caller-identity\n",
    "### STEP 3.2: Using the SRA-toolkit for a single sample.\n",
    "\n",
    "Sequence run accession IDs can be used to download sequence data, using the 'prefetch' tool of the SRA-toolkit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "\n",
    "# Use the correct argument name: s3_staging_dir\n",
    "conn = connect(s3_staging_dir='s3://sra-data-athena/', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawler sra_crawler started.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the Glue client\n",
    "glue_client = boto3.client('glue', region_name='us-east-1')\n",
    "\n",
    "# Run the crawler\n",
    "crawler_name = 'sra_crawler'  # Use your crawler's name\n",
    "glue_client.start_crawler(Name=crawler_name)\n",
    "\n",
    "print(f\"Crawler {crawler_name} started.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6491/3650172437.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>assay_type</th>\n",
       "      <th>center_name</th>\n",
       "      <th>consent</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>instrument</th>\n",
       "      <th>librarylayout</th>\n",
       "      <th>libraryselection</th>\n",
       "      <th>librarysource</th>\n",
       "      <th>...</th>\n",
       "      <th>geo_loc_name_sam</th>\n",
       "      <th>ena_first_public_run</th>\n",
       "      <th>ena_last_update_run</th>\n",
       "      <th>sample_name_sam</th>\n",
       "      <th>datastore_filetype</th>\n",
       "      <th>datastore_provider</th>\n",
       "      <th>datastore_region</th>\n",
       "      <th>attributes</th>\n",
       "      <th>jattr</th>\n",
       "      <th>run_file_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR13349122</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775146</td>\n",
       "      <td>GSM5004088</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004088}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004088\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR13349124</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775147</td>\n",
       "      <td>GSM5004089</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004089}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004089\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR13349130</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775150</td>\n",
       "      <td>GSM5004092</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004092}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004092\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR13349123</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775146</td>\n",
       "      <td>GSM5004088</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004088}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004088\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR13349133</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775151</td>\n",
       "      <td>GSM5004093</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004093}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004093\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SRR13349132</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775151</td>\n",
       "      <td>GSM5004093</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004093}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004093\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SRR13349128</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775149</td>\n",
       "      <td>GSM5004091</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004091}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004091\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SRR13349126</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775148</td>\n",
       "      <td>GSM5004090</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004090}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004090\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SRR13349131</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775150</td>\n",
       "      <td>GSM5004092</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004092}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004092\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SRR13349129</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775149</td>\n",
       "      <td>GSM5004091</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004091}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004091\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SRR13349127</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775148</td>\n",
       "      <td>GSM5004090</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004090}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004090\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SRR13349125</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775147</td>\n",
       "      <td>GSM5004089</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004089}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004089\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            acc assay_type center_name consent  experiment sample_name  \\\n",
       "0   SRR13349122    RNA-Seq         GEO  public  SRX9775146  GSM5004088   \n",
       "1   SRR13349124    RNA-Seq         GEO  public  SRX9775147  GSM5004089   \n",
       "2   SRR13349130    RNA-Seq         GEO  public  SRX9775150  GSM5004092   \n",
       "3   SRR13349123    RNA-Seq         GEO  public  SRX9775146  GSM5004088   \n",
       "4   SRR13349133    RNA-Seq         GEO  public  SRX9775151  GSM5004093   \n",
       "5   SRR13349132    RNA-Seq         GEO  public  SRX9775151  GSM5004093   \n",
       "6   SRR13349128    RNA-Seq         GEO  public  SRX9775149  GSM5004091   \n",
       "7   SRR13349126    RNA-Seq         GEO  public  SRX9775148  GSM5004090   \n",
       "8   SRR13349131    RNA-Seq         GEO  public  SRX9775150  GSM5004092   \n",
       "9   SRR13349129    RNA-Seq         GEO  public  SRX9775149  GSM5004091   \n",
       "10  SRR13349127    RNA-Seq         GEO  public  SRX9775148  GSM5004090   \n",
       "11  SRR13349125    RNA-Seq         GEO  public  SRX9775147  GSM5004089   \n",
       "\n",
       "             instrument librarylayout libraryselection   librarysource  ...  \\\n",
       "0   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "1   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "2   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "3   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "4   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "5   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "6   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "7   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "8   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "9   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "10  Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "11  Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "\n",
       "   geo_loc_name_sam ena_first_public_run ena_last_update_run sample_name_sam  \\\n",
       "0              None                 None                None            None   \n",
       "1              None                 None                None            None   \n",
       "2              None                 None                None            None   \n",
       "3              None                 None                None            None   \n",
       "4              None                 None                None            None   \n",
       "5              None                 None                None            None   \n",
       "6              None                 None                None            None   \n",
       "7              None                 None                None            None   \n",
       "8              None                 None                None            None   \n",
       "9              None                 None                None            None   \n",
       "10             None                 None                None            None   \n",
       "11             None                 None                None            None   \n",
       "\n",
       "      datastore_filetype datastore_provider  \\\n",
       "0   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "1   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "2   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "3   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "4   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "5   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "6   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "7   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "8   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "9   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "10  [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "11  [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "\n",
       "                            datastore_region  \\\n",
       "0   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "1   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "2   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "3   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "4   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "5   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "6   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "7   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "8   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "9   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "10  [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "11  [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "\n",
       "                                           attributes  \\\n",
       "0   [{k=geo_accession_exp, v=GSM5004088}, {k=bases...   \n",
       "1   [{k=geo_accession_exp, v=GSM5004089}, {k=bases...   \n",
       "2   [{k=geo_accession_exp, v=GSM5004092}, {k=bases...   \n",
       "3   [{k=geo_accession_exp, v=GSM5004088}, {k=bases...   \n",
       "4   [{k=geo_accession_exp, v=GSM5004093}, {k=bases...   \n",
       "5   [{k=geo_accession_exp, v=GSM5004093}, {k=bases...   \n",
       "6   [{k=geo_accession_exp, v=GSM5004091}, {k=bases...   \n",
       "7   [{k=geo_accession_exp, v=GSM5004090}, {k=bases...   \n",
       "8   [{k=geo_accession_exp, v=GSM5004092}, {k=bases...   \n",
       "9   [{k=geo_accession_exp, v=GSM5004091}, {k=bases...   \n",
       "10  [{k=geo_accession_exp, v=GSM5004090}, {k=bases...   \n",
       "11  [{k=geo_accession_exp, v=GSM5004089}, {k=bases...   \n",
       "\n",
       "                                                jattr  run_file_version  \n",
       "0   {\"geo_accession_exp\": [\"GSM5004088\"], \"bases\":...                 1  \n",
       "1   {\"geo_accession_exp\": [\"GSM5004089\"], \"bases\":...                 1  \n",
       "2   {\"geo_accession_exp\": [\"GSM5004092\"], \"bases\":...                 1  \n",
       "3   {\"geo_accession_exp\": [\"GSM5004088\"], \"bases\":...                 1  \n",
       "4   {\"geo_accession_exp\": [\"GSM5004093\"], \"bases\":...                 1  \n",
       "5   {\"geo_accession_exp\": [\"GSM5004093\"], \"bases\":...                 1  \n",
       "6   {\"geo_accession_exp\": [\"GSM5004091\"], \"bases\":...                 1  \n",
       "7   {\"geo_accession_exp\": [\"GSM5004090\"], \"bases\":...                 1  \n",
       "8   {\"geo_accession_exp\": [\"GSM5004092\"], \"bases\":...                 1  \n",
       "9   {\"geo_accession_exp\": [\"GSM5004091\"], \"bases\":...                 1  \n",
       "10  {\"geo_accession_exp\": [\"GSM5004090\"], \"bases\":...                 1  \n",
       "11  {\"geo_accession_exp\": [\"GSM5004089\"], \"bases\":...                 1  \n",
       "\n",
       "[12 rows x 37 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM AwsDataCatalog.srametadata.metadata\n",
    "WHERE organism = 'Mycobacteroides chelonae' \n",
    "AND acc LIKE '%SRR133491%'\n",
    "\"\"\"\n",
    "df = pd.read_sql(\n",
    "    query, conn\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR13349122\n",
      "SRR13349124\n",
      "SRR13349130\n",
      "SRR13349123\n",
      "SRR13349133\n",
      "SRR13349132\n",
      "SRR13349128\n",
      "SRR13349126\n",
      "SRR13349131\n",
      "SRR13349129\n",
      "SRR13349127\n",
      "SRR13349125"
     ]
    }
   ],
   "source": [
    "#write the SRR column to a text file\n",
    "with open('accs.txt', 'w') as f:\n",
    "    accs = df['acc'].to_string(header=False, index=False)\n",
    "    f.write(accs)\n",
    "    \n",
    "#print the text file\n",
    "!cat accs.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-13T06:29:49 prefetch.3.1.1: 1) Resolving 'SRR13349123'...\n",
      "2024-09-13T06:29:49 prefetch.3.1.1: Current preference is set to retrieve SRA Normalized Format files with full base quality scores\n",
      "2024-09-13T06:29:50 prefetch.3.1.1: 1) Downloading 'SRR13349123'...\n",
      "2024-09-13T06:29:50 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:29:50 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:30:14 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:30:16 prefetch.3.1.1:  'SRR13349123' is valid: 641070152 bytes were streamed from 641060440\n",
      "2024-09-13T06:30:16 prefetch.3.1.1: 1) 'SRR13349123' was downloaded successfully\n",
      "2024-09-13T06:30:16 prefetch.3.1.1: 'SRR13349123' has 0 dependencies\n"
     ]
    }
   ],
   "source": [
    "#the 'prefetch' command downloads an SRA file.\n",
    "!prefetch SRR13349123 -O data/raw_fastq -f yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the command for downloading a single SRA file using an acecssion ID 'SRR13349123'\n",
    "\n",
    "Notice the SRA archives sequence files in the SRA format. \n",
    "Typically genome workflows process data in the form of zipped or unzipped .fastq, or .fasta files\n",
    "So before we move on, we need to convert the files from .sra to .fastq.\n",
    "\n",
    "There are multiple ways to do this. \n",
    "\n",
    "Included in the sra toolskit are fastq-dump and fasterq-dump. These convert SRA to FASTQ.\n",
    "\n",
    "If you use fasterq-dump, its recommended to zip your fastq files after they are created.\n",
    "\n",
    "There is also a tool called 'parallel-fastq-dump' which supports zipping the fastq files automatically into fastq.gz files.\n",
    "\n",
    "The below code may take approximately 15 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spots read      : 11,165,256\n",
      "reads read      : 22,330,512\n",
      "reads written   : 22,330,512\n"
     ]
    }
   ],
   "source": [
    "#convert sra to fastq\n",
    "!fasterq-dump data/raw_fastq/SRR13349123 -f -O data/raw_fastq/\n",
    "#compress fastq to fastq.gz to save space\n",
    "!gzip data/raw_fastq/SRR13349123_1.fastq\n",
    "!gzip data/raw_fastq/SRR13349123_2.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 3.3 Downloading multiple files using the SRA-toolkit.\n",
    "\n",
    "Often one wants to, as in our case, wish to download multiple runs at once.\n",
    "\n",
    "To aid in this, SRA-tools supports batch downloading. This is why we created the text file earlier.\n",
    "\n",
    "We can download multiple SRA files using a single line of code by using our list SRA IDs, and inputting that into the prefetch command.\n",
    "\n",
    "And then feed that list into the sra-toolkit prefetch command. Note, it may take some time to download all the fastq files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-13T06:43:40 prefetch.3.1.1: 1) Resolving 'SRR13349122'...\n",
      "2024-09-13T06:43:41 prefetch.3.1.1: Current preference is set to retrieve SRA Normalized Format files with full base quality scores\n",
      "2024-09-13T06:43:41 prefetch.3.1.1: 1) Downloading 'SRR13349122'...\n",
      "2024-09-13T06:43:41 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:43:41 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:44:05 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:44:06 prefetch.3.1.1:  'SRR13349122' is valid: 675618606 bytes were streamed from 675611406\n",
      "2024-09-13T06:44:06 prefetch.3.1.1: 1) 'SRR13349122' was downloaded successfully\n",
      "2024-09-13T06:44:06 prefetch.3.1.1: 'SRR13349122' has 0 dependencies\n",
      "2024-09-13T06:44:06 prefetch.3.1.1: 2) Resolving 'SRR13349124'...\n",
      "2024-09-13T06:44:06 prefetch.3.1.1: 2) Downloading 'SRR13349124'...\n",
      "2024-09-13T06:44:06 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:44:06 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:44:31 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:44:33 prefetch.3.1.1:  'SRR13349124' is valid: 671244393 bytes were streamed from 671237438\n",
      "2024-09-13T06:44:33 prefetch.3.1.1: 2) 'SRR13349124' was downloaded successfully\n",
      "2024-09-13T06:44:33 prefetch.3.1.1: 'SRR13349124' has 0 dependencies\n",
      "2024-09-13T06:44:33 prefetch.3.1.1: 3) Resolving 'SRR13349130'...\n",
      "2024-09-13T06:44:33 prefetch.3.1.1: 3) Downloading 'SRR13349130'...\n",
      "2024-09-13T06:44:33 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:44:33 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:44:57 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:44:58 prefetch.3.1.1:  'SRR13349130' is valid: 633040261 bytes were streamed from 633032439\n",
      "2024-09-13T06:44:58 prefetch.3.1.1: 3) 'SRR13349130' was downloaded successfully\n",
      "2024-09-13T06:44:58 prefetch.3.1.1: 'SRR13349130' has 0 dependencies\n",
      "2024-09-13T06:44:58 prefetch.3.1.1: 4) Resolving 'SRR13349123'...\n",
      "2024-09-13T06:44:59 prefetch.3.1.1: 4) Downloading 'SRR13349123'...\n",
      "2024-09-13T06:44:59 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:44:59 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:45:20 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:45:22 prefetch.3.1.1:  'SRR13349123' is valid: 641070152 bytes were streamed from 641069064\n",
      "2024-09-13T06:45:22 prefetch.3.1.1: 4) 'SRR13349123' was downloaded successfully\n",
      "2024-09-13T06:45:22 prefetch.3.1.1: 'SRR13349123' has 0 dependencies\n",
      "2024-09-13T06:45:22 prefetch.3.1.1: 5) Resolving 'SRR13349133'...\n",
      "2024-09-13T06:45:22 prefetch.3.1.1: 5) Downloading 'SRR13349133'...\n",
      "2024-09-13T06:45:22 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:45:22 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:45:46 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:45:48 prefetch.3.1.1:  'SRR13349133' is valid: 665312876 bytes were streamed from 665297439\n",
      "2024-09-13T06:45:48 prefetch.3.1.1: 5) 'SRR13349133' was downloaded successfully\n",
      "2024-09-13T06:45:48 prefetch.3.1.1: 'SRR13349133' has 0 dependencies\n",
      "2024-09-13T06:45:48 prefetch.3.1.1: 6) Resolving 'SRR13349132'...\n",
      "2024-09-13T06:45:48 prefetch.3.1.1: 6) Downloading 'SRR13349132'...\n",
      "2024-09-13T06:45:48 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:45:48 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:46:13 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:46:15 prefetch.3.1.1:  'SRR13349132' is valid: 706295513 bytes were streamed from 706283440\n",
      "2024-09-13T06:46:15 prefetch.3.1.1: 6) 'SRR13349132' was downloaded successfully\n",
      "2024-09-13T06:46:15 prefetch.3.1.1: 'SRR13349132' has 0 dependencies\n",
      "2024-09-13T06:46:15 prefetch.3.1.1: 7) Resolving 'SRR13349128'...\n",
      "2024-09-13T06:46:15 prefetch.3.1.1: 7) Downloading 'SRR13349128'...\n",
      "2024-09-13T06:46:15 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:46:15 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:46:43 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:46:45 prefetch.3.1.1:  'SRR13349128' is valid: 788638616 bytes were streamed from 788633439\n",
      "2024-09-13T06:46:45 prefetch.3.1.1: 7) 'SRR13349128' was downloaded successfully\n",
      "2024-09-13T06:46:45 prefetch.3.1.1: 'SRR13349128' has 0 dependencies\n",
      "2024-09-13T06:46:45 prefetch.3.1.1: 8) Resolving 'SRR13349126'...\n",
      "2024-09-13T06:46:45 prefetch.3.1.1: 8) Downloading 'SRR13349126'...\n",
      "2024-09-13T06:46:45 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:46:45 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:47:12 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:47:13 prefetch.3.1.1:  'SRR13349126' is valid: 773480091 bytes were streamed from 773468441\n",
      "2024-09-13T06:47:13 prefetch.3.1.1: 8) 'SRR13349126' was downloaded successfully\n",
      "2024-09-13T06:47:13 prefetch.3.1.1: 'SRR13349126' has 0 dependencies\n",
      "2024-09-13T06:47:13 prefetch.3.1.1: 9) Resolving 'SRR13349131'...\n",
      "2024-09-13T06:47:14 prefetch.3.1.1: 9) Downloading 'SRR13349131'...\n",
      "2024-09-13T06:47:14 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:47:14 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:47:34 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:47:36 prefetch.3.1.1:  'SRR13349131' is valid: 610217382 bytes were streamed from 610208438\n",
      "2024-09-13T06:47:36 prefetch.3.1.1: 9) 'SRR13349131' was downloaded successfully\n",
      "2024-09-13T06:47:36 prefetch.3.1.1: 'SRR13349131' has 0 dependencies\n",
      "2024-09-13T06:47:36 prefetch.3.1.1: 10) Resolving 'SRR13349129'...\n",
      "2024-09-13T06:47:36 prefetch.3.1.1: 10) Downloading 'SRR13349129'...\n",
      "2024-09-13T06:47:36 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:47:36 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:48:00 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:48:03 prefetch.3.1.1:  'SRR13349129' is valid: 743064450 bytes were streamed from 743057418\n",
      "2024-09-13T06:48:03 prefetch.3.1.1: 10) 'SRR13349129' was downloaded successfully\n",
      "2024-09-13T06:48:03 prefetch.3.1.1: 'SRR13349129' has 0 dependencies\n",
      "2024-09-13T06:48:03 prefetch.3.1.1: 11) Resolving 'SRR13349127'...\n",
      "2024-09-13T06:48:03 prefetch.3.1.1: 11) Downloading 'SRR13349127'...\n",
      "2024-09-13T06:48:03 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:48:03 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:48:31 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:48:32 prefetch.3.1.1:  'SRR13349127' is valid: 733838051 bytes were streamed from 733834607\n",
      "2024-09-13T06:48:32 prefetch.3.1.1: 11) 'SRR13349127' was downloaded successfully\n",
      "2024-09-13T06:48:32 prefetch.3.1.1: 'SRR13349127' has 0 dependencies\n",
      "2024-09-13T06:48:32 prefetch.3.1.1: 12) Resolving 'SRR13349125'...\n",
      "2024-09-13T06:48:33 prefetch.3.1.1: 12) Downloading 'SRR13349125'...\n",
      "2024-09-13T06:48:33 prefetch.3.1.1:  SRA Normalized Format file is being retrieved\n",
      "2024-09-13T06:48:33 prefetch.3.1.1:  Downloading via HTTPS...\n",
      "2024-09-13T06:48:55 prefetch.3.1.1:  HTTPS download succeed\n",
      "2024-09-13T06:48:56 prefetch.3.1.1:  'SRR13349125' is valid: 632540004 bytes were streamed from 632537438\n",
      "2024-09-13T06:48:56 prefetch.3.1.1: 12) 'SRR13349125' was downloaded successfully\n",
      "2024-09-13T06:48:56 prefetch.3.1.1: 'SRR13349125' has 0 dependencies\n"
     ]
    }
   ],
   "source": [
    "!prefetch --option-file accs.txt -O data/raw_fastq -f yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3.4 Converting Multiple SRA files to Fastq\n",
    "\n",
    "Fasterq-dump does not natively support batch converting of files.\n",
    "\n",
    "There are several ways we can get around this.\n",
    "\n",
    "For instance, one could use loops, or utilize piping.\n",
    "\n",
    "The below code uses a 'for' loop to iterate through all the accession IDs in our accs.txt file.\n",
    "\n",
    "It also adds includes various flags\n",
    "\n",
    "-e for cpu threads\n",
    "-m for maximum memory useage\n",
    "-f to force overwrite\n",
    "-O output directory. \n",
    "\n",
    "This process should take about 35 minutes or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spots read      : 10,827,590\n",
      "reads read      : 21,655,180\n",
      "reads written   : 21,655,180\n",
      "spots read      : 10,727,273\n",
      "reads read      : 21,454,546\n",
      "reads written   : 21,454,546\n",
      "spots read      : 10,083,015\n",
      "reads read      : 20,166,030\n",
      "reads written   : 20,166,030\n",
      "spots read      : 11,165,256\n",
      "reads read      : 22,330,512\n",
      "reads written   : 22,330,512\n",
      "spots read      : 11,603,881\n",
      "reads read      : 23,207,762\n",
      "reads written   : 23,207,762\n",
      "spots read      : 11,341,357\n",
      "reads read      : 22,682,714\n",
      "reads written   : 22,682,714\n",
      "spots read      : 12,652,387\n",
      "reads read      : 25,304,774\n",
      "reads written   : 25,304,774\n",
      "spots read      : 12,267,497\n",
      "reads read      : 24,534,994\n",
      "reads written   : 24,534,994\n",
      "spots read      : 10,491,160\n",
      "reads read      : 20,982,320\n",
      "reads written   : 20,982,320\n",
      "spots read      : 12,961,793\n",
      "reads read      : 25,923,586\n",
      "reads written   : 25,923,586\n",
      "spots read      : 12,563,032\n",
      "reads read      : 25,126,064\n",
      "reads written   : 25,126,064\n",
      "spots read      : 10,992,686\n",
      "reads read      : 21,985,372\n",
      "reads written   : 21,985,372\n"
     ]
    }
   ],
   "source": [
    "!for x in `cat accs.txt`; do fasterq-dump -f -O data/raw_fastq -e $THREADS -m 4G data/raw_fastq/$x/$x.sra; done\n",
    "\n",
    "##example of how to alternatively do the above process with parallel-fastq-dump using piping\n",
    "#!cat accs.txt | xargs -I {} parallel-fastq-dump -O data/raw_fastq/ --tmpdir . --threads $THREADS --gzip --split-files --sra-id {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, it is good practice to turn .fastq files into .fastq.gz files to save space.\n",
    "\n",
    "In our case, we will actually need to concatenate the fastq files later on, and so will zip after this.\n",
    "\n",
    "The no redundant SRA files can also be deleted to save more space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘data/raw_fastq/SRR13349124’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349123’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349130’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349132’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349131’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349127’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349125’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349128’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349129’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349133’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349126’: No such file or directory\n",
      "find: ‘data/raw_fastq/SRR13349122’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#find and delete all SRR subfolders in the raw_fastq directory\n",
    "!find data/raw_fastq -type d -name 'SRR*' -exec rm -rf {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 4: Copy reference transcriptome files that will be used by Salmon using E-Direct\n",
    "\n",
    "Salmon is a tool that aligns RNA-Seq reads to a transcriptome.\n",
    "\n",
    "So we will need a transcriptome reference file.\n",
    "\n",
    "To get one, we can search through the NCBI assembly database, find an assembly, and download transcriptome reference files from that assembly using FTP links.\n",
    "\n",
    "For instance, we will use the <a href='https://www.ncbi.nlm.nih.gov/assembly/GCF_001632805.1'>ASM163280v1</a> refseq assembly, found by searching through the NCBI assembly database. The FTP links can be accessed through the website in various ways, one way is to click the 'FTP directory for RefSeq assembly' link, found under 'Access the data', section.\n",
    "\n",
    "Alternatively, if one were inclined, one could take the less common route and perform this through the NCBI command line tool suite called 'Entrez Direct' (EDirect).\n",
    "\n",
    "This is an intricate and complicated set of tools, with many ways to do any one thing.\n",
    "\n",
    "Below is an example of using an eDirect search query with a refseq identifier to obtain the relevant FTP directory, and then using that to download desired reference files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1436k  100 1436k    0     0  1866k      0 --:--:-- --:--:-- --:--:-- 1866k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  397k  100  397k    0     0   714k      0 --:--:-- --:--:-- --:--:--  715k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  225k  100  225k    0     0   434k      0 --:--:-- --:--:-- --:--:--  434k\n"
     ]
    }
   ],
   "source": [
    "#parse for the ftp link and download the genome reference fasta file\n",
    "\n",
    "!esearch -db assembly -query GCF_001632805.1 | efetch -format docsum \\\n",
    "| xtract -pattern DocumentSummary -element FtpPath_RefSeq \\\n",
    "| awk -F\"/\" '{print \"curl -o data/reference/\"$NF\"_genomic.fna.gz \" $0\"/\"$NF\"_genomic.fna.gz\"}' \\\n",
    "| bash\n",
    "\n",
    "#parse for the ftp link and download the gtf reference fasta file\n",
    "\n",
    "!esearch -db assembly -query GCF_001632805.1 | efetch -format docsum \\\n",
    "| xtract -pattern DocumentSummary -element FtpPath_RefSeq \\\n",
    "| awk -F\"/\" '{print \"curl -o data/reference/\"$NF\"_genomic.gff.gz \" $0\"/\"$NF\"_genomic.gff.gz\"}' \\\n",
    "| bash\n",
    "\n",
    "# parse for the ftp link and download the feature-table reference file \n",
    "# (for later use for merging readcounts with gene names in R code).\n",
    "\n",
    "!esearch -db assembly -query GCF_001632805.1 | efetch -format docsum \\\n",
    "| xtract -pattern DocumentSummary -element FtpPath_RefSeq \\\n",
    "| awk -F\"/\" '{print \"curl -o data/reference/\"$NF\"_feature_table.txt.gz \" $0\"/\"$NF\"_feature_table.txt.gz\"}' \\\n",
    "| bash\n",
    "\n",
    "\n",
    "#unzip the compresseed fasta files\n",
    "\n",
    "!gzip -d data/reference/*.gz --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can use a tool called gffread to create a transcriptome reference file using the gtf and genome files we downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA index file data/reference/GCF_001632805.1_ASM163280v1_genomic.fna.fai created.\n"
     ]
    }
   ],
   "source": [
    "!gffread -w data/reference/GCF_001632805.1_transcriptome_reference.fa -g data/reference/GCF_001632805.1_ASM163280v1_genomic.fna data/reference/GCF_001632805.1_ASM163280v1_genomic.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also recommended to include the full genome at the end of the transcriptome reference file, for the purpose of performing a 'decoy-aware' mapping, more information about which can be found in the Salmon documentation.\n",
    "\n",
    "To alert the tool to the presence of this, we will also create a 'decoy file', which salmon needs pointed towards the full genome sequence in our transcriptome reference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat data/reference/GCF_001632805.1_transcriptome_reference.fa > data/reference/GCF_001632805.1_transcriptome_reference_w_decoy.fa\n",
    "!echo >> data/reference/GCF_001632805.1_transcriptome_reference_w_decoy.fa\n",
    "!cat data/reference/GCF_001632805.1_ASM163280v1_genomic.fna >> data/reference/GCF_001632805.1_transcriptome_reference_w_decoy.fa\n",
    "!echo \"NZ_CP007220.1\" > data/reference/decoys.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: Run FastQC\n",
    "FastQC is an invaluable tool that allows you to evaluate whether there are problems with a set of reads. For example, it will provide a report of whether there is any bias in the sequence composition of the reads.\n",
    "\n",
    "The below code may take around 25 minutes to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n",
      "Started analysis of SRR13349122_1.fastq\n",
      "Approx 5% complete for SRR13349122_1.fastq\n",
      "Approx 10% complete for SRR13349122_1.fastq\n",
      "Approx 15% complete for SRR13349122_1.fastq\n",
      "Approx 20% complete for SRR13349122_1.fastq\n",
      "Approx 25% complete for SRR13349122_1.fastq\n",
      "Approx 30% complete for SRR13349122_1.fastq\n",
      "Approx 35% complete for SRR13349122_1.fastq\n",
      "Approx 40% complete for SRR13349122_1.fastq\n",
      "Approx 45% complete for SRR13349122_1.fastq\n",
      "Approx 50% complete for SRR13349122_1.fastq\n",
      "Approx 55% complete for SRR13349122_1.fastq\n",
      "Approx 60% complete for SRR13349122_1.fastq\n",
      "Approx 65% complete for SRR13349122_1.fastq\n",
      "Approx 70% complete for SRR13349122_1.fastq\n",
      "Approx 75% complete for SRR13349122_1.fastq\n",
      "Approx 80% complete for SRR13349122_1.fastq\n",
      "Approx 85% complete for SRR13349122_1.fastq\n",
      "Approx 90% complete for SRR13349122_1.fastq\n",
      "Approx 95% complete for SRR13349122_1.fastq\n",
      "Analysis complete for SRR13349122_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349124_1.fastq\n",
      "Approx 5% complete for SRR13349124_1.fastq\n",
      "Approx 10% complete for SRR13349124_1.fastq\n",
      "Approx 15% complete for SRR13349124_1.fastq\n",
      "Approx 20% complete for SRR13349124_1.fastq\n",
      "Approx 25% complete for SRR13349124_1.fastq\n",
      "Approx 30% complete for SRR13349124_1.fastq\n",
      "Approx 35% complete for SRR13349124_1.fastq\n",
      "Approx 40% complete for SRR13349124_1.fastq\n",
      "Approx 45% complete for SRR13349124_1.fastq\n",
      "Approx 50% complete for SRR13349124_1.fastq\n",
      "Approx 55% complete for SRR13349124_1.fastq\n",
      "Approx 60% complete for SRR13349124_1.fastq\n",
      "Approx 65% complete for SRR13349124_1.fastq\n",
      "Approx 70% complete for SRR13349124_1.fastq\n",
      "Approx 75% complete for SRR13349124_1.fastq\n",
      "Approx 80% complete for SRR13349124_1.fastq\n",
      "Approx 85% complete for SRR13349124_1.fastq\n",
      "Approx 90% complete for SRR13349124_1.fastq\n",
      "Approx 95% complete for SRR13349124_1.fastq\n",
      "Analysis complete for SRR13349124_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349130_1.fastq\n",
      "Approx 5% complete for SRR13349130_1.fastq\n",
      "Approx 10% complete for SRR13349130_1.fastq\n",
      "Approx 15% complete for SRR13349130_1.fastq\n",
      "Approx 20% complete for SRR13349130_1.fastq\n",
      "Approx 25% complete for SRR13349130_1.fastq\n",
      "Approx 30% complete for SRR13349130_1.fastq\n",
      "Approx 35% complete for SRR13349130_1.fastq\n",
      "Approx 40% complete for SRR13349130_1.fastq\n",
      "Approx 45% complete for SRR13349130_1.fastq\n",
      "Approx 50% complete for SRR13349130_1.fastq\n",
      "Approx 55% complete for SRR13349130_1.fastq\n",
      "Approx 60% complete for SRR13349130_1.fastq\n",
      "Approx 65% complete for SRR13349130_1.fastq\n",
      "Approx 70% complete for SRR13349130_1.fastq\n",
      "Approx 75% complete for SRR13349130_1.fastq\n",
      "Approx 80% complete for SRR13349130_1.fastq\n",
      "Approx 85% complete for SRR13349130_1.fastq\n",
      "Approx 90% complete for SRR13349130_1.fastq\n",
      "Approx 95% complete for SRR13349130_1.fastq\n",
      "Analysis complete for SRR13349130_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349123_1.fastq\n",
      "Approx 5% complete for SRR13349123_1.fastq\n",
      "Approx 10% complete for SRR13349123_1.fastq\n",
      "Approx 15% complete for SRR13349123_1.fastq\n",
      "Approx 20% complete for SRR13349123_1.fastq\n",
      "Approx 25% complete for SRR13349123_1.fastq\n",
      "Approx 30% complete for SRR13349123_1.fastq\n",
      "Approx 35% complete for SRR13349123_1.fastq\n",
      "Approx 40% complete for SRR13349123_1.fastq\n",
      "Approx 45% complete for SRR13349123_1.fastq\n",
      "Approx 50% complete for SRR13349123_1.fastq\n",
      "Approx 55% complete for SRR13349123_1.fastq\n",
      "Approx 60% complete for SRR13349123_1.fastq\n",
      "Approx 65% complete for SRR13349123_1.fastq\n",
      "Approx 70% complete for SRR13349123_1.fastq\n",
      "Approx 75% complete for SRR13349123_1.fastq\n",
      "Approx 80% complete for SRR13349123_1.fastq\n",
      "Approx 85% complete for SRR13349123_1.fastq\n",
      "Approx 90% complete for SRR13349123_1.fastq\n",
      "Approx 95% complete for SRR13349123_1.fastq\n",
      "Analysis complete for SRR13349123_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349133_1.fastq\n",
      "Approx 5% complete for SRR13349133_1.fastq\n",
      "Approx 10% complete for SRR13349133_1.fastq\n",
      "Approx 15% complete for SRR13349133_1.fastq\n",
      "Approx 20% complete for SRR13349133_1.fastq\n",
      "Approx 25% complete for SRR13349133_1.fastq\n",
      "Approx 30% complete for SRR13349133_1.fastq\n",
      "Approx 35% complete for SRR13349133_1.fastq\n",
      "Approx 40% complete for SRR13349133_1.fastq\n",
      "Approx 45% complete for SRR13349133_1.fastq\n",
      "Approx 50% complete for SRR13349133_1.fastq\n",
      "Approx 55% complete for SRR13349133_1.fastq\n",
      "Approx 60% complete for SRR13349133_1.fastq\n",
      "Approx 65% complete for SRR13349133_1.fastq\n",
      "Approx 70% complete for SRR13349133_1.fastq\n",
      "Approx 75% complete for SRR13349133_1.fastq\n",
      "Approx 80% complete for SRR13349133_1.fastq\n",
      "Approx 85% complete for SRR13349133_1.fastq\n",
      "Approx 90% complete for SRR13349133_1.fastq\n",
      "Approx 95% complete for SRR13349133_1.fastq\n",
      "Analysis complete for SRR13349133_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349132_1.fastq\n",
      "Approx 5% complete for SRR13349132_1.fastq\n",
      "Approx 10% complete for SRR13349132_1.fastq\n",
      "Approx 15% complete for SRR13349132_1.fastq\n",
      "Approx 20% complete for SRR13349132_1.fastq\n",
      "Approx 25% complete for SRR13349132_1.fastq\n",
      "Approx 30% complete for SRR13349132_1.fastq\n",
      "Approx 35% complete for SRR13349132_1.fastq\n",
      "Approx 40% complete for SRR13349132_1.fastq\n",
      "Approx 45% complete for SRR13349132_1.fastq\n",
      "Approx 50% complete for SRR13349132_1.fastq\n",
      "Approx 55% complete for SRR13349132_1.fastq\n",
      "Approx 60% complete for SRR13349132_1.fastq\n",
      "Approx 65% complete for SRR13349132_1.fastq\n",
      "Approx 70% complete for SRR13349132_1.fastq\n",
      "Approx 75% complete for SRR13349132_1.fastq\n",
      "Approx 80% complete for SRR13349132_1.fastq\n",
      "Approx 85% complete for SRR13349132_1.fastq\n",
      "Approx 90% complete for SRR13349132_1.fastq\n",
      "Approx 95% complete for SRR13349132_1.fastq\n",
      "Analysis complete for SRR13349132_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349128_1.fastq\n",
      "Approx 5% complete for SRR13349128_1.fastq\n",
      "Approx 10% complete for SRR13349128_1.fastq\n",
      "Approx 15% complete for SRR13349128_1.fastq\n",
      "Approx 20% complete for SRR13349128_1.fastq\n",
      "Approx 25% complete for SRR13349128_1.fastq\n",
      "Approx 30% complete for SRR13349128_1.fastq\n",
      "Approx 35% complete for SRR13349128_1.fastq\n",
      "Approx 40% complete for SRR13349128_1.fastq\n",
      "Approx 45% complete for SRR13349128_1.fastq\n",
      "Approx 50% complete for SRR13349128_1.fastq\n",
      "Approx 55% complete for SRR13349128_1.fastq\n",
      "Approx 60% complete for SRR13349128_1.fastq\n",
      "Approx 65% complete for SRR13349128_1.fastq\n",
      "Approx 70% complete for SRR13349128_1.fastq\n",
      "Approx 75% complete for SRR13349128_1.fastq\n",
      "Approx 80% complete for SRR13349128_1.fastq\n",
      "Approx 85% complete for SRR13349128_1.fastq\n",
      "Approx 90% complete for SRR13349128_1.fastq\n",
      "Approx 95% complete for SRR13349128_1.fastq\n",
      "Analysis complete for SRR13349128_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349126_1.fastq\n",
      "Approx 5% complete for SRR13349126_1.fastq\n",
      "Approx 10% complete for SRR13349126_1.fastq\n",
      "Approx 15% complete for SRR13349126_1.fastq\n",
      "Approx 20% complete for SRR13349126_1.fastq\n",
      "Approx 25% complete for SRR13349126_1.fastq\n",
      "Approx 30% complete for SRR13349126_1.fastq\n",
      "Approx 35% complete for SRR13349126_1.fastq\n",
      "Approx 40% complete for SRR13349126_1.fastq\n",
      "Approx 45% complete for SRR13349126_1.fastq\n",
      "Approx 50% complete for SRR13349126_1.fastq\n",
      "Approx 55% complete for SRR13349126_1.fastq\n",
      "Approx 60% complete for SRR13349126_1.fastq\n",
      "Approx 65% complete for SRR13349126_1.fastq\n",
      "Approx 70% complete for SRR13349126_1.fastq\n",
      "Approx 75% complete for SRR13349126_1.fastq\n",
      "Approx 80% complete for SRR13349126_1.fastq\n",
      "Approx 85% complete for SRR13349126_1.fastq\n",
      "Approx 90% complete for SRR13349126_1.fastq\n",
      "Approx 95% complete for SRR13349126_1.fastq\n",
      "Analysis complete for SRR13349126_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349131_1.fastq\n",
      "Approx 5% complete for SRR13349131_1.fastq\n",
      "Approx 10% complete for SRR13349131_1.fastq\n",
      "Approx 15% complete for SRR13349131_1.fastq\n",
      "Approx 20% complete for SRR13349131_1.fastq\n",
      "Approx 25% complete for SRR13349131_1.fastq\n",
      "Approx 30% complete for SRR13349131_1.fastq\n",
      "Approx 35% complete for SRR13349131_1.fastq\n",
      "Approx 40% complete for SRR13349131_1.fastq\n",
      "Approx 45% complete for SRR13349131_1.fastq\n",
      "Approx 50% complete for SRR13349131_1.fastq\n",
      "Approx 55% complete for SRR13349131_1.fastq\n",
      "Approx 60% complete for SRR13349131_1.fastq\n",
      "Approx 65% complete for SRR13349131_1.fastq\n",
      "Approx 70% complete for SRR13349131_1.fastq\n",
      "Approx 75% complete for SRR13349131_1.fastq\n",
      "Approx 80% complete for SRR13349131_1.fastq\n",
      "Approx 85% complete for SRR13349131_1.fastq\n",
      "Approx 90% complete for SRR13349131_1.fastq\n",
      "Approx 95% complete for SRR13349131_1.fastq\n",
      "Analysis complete for SRR13349131_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349129_1.fastq\n",
      "Approx 5% complete for SRR13349129_1.fastq\n",
      "Approx 10% complete for SRR13349129_1.fastq\n",
      "Approx 15% complete for SRR13349129_1.fastq\n",
      "Approx 20% complete for SRR13349129_1.fastq\n",
      "Approx 25% complete for SRR13349129_1.fastq\n",
      "Approx 30% complete for SRR13349129_1.fastq\n",
      "Approx 35% complete for SRR13349129_1.fastq\n",
      "Approx 40% complete for SRR13349129_1.fastq\n",
      "Approx 45% complete for SRR13349129_1.fastq\n",
      "Approx 50% complete for SRR13349129_1.fastq\n",
      "Approx 55% complete for SRR13349129_1.fastq\n",
      "Approx 60% complete for SRR13349129_1.fastq\n",
      "Approx 65% complete for SRR13349129_1.fastq\n",
      "Approx 70% complete for SRR13349129_1.fastq\n",
      "Approx 75% complete for SRR13349129_1.fastq\n",
      "Approx 80% complete for SRR13349129_1.fastq\n",
      "Approx 85% complete for SRR13349129_1.fastq\n",
      "Approx 90% complete for SRR13349129_1.fastq\n",
      "Approx 95% complete for SRR13349129_1.fastq\n",
      "Analysis complete for SRR13349129_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349127_1.fastq\n",
      "Approx 5% complete for SRR13349127_1.fastq\n",
      "Approx 10% complete for SRR13349127_1.fastq\n",
      "Approx 15% complete for SRR13349127_1.fastq\n",
      "Approx 20% complete for SRR13349127_1.fastq\n",
      "Approx 25% complete for SRR13349127_1.fastq\n",
      "Approx 30% complete for SRR13349127_1.fastq\n",
      "Approx 35% complete for SRR13349127_1.fastq\n",
      "Approx 40% complete for SRR13349127_1.fastq\n",
      "Approx 45% complete for SRR13349127_1.fastq\n",
      "Approx 50% complete for SRR13349127_1.fastq\n",
      "Approx 55% complete for SRR13349127_1.fastq\n",
      "Approx 60% complete for SRR13349127_1.fastq\n",
      "Approx 65% complete for SRR13349127_1.fastq\n",
      "Approx 70% complete for SRR13349127_1.fastq\n",
      "Approx 75% complete for SRR13349127_1.fastq\n",
      "Approx 80% complete for SRR13349127_1.fastq\n",
      "Approx 85% complete for SRR13349127_1.fastq\n",
      "Approx 90% complete for SRR13349127_1.fastq\n",
      "Approx 95% complete for SRR13349127_1.fastq\n",
      "Analysis complete for SRR13349127_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349125_1.fastq\n",
      "Approx 5% complete for SRR13349125_1.fastq\n",
      "Approx 10% complete for SRR13349125_1.fastq\n",
      "Approx 15% complete for SRR13349125_1.fastq\n",
      "Approx 20% complete for SRR13349125_1.fastq\n",
      "Approx 25% complete for SRR13349125_1.fastq\n",
      "Approx 30% complete for SRR13349125_1.fastq\n",
      "Approx 35% complete for SRR13349125_1.fastq\n",
      "Approx 40% complete for SRR13349125_1.fastq\n",
      "Approx 45% complete for SRR13349125_1.fastq\n",
      "Approx 50% complete for SRR13349125_1.fastq\n",
      "Approx 55% complete for SRR13349125_1.fastq\n",
      "Approx 60% complete for SRR13349125_1.fastq\n",
      "Approx 65% complete for SRR13349125_1.fastq\n",
      "Approx 70% complete for SRR13349125_1.fastq\n",
      "Approx 75% complete for SRR13349125_1.fastq\n",
      "Approx 80% complete for SRR13349125_1.fastq\n",
      "Approx 85% complete for SRR13349125_1.fastq\n",
      "Approx 90% complete for SRR13349125_1.fastq\n",
      "Approx 95% complete for SRR13349125_1.fastq\n",
      "Analysis complete for SRR13349125_1.fastq\n",
      "null\n",
      "Started analysis of SRR13349122_2.fastq\n",
      "Approx 5% complete for SRR13349122_2.fastq\n",
      "Approx 10% complete for SRR13349122_2.fastq\n",
      "Approx 15% complete for SRR13349122_2.fastq\n",
      "Approx 20% complete for SRR13349122_2.fastq\n",
      "Approx 25% complete for SRR13349122_2.fastq\n",
      "Approx 30% complete for SRR13349122_2.fastq\n",
      "Approx 35% complete for SRR13349122_2.fastq\n",
      "Approx 40% complete for SRR13349122_2.fastq\n",
      "Approx 45% complete for SRR13349122_2.fastq\n",
      "Approx 50% complete for SRR13349122_2.fastq\n",
      "Approx 55% complete for SRR13349122_2.fastq\n",
      "Approx 60% complete for SRR13349122_2.fastq\n",
      "Approx 65% complete for SRR13349122_2.fastq\n",
      "Approx 70% complete for SRR13349122_2.fastq\n",
      "Approx 75% complete for SRR13349122_2.fastq\n",
      "Approx 80% complete for SRR13349122_2.fastq\n",
      "Approx 85% complete for SRR13349122_2.fastq\n",
      "Approx 90% complete for SRR13349122_2.fastq\n",
      "Approx 95% complete for SRR13349122_2.fastq\n",
      "Analysis complete for SRR13349122_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349124_2.fastq\n",
      "Approx 5% complete for SRR13349124_2.fastq\n",
      "Approx 10% complete for SRR13349124_2.fastq\n",
      "Approx 15% complete for SRR13349124_2.fastq\n",
      "Approx 20% complete for SRR13349124_2.fastq\n",
      "Approx 25% complete for SRR13349124_2.fastq\n",
      "Approx 30% complete for SRR13349124_2.fastq\n",
      "Approx 35% complete for SRR13349124_2.fastq\n",
      "Approx 40% complete for SRR13349124_2.fastq\n",
      "Approx 45% complete for SRR13349124_2.fastq\n",
      "Approx 50% complete for SRR13349124_2.fastq\n",
      "Approx 55% complete for SRR13349124_2.fastq\n",
      "Approx 60% complete for SRR13349124_2.fastq\n",
      "Approx 65% complete for SRR13349124_2.fastq\n",
      "Approx 70% complete for SRR13349124_2.fastq\n",
      "Approx 75% complete for SRR13349124_2.fastq\n",
      "Approx 80% complete for SRR13349124_2.fastq\n",
      "Approx 85% complete for SRR13349124_2.fastq\n",
      "Approx 90% complete for SRR13349124_2.fastq\n",
      "Approx 95% complete for SRR13349124_2.fastq\n",
      "Analysis complete for SRR13349124_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349130_2.fastq\n",
      "Approx 5% complete for SRR13349130_2.fastq\n",
      "Approx 10% complete for SRR13349130_2.fastq\n",
      "Approx 15% complete for SRR13349130_2.fastq\n",
      "Approx 20% complete for SRR13349130_2.fastq\n",
      "Approx 25% complete for SRR13349130_2.fastq\n",
      "Approx 30% complete for SRR13349130_2.fastq\n",
      "Approx 35% complete for SRR13349130_2.fastq\n",
      "Approx 40% complete for SRR13349130_2.fastq\n",
      "Approx 45% complete for SRR13349130_2.fastq\n",
      "Approx 50% complete for SRR13349130_2.fastq\n",
      "Approx 55% complete for SRR13349130_2.fastq\n",
      "Approx 60% complete for SRR13349130_2.fastq\n",
      "Approx 65% complete for SRR13349130_2.fastq\n",
      "Approx 70% complete for SRR13349130_2.fastq\n",
      "Approx 75% complete for SRR13349130_2.fastq\n",
      "Approx 80% complete for SRR13349130_2.fastq\n",
      "Approx 85% complete for SRR13349130_2.fastq\n",
      "Approx 90% complete for SRR13349130_2.fastq\n",
      "Approx 95% complete for SRR13349130_2.fastq\n",
      "Analysis complete for SRR13349130_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349123_2.fastq\n",
      "Approx 5% complete for SRR13349123_2.fastq\n",
      "Approx 10% complete for SRR13349123_2.fastq\n",
      "Approx 15% complete for SRR13349123_2.fastq\n",
      "Approx 20% complete for SRR13349123_2.fastq\n",
      "Approx 25% complete for SRR13349123_2.fastq\n",
      "Approx 30% complete for SRR13349123_2.fastq\n",
      "Approx 35% complete for SRR13349123_2.fastq\n",
      "Approx 40% complete for SRR13349123_2.fastq\n",
      "Approx 45% complete for SRR13349123_2.fastq\n",
      "Approx 50% complete for SRR13349123_2.fastq\n",
      "Approx 55% complete for SRR13349123_2.fastq\n",
      "Approx 60% complete for SRR13349123_2.fastq\n",
      "Approx 65% complete for SRR13349123_2.fastq\n",
      "Approx 70% complete for SRR13349123_2.fastq\n",
      "Approx 75% complete for SRR13349123_2.fastq\n",
      "Approx 80% complete for SRR13349123_2.fastq\n",
      "Approx 85% complete for SRR13349123_2.fastq\n",
      "Approx 90% complete for SRR13349123_2.fastq\n",
      "Approx 95% complete for SRR13349123_2.fastq\n",
      "Analysis complete for SRR13349123_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349133_2.fastq\n",
      "Approx 5% complete for SRR13349133_2.fastq\n",
      "Approx 10% complete for SRR13349133_2.fastq\n",
      "Approx 15% complete for SRR13349133_2.fastq\n",
      "Approx 20% complete for SRR13349133_2.fastq\n",
      "Approx 25% complete for SRR13349133_2.fastq\n",
      "Approx 30% complete for SRR13349133_2.fastq\n",
      "Approx 35% complete for SRR13349133_2.fastq\n",
      "Approx 40% complete for SRR13349133_2.fastq\n",
      "Approx 45% complete for SRR13349133_2.fastq\n",
      "Approx 50% complete for SRR13349133_2.fastq\n",
      "Approx 55% complete for SRR13349133_2.fastq\n",
      "Approx 60% complete for SRR13349133_2.fastq\n",
      "Approx 65% complete for SRR13349133_2.fastq\n",
      "Approx 70% complete for SRR13349133_2.fastq\n",
      "Approx 75% complete for SRR13349133_2.fastq\n",
      "Approx 80% complete for SRR13349133_2.fastq\n",
      "Approx 85% complete for SRR13349133_2.fastq\n",
      "Approx 90% complete for SRR13349133_2.fastq\n",
      "Approx 95% complete for SRR13349133_2.fastq\n",
      "Analysis complete for SRR13349133_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349132_2.fastq\n",
      "Approx 5% complete for SRR13349132_2.fastq\n",
      "Approx 10% complete for SRR13349132_2.fastq\n",
      "Approx 15% complete for SRR13349132_2.fastq\n",
      "Approx 20% complete for SRR13349132_2.fastq\n",
      "Approx 25% complete for SRR13349132_2.fastq\n",
      "Approx 30% complete for SRR13349132_2.fastq\n",
      "Approx 35% complete for SRR13349132_2.fastq\n",
      "Approx 40% complete for SRR13349132_2.fastq\n",
      "Approx 45% complete for SRR13349132_2.fastq\n",
      "Approx 50% complete for SRR13349132_2.fastq\n",
      "Approx 55% complete for SRR13349132_2.fastq\n",
      "Approx 60% complete for SRR13349132_2.fastq\n",
      "Approx 65% complete for SRR13349132_2.fastq\n",
      "Approx 70% complete for SRR13349132_2.fastq\n",
      "Approx 75% complete for SRR13349132_2.fastq\n",
      "Approx 80% complete for SRR13349132_2.fastq\n",
      "Approx 85% complete for SRR13349132_2.fastq\n",
      "Approx 90% complete for SRR13349132_2.fastq\n",
      "Approx 95% complete for SRR13349132_2.fastq\n",
      "Analysis complete for SRR13349132_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349128_2.fastq\n",
      "Approx 5% complete for SRR13349128_2.fastq\n",
      "Approx 10% complete for SRR13349128_2.fastq\n",
      "Approx 15% complete for SRR13349128_2.fastq\n",
      "Approx 20% complete for SRR13349128_2.fastq\n",
      "Approx 25% complete for SRR13349128_2.fastq\n",
      "Approx 30% complete for SRR13349128_2.fastq\n",
      "Approx 35% complete for SRR13349128_2.fastq\n",
      "Approx 40% complete for SRR13349128_2.fastq\n",
      "Approx 45% complete for SRR13349128_2.fastq\n",
      "Approx 50% complete for SRR13349128_2.fastq\n",
      "Approx 55% complete for SRR13349128_2.fastq\n",
      "Approx 60% complete for SRR13349128_2.fastq\n",
      "Approx 65% complete for SRR13349128_2.fastq\n",
      "Approx 70% complete for SRR13349128_2.fastq\n",
      "Approx 75% complete for SRR13349128_2.fastq\n",
      "Approx 80% complete for SRR13349128_2.fastq\n",
      "Approx 85% complete for SRR13349128_2.fastq\n",
      "Approx 90% complete for SRR13349128_2.fastq\n",
      "Approx 95% complete for SRR13349128_2.fastq\n",
      "Analysis complete for SRR13349128_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349126_2.fastq\n",
      "Approx 5% complete for SRR13349126_2.fastq\n",
      "Approx 10% complete for SRR13349126_2.fastq\n",
      "Approx 15% complete for SRR13349126_2.fastq\n",
      "Approx 20% complete for SRR13349126_2.fastq\n",
      "Approx 25% complete for SRR13349126_2.fastq\n",
      "Approx 30% complete for SRR13349126_2.fastq\n",
      "Approx 35% complete for SRR13349126_2.fastq\n",
      "Approx 40% complete for SRR13349126_2.fastq\n",
      "Approx 45% complete for SRR13349126_2.fastq\n",
      "Approx 50% complete for SRR13349126_2.fastq\n",
      "Approx 55% complete for SRR13349126_2.fastq\n",
      "Approx 60% complete for SRR13349126_2.fastq\n",
      "Approx 65% complete for SRR13349126_2.fastq\n",
      "Approx 70% complete for SRR13349126_2.fastq\n",
      "Approx 75% complete for SRR13349126_2.fastq\n",
      "Approx 80% complete for SRR13349126_2.fastq\n",
      "Approx 85% complete for SRR13349126_2.fastq\n",
      "Approx 90% complete for SRR13349126_2.fastq\n",
      "Approx 95% complete for SRR13349126_2.fastq\n",
      "Analysis complete for SRR13349126_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349131_2.fastq\n",
      "Approx 5% complete for SRR13349131_2.fastq\n",
      "Approx 10% complete for SRR13349131_2.fastq\n",
      "Approx 15% complete for SRR13349131_2.fastq\n",
      "Approx 20% complete for SRR13349131_2.fastq\n",
      "Approx 25% complete for SRR13349131_2.fastq\n",
      "Approx 30% complete for SRR13349131_2.fastq\n",
      "Approx 35% complete for SRR13349131_2.fastq\n",
      "Approx 40% complete for SRR13349131_2.fastq\n",
      "Approx 45% complete for SRR13349131_2.fastq\n",
      "Approx 50% complete for SRR13349131_2.fastq\n",
      "Approx 55% complete for SRR13349131_2.fastq\n",
      "Approx 60% complete for SRR13349131_2.fastq\n",
      "Approx 65% complete for SRR13349131_2.fastq\n",
      "Approx 70% complete for SRR13349131_2.fastq\n",
      "Approx 75% complete for SRR13349131_2.fastq\n",
      "Approx 80% complete for SRR13349131_2.fastq\n",
      "Approx 85% complete for SRR13349131_2.fastq\n",
      "Approx 90% complete for SRR13349131_2.fastq\n",
      "Approx 95% complete for SRR13349131_2.fastq\n",
      "Analysis complete for SRR13349131_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349129_2.fastq\n",
      "Approx 5% complete for SRR13349129_2.fastq\n",
      "Approx 10% complete for SRR13349129_2.fastq\n",
      "Approx 15% complete for SRR13349129_2.fastq\n",
      "Approx 20% complete for SRR13349129_2.fastq\n",
      "Approx 25% complete for SRR13349129_2.fastq\n",
      "Approx 30% complete for SRR13349129_2.fastq\n",
      "Approx 35% complete for SRR13349129_2.fastq\n",
      "Approx 40% complete for SRR13349129_2.fastq\n",
      "Approx 45% complete for SRR13349129_2.fastq\n",
      "Approx 50% complete for SRR13349129_2.fastq\n",
      "Approx 55% complete for SRR13349129_2.fastq\n",
      "Approx 60% complete for SRR13349129_2.fastq\n",
      "Approx 65% complete for SRR13349129_2.fastq\n",
      "Approx 70% complete for SRR13349129_2.fastq\n",
      "Approx 75% complete for SRR13349129_2.fastq\n",
      "Approx 80% complete for SRR13349129_2.fastq\n",
      "Approx 85% complete for SRR13349129_2.fastq\n",
      "Approx 90% complete for SRR13349129_2.fastq\n",
      "Approx 95% complete for SRR13349129_2.fastq\n",
      "Analysis complete for SRR13349129_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349127_2.fastq\n",
      "Approx 5% complete for SRR13349127_2.fastq\n",
      "Approx 10% complete for SRR13349127_2.fastq\n",
      "Approx 15% complete for SRR13349127_2.fastq\n",
      "Approx 20% complete for SRR13349127_2.fastq\n",
      "Approx 25% complete for SRR13349127_2.fastq\n",
      "Approx 30% complete for SRR13349127_2.fastq\n",
      "Approx 35% complete for SRR13349127_2.fastq\n",
      "Approx 40% complete for SRR13349127_2.fastq\n",
      "Approx 45% complete for SRR13349127_2.fastq\n",
      "Approx 50% complete for SRR13349127_2.fastq\n",
      "Approx 55% complete for SRR13349127_2.fastq\n",
      "Approx 60% complete for SRR13349127_2.fastq\n",
      "Approx 65% complete for SRR13349127_2.fastq\n",
      "Approx 70% complete for SRR13349127_2.fastq\n",
      "Approx 75% complete for SRR13349127_2.fastq\n",
      "Approx 80% complete for SRR13349127_2.fastq\n",
      "Approx 85% complete for SRR13349127_2.fastq\n",
      "Approx 90% complete for SRR13349127_2.fastq\n",
      "Approx 95% complete for SRR13349127_2.fastq\n",
      "Analysis complete for SRR13349127_2.fastq\n",
      "null\n",
      "Started analysis of SRR13349125_2.fastq\n",
      "Approx 5% complete for SRR13349125_2.fastq\n",
      "Approx 10% complete for SRR13349125_2.fastq\n",
      "Approx 15% complete for SRR13349125_2.fastq\n",
      "Approx 20% complete for SRR13349125_2.fastq\n",
      "Approx 25% complete for SRR13349125_2.fastq\n",
      "Approx 30% complete for SRR13349125_2.fastq\n",
      "Approx 35% complete for SRR13349125_2.fastq\n",
      "Approx 40% complete for SRR13349125_2.fastq\n",
      "Approx 45% complete for SRR13349125_2.fastq\n",
      "Approx 50% complete for SRR13349125_2.fastq\n",
      "Approx 55% complete for SRR13349125_2.fastq\n",
      "Approx 60% complete for SRR13349125_2.fastq\n",
      "Approx 65% complete for SRR13349125_2.fastq\n",
      "Approx 70% complete for SRR13349125_2.fastq\n",
      "Approx 75% complete for SRR13349125_2.fastq\n",
      "Approx 80% complete for SRR13349125_2.fastq\n",
      "Approx 85% complete for SRR13349125_2.fastq\n",
      "Approx 90% complete for SRR13349125_2.fastq\n",
      "Approx 95% complete for SRR13349125_2.fastq\n",
      "Analysis complete for SRR13349125_2.fastq\n"
     ]
    }
   ],
   "source": [
    "#run fastqc for forward reads\n",
    "!cat accs.txt | xargs -I {} fastqc \"data/raw_fastq/{}_1.fastq\" -o data/fastqc/\n",
    "#run fastqc for reverse reads\n",
    "!cat accs.txt | xargs -I {} fastqc \"data/raw_fastq/{}_2.fastq\" -o data/fastqc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastqc will output the results in HTML format, as below, for all forward and reverse reads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./data/fastqc/SRR13349126_1_fastqc.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3faddf62f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='./data/fastqc/SRR13349126_1_fastqc.html', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although its best practice to look over them individually, tools like multiqc allow one to quickly look at a summary of the quality reports of the fastq files.\n",
    "\n",
    "For instance, the below table shows which warnings, passes, or failures, from each fastqc report. There are other summaries created as well by multiqc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91m///\u001b[0m \u001b]8;id=48185;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2mv1.24.1\u001b[0m\n",
      "\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/ec2-user/SageMaker/rnaseq-myco-notebook/data/fastqc\n",
      "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m48/48\u001b[0m  data/fastqc/SRR13349128_2_fastqc.html\u001b[0m\n",
      "\u001b[?25h\u001b[34m            fastqc\u001b[0m | Found 24 reports\n",
      "\u001b[34m     write_results\u001b[0m | Data        : multiqc_data   (overwritten)\n",
      "\u001b[34m     write_results\u001b[0m | Report      : multiqc_report.html   (overwritten)\n",
      "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Filename</th>\n",
       "      <th>File type</th>\n",
       "      <th>Encoding</th>\n",
       "      <th>Total Sequences</th>\n",
       "      <th>Total Bases</th>\n",
       "      <th>Sequences flagged as poor quality</th>\n",
       "      <th>Sequence length</th>\n",
       "      <th>%GC</th>\n",
       "      <th>total_deduplicated_percentage</th>\n",
       "      <th>...</th>\n",
       "      <th>basic_statistics</th>\n",
       "      <th>per_base_sequence_quality</th>\n",
       "      <th>per_sequence_quality_scores</th>\n",
       "      <th>per_base_sequence_content</th>\n",
       "      <th>per_sequence_gc_content</th>\n",
       "      <th>per_base_n_content</th>\n",
       "      <th>sequence_length_distribution</th>\n",
       "      <th>sequence_duplication_levels</th>\n",
       "      <th>overrepresented_sequences</th>\n",
       "      <th>adapter_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR13349122_1</td>\n",
       "      <td>SRR13349122_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10827590.0</td>\n",
       "      <td>552.2 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.503069</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR13349122_2</td>\n",
       "      <td>SRR13349122_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10827590.0</td>\n",
       "      <td>552.2 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.335313</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR13349123_1</td>\n",
       "      <td>SRR13349123_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>11165256.0</td>\n",
       "      <td>569.4 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.097632</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR13349123_2</td>\n",
       "      <td>SRR13349123_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>11165256.0</td>\n",
       "      <td>569.4 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.070512</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR13349124_1</td>\n",
       "      <td>SRR13349124_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10727273.0</td>\n",
       "      <td>547 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.313842</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SRR13349124_2</td>\n",
       "      <td>SRR13349124_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10727273.0</td>\n",
       "      <td>547 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.139844</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SRR13349125_1</td>\n",
       "      <td>SRR13349125_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10992686.0</td>\n",
       "      <td>560.6 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.918485</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SRR13349125_2</td>\n",
       "      <td>SRR13349125_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10992686.0</td>\n",
       "      <td>560.6 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.541477</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SRR13349126_1</td>\n",
       "      <td>SRR13349126_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>12267497.0</td>\n",
       "      <td>625.6 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.804107</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SRR13349126_2</td>\n",
       "      <td>SRR13349126_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>12267497.0</td>\n",
       "      <td>625.6 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>9.482849</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SRR13349127_1</td>\n",
       "      <td>SRR13349127_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>12563032.0</td>\n",
       "      <td>640.7 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.443504</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SRR13349127_2</td>\n",
       "      <td>SRR13349127_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>12563032.0</td>\n",
       "      <td>640.7 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.669627</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SRR13349128_1</td>\n",
       "      <td>SRR13349128_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>12652387.0</td>\n",
       "      <td>645.2 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.368545</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SRR13349128_2</td>\n",
       "      <td>SRR13349128_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>12652387.0</td>\n",
       "      <td>645.2 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.965338</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SRR13349129_1</td>\n",
       "      <td>SRR13349129_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>12961793.0</td>\n",
       "      <td>661 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.980868</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SRR13349129_2</td>\n",
       "      <td>SRR13349129_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>12961793.0</td>\n",
       "      <td>661 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.409335</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SRR13349130_1</td>\n",
       "      <td>SRR13349130_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10083015.0</td>\n",
       "      <td>514.2 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.997743</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SRR13349130_2</td>\n",
       "      <td>SRR13349130_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10083015.0</td>\n",
       "      <td>514.2 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.136776</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SRR13349131_1</td>\n",
       "      <td>SRR13349131_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10491160.0</td>\n",
       "      <td>535 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.458165</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SRR13349131_2</td>\n",
       "      <td>SRR13349131_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>10491160.0</td>\n",
       "      <td>535 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.218760</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SRR13349132_1</td>\n",
       "      <td>SRR13349132_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>11341357.0</td>\n",
       "      <td>578.4 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.233561</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SRR13349132_2</td>\n",
       "      <td>SRR13349132_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>11341357.0</td>\n",
       "      <td>578.4 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.801641</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SRR13349133_1</td>\n",
       "      <td>SRR13349133_1.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>11603881.0</td>\n",
       "      <td>591.7 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.841224</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SRR13349133_2</td>\n",
       "      <td>SRR13349133_2.fastq</td>\n",
       "      <td>Conventional base calls</td>\n",
       "      <td>Sanger / Illumina 1.9</td>\n",
       "      <td>11603881.0</td>\n",
       "      <td>591.7 Mbp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8.262785</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>warn</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>fail</td>\n",
       "      <td>fail</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sample             Filename                File type  \\\n",
       "0   SRR13349122_1  SRR13349122_1.fastq  Conventional base calls   \n",
       "1   SRR13349122_2  SRR13349122_2.fastq  Conventional base calls   \n",
       "2   SRR13349123_1  SRR13349123_1.fastq  Conventional base calls   \n",
       "3   SRR13349123_2  SRR13349123_2.fastq  Conventional base calls   \n",
       "4   SRR13349124_1  SRR13349124_1.fastq  Conventional base calls   \n",
       "5   SRR13349124_2  SRR13349124_2.fastq  Conventional base calls   \n",
       "6   SRR13349125_1  SRR13349125_1.fastq  Conventional base calls   \n",
       "7   SRR13349125_2  SRR13349125_2.fastq  Conventional base calls   \n",
       "8   SRR13349126_1  SRR13349126_1.fastq  Conventional base calls   \n",
       "9   SRR13349126_2  SRR13349126_2.fastq  Conventional base calls   \n",
       "10  SRR13349127_1  SRR13349127_1.fastq  Conventional base calls   \n",
       "11  SRR13349127_2  SRR13349127_2.fastq  Conventional base calls   \n",
       "12  SRR13349128_1  SRR13349128_1.fastq  Conventional base calls   \n",
       "13  SRR13349128_2  SRR13349128_2.fastq  Conventional base calls   \n",
       "14  SRR13349129_1  SRR13349129_1.fastq  Conventional base calls   \n",
       "15  SRR13349129_2  SRR13349129_2.fastq  Conventional base calls   \n",
       "16  SRR13349130_1  SRR13349130_1.fastq  Conventional base calls   \n",
       "17  SRR13349130_2  SRR13349130_2.fastq  Conventional base calls   \n",
       "18  SRR13349131_1  SRR13349131_1.fastq  Conventional base calls   \n",
       "19  SRR13349131_2  SRR13349131_2.fastq  Conventional base calls   \n",
       "20  SRR13349132_1  SRR13349132_1.fastq  Conventional base calls   \n",
       "21  SRR13349132_2  SRR13349132_2.fastq  Conventional base calls   \n",
       "22  SRR13349133_1  SRR13349133_1.fastq  Conventional base calls   \n",
       "23  SRR13349133_2  SRR13349133_2.fastq  Conventional base calls   \n",
       "\n",
       "                 Encoding  Total Sequences Total Bases  \\\n",
       "0   Sanger / Illumina 1.9       10827590.0   552.2 Mbp   \n",
       "1   Sanger / Illumina 1.9       10827590.0   552.2 Mbp   \n",
       "2   Sanger / Illumina 1.9       11165256.0   569.4 Mbp   \n",
       "3   Sanger / Illumina 1.9       11165256.0   569.4 Mbp   \n",
       "4   Sanger / Illumina 1.9       10727273.0     547 Mbp   \n",
       "5   Sanger / Illumina 1.9       10727273.0     547 Mbp   \n",
       "6   Sanger / Illumina 1.9       10992686.0   560.6 Mbp   \n",
       "7   Sanger / Illumina 1.9       10992686.0   560.6 Mbp   \n",
       "8   Sanger / Illumina 1.9       12267497.0   625.6 Mbp   \n",
       "9   Sanger / Illumina 1.9       12267497.0   625.6 Mbp   \n",
       "10  Sanger / Illumina 1.9       12563032.0   640.7 Mbp   \n",
       "11  Sanger / Illumina 1.9       12563032.0   640.7 Mbp   \n",
       "12  Sanger / Illumina 1.9       12652387.0   645.2 Mbp   \n",
       "13  Sanger / Illumina 1.9       12652387.0   645.2 Mbp   \n",
       "14  Sanger / Illumina 1.9       12961793.0     661 Mbp   \n",
       "15  Sanger / Illumina 1.9       12961793.0     661 Mbp   \n",
       "16  Sanger / Illumina 1.9       10083015.0   514.2 Mbp   \n",
       "17  Sanger / Illumina 1.9       10083015.0   514.2 Mbp   \n",
       "18  Sanger / Illumina 1.9       10491160.0     535 Mbp   \n",
       "19  Sanger / Illumina 1.9       10491160.0     535 Mbp   \n",
       "20  Sanger / Illumina 1.9       11341357.0   578.4 Mbp   \n",
       "21  Sanger / Illumina 1.9       11341357.0   578.4 Mbp   \n",
       "22  Sanger / Illumina 1.9       11603881.0   591.7 Mbp   \n",
       "23  Sanger / Illumina 1.9       11603881.0   591.7 Mbp   \n",
       "\n",
       "    Sequences flagged as poor quality  Sequence length   %GC  \\\n",
       "0                                 0.0             51.0  55.0   \n",
       "1                                 0.0             51.0  56.0   \n",
       "2                                 0.0             51.0  56.0   \n",
       "3                                 0.0             51.0  56.0   \n",
       "4                                 0.0             51.0  55.0   \n",
       "5                                 0.0             51.0  56.0   \n",
       "6                                 0.0             51.0  55.0   \n",
       "7                                 0.0             51.0  56.0   \n",
       "8                                 0.0             51.0  55.0   \n",
       "9                                 0.0             51.0  55.0   \n",
       "10                                0.0             51.0  55.0   \n",
       "11                                0.0             51.0  56.0   \n",
       "12                                0.0             51.0  54.0   \n",
       "13                                0.0             51.0  56.0   \n",
       "14                                0.0             51.0  54.0   \n",
       "15                                0.0             51.0  56.0   \n",
       "16                                0.0             51.0  55.0   \n",
       "17                                0.0             51.0  56.0   \n",
       "18                                0.0             51.0  55.0   \n",
       "19                                0.0             51.0  56.0   \n",
       "20                                0.0             51.0  55.0   \n",
       "21                                0.0             51.0  56.0   \n",
       "22                                0.0             51.0  55.0   \n",
       "23                                0.0             51.0  56.0   \n",
       "\n",
       "    total_deduplicated_percentage  ...  basic_statistics  \\\n",
       "0                        5.503069  ...              pass   \n",
       "1                        9.335313  ...              pass   \n",
       "2                        5.097632  ...              pass   \n",
       "3                        9.070512  ...              pass   \n",
       "4                        5.313842  ...              pass   \n",
       "5                        9.139844  ...              pass   \n",
       "6                        4.918485  ...              pass   \n",
       "7                        8.541477  ...              pass   \n",
       "8                        4.804107  ...              pass   \n",
       "9                        9.482849  ...              pass   \n",
       "10                       4.443504  ...              pass   \n",
       "11                       9.669627  ...              pass   \n",
       "12                       4.368545  ...              pass   \n",
       "13                       7.965338  ...              pass   \n",
       "14                       3.980868  ...              pass   \n",
       "15                       7.409335  ...              pass   \n",
       "16                       4.997743  ...              pass   \n",
       "17                      10.136776  ...              pass   \n",
       "18                       4.458165  ...              pass   \n",
       "19                      10.218760  ...              pass   \n",
       "20                       5.233561  ...              pass   \n",
       "21                       8.801641  ...              pass   \n",
       "22                       4.841224  ...              pass   \n",
       "23                       8.262785  ...              pass   \n",
       "\n",
       "    per_base_sequence_quality per_sequence_quality_scores  \\\n",
       "0                        pass                        pass   \n",
       "1                        pass                        pass   \n",
       "2                        pass                        pass   \n",
       "3                        pass                        pass   \n",
       "4                        pass                        pass   \n",
       "5                        pass                        pass   \n",
       "6                        pass                        pass   \n",
       "7                        pass                        pass   \n",
       "8                        pass                        pass   \n",
       "9                        pass                        pass   \n",
       "10                       pass                        pass   \n",
       "11                       pass                        pass   \n",
       "12                       pass                        pass   \n",
       "13                       pass                        pass   \n",
       "14                       pass                        pass   \n",
       "15                       pass                        pass   \n",
       "16                       pass                        pass   \n",
       "17                       pass                        pass   \n",
       "18                       pass                        pass   \n",
       "19                       pass                        pass   \n",
       "20                       pass                        pass   \n",
       "21                       pass                        pass   \n",
       "22                       pass                        pass   \n",
       "23                       pass                        pass   \n",
       "\n",
       "   per_base_sequence_content per_sequence_gc_content per_base_n_content  \\\n",
       "0                       fail                    pass               pass   \n",
       "1                       fail                    pass               pass   \n",
       "2                       fail                    pass               pass   \n",
       "3                       fail                    warn               pass   \n",
       "4                       fail                    pass               pass   \n",
       "5                       fail                    pass               pass   \n",
       "6                       fail                    pass               pass   \n",
       "7                       fail                    warn               pass   \n",
       "8                       fail                    pass               pass   \n",
       "9                       fail                    warn               pass   \n",
       "10                      fail                    pass               pass   \n",
       "11                      fail                    warn               pass   \n",
       "12                      fail                    warn               pass   \n",
       "13                      fail                    pass               pass   \n",
       "14                      fail                    warn               pass   \n",
       "15                      fail                    warn               pass   \n",
       "16                      fail                    warn               pass   \n",
       "17                      fail                    pass               pass   \n",
       "18                      fail                    pass               pass   \n",
       "19                      fail                    warn               pass   \n",
       "20                      fail                    warn               pass   \n",
       "21                      fail                    warn               pass   \n",
       "22                      fail                    warn               pass   \n",
       "23                      fail                    warn               pass   \n",
       "\n",
       "   sequence_length_distribution sequence_duplication_levels  \\\n",
       "0                          pass                        fail   \n",
       "1                          pass                        fail   \n",
       "2                          pass                        fail   \n",
       "3                          pass                        fail   \n",
       "4                          pass                        fail   \n",
       "5                          pass                        fail   \n",
       "6                          pass                        fail   \n",
       "7                          pass                        fail   \n",
       "8                          pass                        fail   \n",
       "9                          pass                        fail   \n",
       "10                         pass                        fail   \n",
       "11                         pass                        fail   \n",
       "12                         pass                        fail   \n",
       "13                         pass                        fail   \n",
       "14                         pass                        fail   \n",
       "15                         pass                        fail   \n",
       "16                         pass                        fail   \n",
       "17                         pass                        fail   \n",
       "18                         pass                        fail   \n",
       "19                         pass                        fail   \n",
       "20                         pass                        fail   \n",
       "21                         pass                        fail   \n",
       "22                         pass                        fail   \n",
       "23                         pass                        fail   \n",
       "\n",
       "   overrepresented_sequences adapter_content  \n",
       "0                       fail            pass  \n",
       "1                       fail            pass  \n",
       "2                       fail            pass  \n",
       "3                       fail            pass  \n",
       "4                       fail            pass  \n",
       "5                       fail            pass  \n",
       "6                       fail            pass  \n",
       "7                       fail            pass  \n",
       "8                       fail            pass  \n",
       "9                       fail            pass  \n",
       "10                      fail            pass  \n",
       "11                      fail            pass  \n",
       "12                      fail            pass  \n",
       "13                      fail            pass  \n",
       "14                      fail            pass  \n",
       "15                      fail            pass  \n",
       "16                      fail            pass  \n",
       "17                      fail            pass  \n",
       "18                      fail            pass  \n",
       "19                      fail            pass  \n",
       "20                      fail            pass  \n",
       "21                      fail            pass  \n",
       "22                      fail            pass  \n",
       "23                      fail            pass  \n",
       "\n",
       "[24 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!multiqc -f data/fastqc/\n",
    "\n",
    "import pandas as pd\n",
    "dframe = pd.read_csv(\"./multiqc_data/multiqc_fastqc.txt\", sep='\\t')\n",
    "display(dframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5.1 Merging our fastq files\n",
    "\n",
    "The following step may not be necessary -- it depends on the study.\n",
    "\n",
    "In our case, if we look at our SRA files:\n",
    "\n",
    "https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=SRP300216&o=acc_s%3Aa\n",
    "\n",
    "We will notice that, although there are 12 SRA files, coming from 12 SRR runs -- Actually, there are only 6 total samples. \n",
    "\n",
    "In such a case it is possible that, for instance, multiple different lanes in a flowcell may have been used for the same sample.\n",
    "\n",
    "In our analysis will be comparing at the sample level. So, we would like to merge the fastq files that, although were created as separate fastq files by the sequencer, actually came from the sample. \n",
    "\n",
    "It is generally easier to do this merging after an initial fastqc report, as it makes it easier to pinpoint errors that may be lane specific.\n",
    "\n",
    "Combining two FASTQ files is a straightforward process. Remember how FASTQ files are formatted, they are a list of readcounts. Consequently, we can simply 'concatenate' or add one fastq file to the bottom of another to create a merged fastq. Note that header information in a single fastq file may now contain different lane information -- however for our downstream processes this is acceptable. Remember if your fastq files are zipped, you will have to unzip them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example of how to concatenate two of our fastq files from the same experiment.\n",
    "!cat data/raw_fastq/SRR13349122_1.fastq data/raw_fastq/SRR13349123_1.fastq > data/raw_fastq/GSM5004088_1.fastq\n",
    "!cat data/raw_fastq/SRR13349122_2.fastq data/raw_fastq/SRR13349123_2.fastq > data/raw_fastq/GSM5004088_2.fastq\n",
    "#notice we concat the forward read with a forward read, and reverse with reverse.\n",
    "#also note here we are naming it after the GSM, which is the sample experiment ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could manually do the above for all 12 of our runs, and it wouldn't be much work.\n",
    "\n",
    "If you are comfortable doing so, that is the best process to use.\n",
    "\n",
    "As always though, there are ways to automate things. For instance, we could make use of our query code from 3.1.2 to obtain a list of the SRX IDs, and take advantage of our Jupyter's ability to write python to write a loop to iterate and concat our list.\n",
    "\n",
    "Specific to our case, each sample contains two paired-end SRRs. \n",
    "\n",
    "Note; running this step will remove the previous unmerged fastq files in order to save space.\n",
    "\n",
    "This will take about one hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6491/1247509149.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>assay_type</th>\n",
       "      <th>center_name</th>\n",
       "      <th>consent</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>instrument</th>\n",
       "      <th>librarylayout</th>\n",
       "      <th>libraryselection</th>\n",
       "      <th>librarysource</th>\n",
       "      <th>...</th>\n",
       "      <th>geo_loc_name_sam</th>\n",
       "      <th>ena_first_public_run</th>\n",
       "      <th>ena_last_update_run</th>\n",
       "      <th>sample_name_sam</th>\n",
       "      <th>datastore_filetype</th>\n",
       "      <th>datastore_provider</th>\n",
       "      <th>datastore_region</th>\n",
       "      <th>attributes</th>\n",
       "      <th>jattr</th>\n",
       "      <th>run_file_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR13349124</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775147</td>\n",
       "      <td>GSM5004089</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004089}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004089\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR13349122</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775146</td>\n",
       "      <td>GSM5004088</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004088}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004088\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR13349132</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775151</td>\n",
       "      <td>GSM5004093</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004093}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004093\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR13349133</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775151</td>\n",
       "      <td>GSM5004093</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004093}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004093\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR13349130</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775150</td>\n",
       "      <td>GSM5004092</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004092}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004092\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SRR13349123</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775146</td>\n",
       "      <td>GSM5004088</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004088}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004088\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SRR13349126</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775148</td>\n",
       "      <td>GSM5004090</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004090}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004090\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SRR13349128</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775149</td>\n",
       "      <td>GSM5004091</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004091}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004091\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SRR13349127</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775148</td>\n",
       "      <td>GSM5004090</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004090}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004090\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SRR13349129</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775149</td>\n",
       "      <td>GSM5004091</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004091}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004091\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SRR13349125</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775147</td>\n",
       "      <td>GSM5004089</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004089}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004089\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SRR13349131</td>\n",
       "      <td>RNA-Seq</td>\n",
       "      <td>GEO</td>\n",
       "      <td>public</td>\n",
       "      <td>SRX9775150</td>\n",
       "      <td>GSM5004092</td>\n",
       "      <td>Illumina HiSeq 2500</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>cDNA</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[fastq, run.zq, sra]</td>\n",
       "      <td>[gs, ncbi, s3]</td>\n",
       "      <td>[gs.us-east1, ncbi.public, s3.us-east-1]</td>\n",
       "      <td>[{k=geo_accession_exp, v=GSM5004092}, {k=bases...</td>\n",
       "      <td>{\"geo_accession_exp\": [\"GSM5004092\"], \"bases\":...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            acc assay_type center_name consent  experiment sample_name  \\\n",
       "0   SRR13349124    RNA-Seq         GEO  public  SRX9775147  GSM5004089   \n",
       "1   SRR13349122    RNA-Seq         GEO  public  SRX9775146  GSM5004088   \n",
       "2   SRR13349132    RNA-Seq         GEO  public  SRX9775151  GSM5004093   \n",
       "3   SRR13349133    RNA-Seq         GEO  public  SRX9775151  GSM5004093   \n",
       "4   SRR13349130    RNA-Seq         GEO  public  SRX9775150  GSM5004092   \n",
       "5   SRR13349123    RNA-Seq         GEO  public  SRX9775146  GSM5004088   \n",
       "6   SRR13349126    RNA-Seq         GEO  public  SRX9775148  GSM5004090   \n",
       "7   SRR13349128    RNA-Seq         GEO  public  SRX9775149  GSM5004091   \n",
       "8   SRR13349127    RNA-Seq         GEO  public  SRX9775148  GSM5004090   \n",
       "9   SRR13349129    RNA-Seq         GEO  public  SRX9775149  GSM5004091   \n",
       "10  SRR13349125    RNA-Seq         GEO  public  SRX9775147  GSM5004089   \n",
       "11  SRR13349131    RNA-Seq         GEO  public  SRX9775150  GSM5004092   \n",
       "\n",
       "             instrument librarylayout libraryselection   librarysource  ...  \\\n",
       "0   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "1   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "2   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "3   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "4   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "5   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "6   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "7   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "8   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "9   Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "10  Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "11  Illumina HiSeq 2500        PAIRED             cDNA  TRANSCRIPTOMIC  ...   \n",
       "\n",
       "   geo_loc_name_sam ena_first_public_run ena_last_update_run sample_name_sam  \\\n",
       "0              None                 None                None            None   \n",
       "1              None                 None                None            None   \n",
       "2              None                 None                None            None   \n",
       "3              None                 None                None            None   \n",
       "4              None                 None                None            None   \n",
       "5              None                 None                None            None   \n",
       "6              None                 None                None            None   \n",
       "7              None                 None                None            None   \n",
       "8              None                 None                None            None   \n",
       "9              None                 None                None            None   \n",
       "10             None                 None                None            None   \n",
       "11             None                 None                None            None   \n",
       "\n",
       "      datastore_filetype datastore_provider  \\\n",
       "0   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "1   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "2   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "3   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "4   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "5   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "6   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "7   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "8   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "9   [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "10  [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "11  [fastq, run.zq, sra]     [gs, ncbi, s3]   \n",
       "\n",
       "                            datastore_region  \\\n",
       "0   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "1   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "2   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "3   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "4   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "5   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "6   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "7   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "8   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "9   [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "10  [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "11  [gs.us-east1, ncbi.public, s3.us-east-1]   \n",
       "\n",
       "                                           attributes  \\\n",
       "0   [{k=geo_accession_exp, v=GSM5004089}, {k=bases...   \n",
       "1   [{k=geo_accession_exp, v=GSM5004088}, {k=bases...   \n",
       "2   [{k=geo_accession_exp, v=GSM5004093}, {k=bases...   \n",
       "3   [{k=geo_accession_exp, v=GSM5004093}, {k=bases...   \n",
       "4   [{k=geo_accession_exp, v=GSM5004092}, {k=bases...   \n",
       "5   [{k=geo_accession_exp, v=GSM5004088}, {k=bases...   \n",
       "6   [{k=geo_accession_exp, v=GSM5004090}, {k=bases...   \n",
       "7   [{k=geo_accession_exp, v=GSM5004091}, {k=bases...   \n",
       "8   [{k=geo_accession_exp, v=GSM5004090}, {k=bases...   \n",
       "9   [{k=geo_accession_exp, v=GSM5004091}, {k=bases...   \n",
       "10  [{k=geo_accession_exp, v=GSM5004089}, {k=bases...   \n",
       "11  [{k=geo_accession_exp, v=GSM5004092}, {k=bases...   \n",
       "\n",
       "                                                jattr  run_file_version  \n",
       "0   {\"geo_accession_exp\": [\"GSM5004089\"], \"bases\":...                 1  \n",
       "1   {\"geo_accession_exp\": [\"GSM5004088\"], \"bases\":...                 1  \n",
       "2   {\"geo_accession_exp\": [\"GSM5004093\"], \"bases\":...                 1  \n",
       "3   {\"geo_accession_exp\": [\"GSM5004093\"], \"bases\":...                 1  \n",
       "4   {\"geo_accession_exp\": [\"GSM5004092\"], \"bases\":...                 1  \n",
       "5   {\"geo_accession_exp\": [\"GSM5004088\"], \"bases\":...                 1  \n",
       "6   {\"geo_accession_exp\": [\"GSM5004090\"], \"bases\":...                 1  \n",
       "7   {\"geo_accession_exp\": [\"GSM5004091\"], \"bases\":...                 1  \n",
       "8   {\"geo_accession_exp\": [\"GSM5004090\"], \"bases\":...                 1  \n",
       "9   {\"geo_accession_exp\": [\"GSM5004091\"], \"bases\":...                 1  \n",
       "10  {\"geo_accession_exp\": [\"GSM5004089\"], \"bases\":...                 1  \n",
       "11  {\"geo_accession_exp\": [\"GSM5004092\"], \"bases\":...                 1  \n",
       "\n",
       "[12 rows x 37 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "\n",
    "# Use the correct argument name: s3_staging_dir\n",
    "conn = connect(s3_staging_dir='s3://sra-data-athena/', region_name='us-east-1')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM AwsDataCatalog.srametadata.metadata\n",
    "WHERE organism = 'Mycobacteroides chelonae' \n",
    "AND acc LIKE '%SRR133491%'\n",
    "\"\"\"\n",
    "df = pd.read_sql(\n",
    "    query, conn\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os so we can easily pass strings to shell commands using 'subprocess'\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "#now get the accession id's and sample id's from the created dataframe\n",
    "runs = df['acc'].values\n",
    "samples = list(set(df['sample_name'].values))\n",
    "\n",
    "#sort them to be in numerical order\n",
    "runs.sort()\n",
    "samples.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The below code may take approximately 35 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, item in enumerate(samples):\n",
    "    try:\n",
    "        # Concatenate the two SRRs for forward reads\n",
    "        subprocess.run(f\"cat data/raw_fastq/{runs[index*2]}_1.fastq data/raw_fastq/{runs[index*2+1]}_1.fastq > data/raw_fastq/{samples[index]}_1.fastq\", shell=True, check=True)\n",
    "        \n",
    "        # Remove the original fastq files for forward reads\n",
    "        subprocess.run(f\"rm data/raw_fastq/{runs[index*2]}_1.fastq\", shell=True, check=True)\n",
    "        subprocess.run(f\"rm data/raw_fastq/{runs[index*2+1]}_1.fastq\", shell=True, check=True)\n",
    "        \n",
    "        # Compress the concatenated forward fastq file\n",
    "        subprocess.run(f\"gzip data/raw_fastq/{samples[index]}_1.fastq\", shell=True, check=True)\n",
    "        \n",
    "        # Concatenate the two SRRs for reverse reads\n",
    "        subprocess.run(f\"cat data/raw_fastq/{runs[index*2]}_2.fastq data/raw_fastq/{runs[index*2+1]}_2.fastq > data/raw_fastq/{samples[index]}_2.fastq\", shell=True, check=True)\n",
    "        \n",
    "        # Remove the original fastq files for reverse reads\n",
    "        subprocess.run(f\"rm data/raw_fastq/{runs[index*2]}_2.fastq\", shell=True, check=True)\n",
    "        subprocess.run(f\"rm data/raw_fastq/{runs[index*2+1]}_2.fastq\", shell=True, check=True)\n",
    "        \n",
    "        # Compress the concatenated reverse fastq file\n",
    "        subprocess.run(f\"gzip data/raw_fastq/{samples[index]}_2.fastq\", shell=True, check=True)\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error processing {samples[index]}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSM5004088\n",
      "GSM5004089\n",
      "GSM5004090\n",
      "GSM5004091\n",
      "GSM5004092\n",
      "GSM5004093"
     ]
    }
   ],
   "source": [
    "#since our files will now be samples, not SRRs we can write a new text file to use for downstream batch processes.\n",
    "#we can use the DF we made in the previous cell.\n",
    "with open('samples.txt', 'w') as f:\n",
    "    df = df.sort_values(by='sample_name', ascending=True)\n",
    "    samples = df['sample_name'].unique()\n",
    "    samples = '\\n'.join(map(str, samples))\n",
    "    f.write(samples)\n",
    "    \n",
    "!cat samples.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE Unsaved/\n",
      "2024-09-08 06:54:10        547 7f83eff2-4e38-42b7-bec2-83d53e70ec3a.txt\n",
      "2024-09-08 06:55:09        547 82029943-19a2-41cc-82b3-bc4da4e5fd0c.txt\n",
      "2024-09-08 23:24:20        547 f3902544-3a83-4096-a541-cbeb8bf45164.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://rnaseq-myco-bucket/athena-results/ --region us-east-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5.3: Copy data file for Trimmomatic\n",
    "\n",
    "One of trimmomatics functions is to trim sequence machine specific adapter sequences. These are usually within the trimmomatic installation directory in a folder called adapters.\n",
    "\n",
    "Directories of packages within conda installations can be confusing, so in the case of using conda with trimmomatic, it may be easier to simply download or create a file with the relevant adapter sequencecs and store it in an easy to find directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://nigms-sandbox/me-inbre-rnaseq-pipelinev2/config/TruSeq3-PE.fa...\n",
      "/ [1/1 files][   95.0 B/   95.0 B] 100% Done                                    \n",
      "Operation completed over 1 objects/95.0 B.                                       \n",
      ">PrefixPE/1\n",
      "TACACTCTTTCCCTACACGACGCTCTTCCGATCT\n",
      ">PrefixPE/2\n",
      "GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r gs://nigms-sandbox/me-inbre-rnaseq-pipelinev2/config/TruSeq3-PE.fa .\n",
    "!head TruSeq3-PE.fa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: Run Trimmomatic\n",
    "Trimmomatic will trim off any adapter sequences or low quality sequence it detects in the FASTQ files.\n",
    "\n",
    "Using piping and our original list, it is possible to queue up a batch run of trimmomatic for all our files, note that this is a different way to run a loop compared with what we did before.\n",
    "\n",
    "The below code may take approximately 35 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 1 data/raw_fastq/GSM5004088_1.fastq.gz data/raw_fastq/GSM5004088_2.fastq.gz data/trimmed/GSM5004088_1_trimmed.fastq.gz data/trimmed/GSM5004088_1_trimmed_unpaired.fastq.gz data/trimmed/GSM5004088_2_trimmed.fastq.gz data/trimmed/GSM5004088_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 21992846 Both Surviving: 21906525 (99.61%) Forward Only Surviving: 86263 (0.39%) Reverse Only Surviving: 0 (0.00%) Dropped: 58 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 1 data/raw_fastq/GSM5004089_1.fastq.gz data/raw_fastq/GSM5004089_2.fastq.gz data/trimmed/GSM5004089_1_trimmed.fastq.gz data/trimmed/GSM5004089_1_trimmed_unpaired.fastq.gz data/trimmed/GSM5004089_2_trimmed.fastq.gz data/trimmed/GSM5004089_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 21719959 Both Surviving: 21634631 (99.61%) Forward Only Surviving: 85258 (0.39%) Reverse Only Surviving: 0 (0.00%) Dropped: 70 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 1 data/raw_fastq/GSM5004090_1.fastq.gz data/raw_fastq/GSM5004090_2.fastq.gz data/trimmed/GSM5004090_1_trimmed.fastq.gz data/trimmed/GSM5004090_1_trimmed_unpaired.fastq.gz data/trimmed/GSM5004090_2_trimmed.fastq.gz data/trimmed/GSM5004090_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 24830529 Both Surviving: 24733566 (99.61%) Forward Only Surviving: 96797 (0.39%) Reverse Only Surviving: 0 (0.00%) Dropped: 166 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 1 data/raw_fastq/GSM5004091_1.fastq.gz data/raw_fastq/GSM5004091_2.fastq.gz data/trimmed/GSM5004091_1_trimmed.fastq.gz data/trimmed/GSM5004091_1_trimmed_unpaired.fastq.gz data/trimmed/GSM5004091_2_trimmed.fastq.gz data/trimmed/GSM5004091_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 25614180 Both Surviving: 25513907 (99.61%) Forward Only Surviving: 100110 (0.39%) Reverse Only Surviving: 0 (0.00%) Dropped: 163 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 1 data/raw_fastq/GSM5004092_1.fastq.gz data/raw_fastq/GSM5004092_2.fastq.gz data/trimmed/GSM5004092_1_trimmed.fastq.gz data/trimmed/GSM5004092_1_trimmed_unpaired.fastq.gz data/trimmed/GSM5004092_2_trimmed.fastq.gz data/trimmed/GSM5004092_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 20574175 Both Surviving: 20494262 (99.61%) Forward Only Surviving: 79849 (0.39%) Reverse Only Surviving: 0 (0.00%) Dropped: 64 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n",
      "TrimmomaticPE: Started with arguments:\n",
      " -threads 1 data/raw_fastq/GSM5004093_1.fastq.gz data/raw_fastq/GSM5004093_2.fastq.gz data/trimmed/GSM5004093_1_trimmed.fastq.gz data/trimmed/GSM5004093_1_trimmed_unpaired.fastq.gz data/trimmed/GSM5004093_2_trimmed.fastq.gz data/trimmed/GSM5004093_2_trimmed_unpaired.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36\n",
      "Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT'\n",
      "ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 22945238 Both Surviving: 22854486 (99.60%) Forward Only Surviving: 90659 (0.40%) Reverse Only Surviving: 0 (0.00%) Dropped: 93 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n"
     ]
    }
   ],
   "source": [
    "!cat samples.txt | xargs -I {} trimmomatic PE -threads $THREADS 'data/raw_fastq/{}_1.fastq.gz' 'data/raw_fastq/{}_2.fastq.gz' 'data/trimmed/{}_1_trimmed.fastq.gz' 'data/trimmed/{}_1_trimmed_unpaired.fastq.gz' 'data/trimmed/{}_2_trimmed.fastq.gz' 'data/trimmed/{}_2_trimmed_unpaired.fastq.gz' ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 MINLEN:36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 7 (Optional): Run FastQC\n",
    "\n",
    "It's best practice to run FastQC after trimming. However, you may decide to run FastQC only once, before or after trimming.\n",
    "\n",
    "We will proceed with only the forward reads -- this is because, looking at trimmomatic, there were very few 'orphaned' reads. That is to say, most forward and reverse reads were successfully paired together. Because we are just trying to map to a transcriptome, the read lengths of the forward reads alone, in this case, around 50~ basepairs, should be sufficient.\n",
    "\n",
    "The below code may take around 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application/gzip\n",
      "Started analysis of GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 5% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 10% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 15% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 20% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 25% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 30% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 35% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 40% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 45% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 50% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 55% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 60% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 65% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 70% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 75% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 80% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 85% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 90% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Approx 95% complete for GSM5004088_1_trimmed.fastq.gz\n",
      "Analysis complete for GSM5004088_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 5% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 10% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 15% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 20% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 25% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 30% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 35% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 40% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 45% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 50% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 55% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 60% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 65% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 70% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 75% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 80% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 85% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 90% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Approx 95% complete for GSM5004089_1_trimmed.fastq.gz\n",
      "Analysis complete for GSM5004089_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 5% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 10% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 15% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 20% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 25% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 30% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 35% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 40% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 45% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 50% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 55% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 60% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 65% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 70% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 75% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 80% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 85% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 90% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Approx 95% complete for GSM5004090_1_trimmed.fastq.gz\n",
      "Analysis complete for GSM5004090_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 5% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 10% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 15% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 20% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 25% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 30% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 35% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 40% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 45% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 50% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 55% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 60% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 65% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 70% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 75% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 80% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 85% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 90% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Approx 95% complete for GSM5004091_1_trimmed.fastq.gz\n",
      "Analysis complete for GSM5004091_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 5% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 10% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 15% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 20% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 25% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 30% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 35% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 40% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 45% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 50% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 55% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 60% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 65% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 70% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 75% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 80% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 85% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 90% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Approx 95% complete for GSM5004092_1_trimmed.fastq.gz\n",
      "Analysis complete for GSM5004092_1_trimmed.fastq.gz\n",
      "application/gzip\n",
      "Started analysis of GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 5% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 10% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 15% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 20% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 25% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 30% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 35% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 40% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 45% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 50% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 55% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 60% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 65% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 70% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 75% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 80% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 85% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 90% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Approx 95% complete for GSM5004093_1_trimmed.fastq.gz\n",
      "Analysis complete for GSM5004093_1_trimmed.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "!cat samples.txt | xargs -I {} fastqc \"data/trimmed/{}_1_trimmed.fastq.gz\" -o data/fastqc_samples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 8: Run MultiQC\n",
    "MultiQC reads in the FastQC reports and generate a compiled report for all the analyzed FASTQ files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[91m///\u001b[0m \u001b]8;id=231440;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2mv1.24.1\u001b[0m\n",
      "\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/ec2-user/SageMaker/rnaseq-myco-notebook/data/fastqc_samples\n",
      "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m12/12\u001b[0m  p\u001b[0mm  \n",
      "\u001b[?25h\u001b[34m            fastqc\u001b[0m | Found 6 reports\n",
      "\u001b[34m     write_results\u001b[0m | Data        : data/multiqc_samples/multiqc_data\n",
      "\u001b[34m     write_results\u001b[0m | Report      : data/multiqc_samples/multiqc_report.html\n",
      "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "#!multiqc -f data/fastqc_samples/\n",
    "!multiqc -f -o data/multiqc_samples/ data/fastqc_samples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 9: Index the Transcriptome so that Trimmed Reads Can Be Mapped Using Salmon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run salmon we must specify the reference transcriptome, and the folder of our created index.\n",
    "\n",
    "Note here, -i does not mean input, but the folder where the index will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Server Response: Not Found\n",
      "index [\"data/reference/transcriptome_index\"] did not previously exist  . . . creating it\n",
      "[2024-09-13 10:38:21.327] [jLog] [info] building index\n",
      "out : data/reference/transcriptome_index\n",
      "\u001b[00m[2024-09-13 10:38:21.328] [puff::index::jointLog] [info] Running fixFasta\n",
      "\u001b[00m\n",
      "[Step 1 of 4] : counting k-mers\n",
      "\n",
      "\u001b[35m[2024-09-13 10:38:21.624] [puff::index::jointLog] [warning] There were 1 transcripts that would need to be removed to avoid duplicates.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:21.625] [puff::index::jointLog] [info] Replaced 0 non-ATCG nucleotides\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:21.625] [puff::index::jointLog] [info] Clipped poly-A tails from 0 transcripts\n",
      "\u001b[00mwrote 4919 cleaned references\n",
      "\u001b[00m[2024-09-13 10:38:21.648] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:21.797] [puff::index::jointLog] [info] ntHll estimated 4966944 distinct k-mers, setting filter size to 2^27\n",
      "\u001b[00mThreads = 1\n",
      "Vertex length = 31\n",
      "Hash functions = 5\n",
      "Filter size = 134217728\n",
      "Capacity = 2\n",
      "Files: \n",
      "data/reference/transcriptome_index/ref_k31_fixed.fa\n",
      "--------------------------------------------------------------------------------\n",
      "Round 0, 0:134217728\n",
      "Pass\tFilling\tFiltering\n",
      "1\t5\t10\t\n",
      "2\t0\t0\n",
      "True junctions count = 10233\n",
      "False junctions count = 9667\n",
      "Hash table size = 19900\n",
      "Candidate marks count = 39899\n",
      "--------------------------------------------------------------------------------\n",
      "Reallocating bifurcations time: 1\n",
      "True marks count: 21486\n",
      "Edges construction time: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Distinct junctions = 10233\n",
      "\n",
      "TwoPaCo::buildGraphMain:: allocated with scalable_malloc; freeing.\n",
      "TwoPaCo::buildGraphMain:: Calling scalable_allocation_command(TBBMALLOC_CLEAN_ALL_BUFFERS, 0);\n",
      "allowedIn: 17\n",
      "Max Junction ID: 10276\n",
      "seen.size():82217 kmerInfo.size():10277\n",
      "approximateContigTotalLength: 4949507\n",
      "counters for complex kmers:\n",
      "(prec>1 & succ>1)=8 | (succ>1 & isStart)=0 | (prec>1 & isEnd)=0 | (isStart & isEnd)=2\n",
      "contig count: 10455 element count: 5331183 complex nodes: 10\n",
      "# of ones in rank vector: 10454\n",
      "\u001b[00m[2024-09-13 10:38:38.338] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.338] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory data/reference/transcriptome_index\n",
      "\u001b[00msize = 5331183\n",
      "-----------------------------------------\n",
      "| Loading contigs | Time = 1.1337 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 980.27 us\n",
      "-----------------------------------------\n",
      "Number of ones: 10454\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "10454\n",
      "\u001b[00m[2024-09-13 10:38:38.351] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.351] [puff::index::jointLog] [info] contig count for validation: 10,454\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.355] [puff::index::jointLog] [info] Total # of Contigs : 10,454\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.355] [puff::index::jointLog] [info] Total # of numerical Contigs : 10,454\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.355] [puff::index::jointLog] [info] Total # of contig vec entries: 16,600\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.355] [puff::index::jointLog] [info] bits per offset entry 15\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.356] [puff::index::jointLog] [info] Done constructing the contig vector. 10455\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.358] [puff::index::jointLog] [info] # segments = 10,454\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.358] [puff::index::jointLog] [info] total length = 5,331,183\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.360] [puff::index::jointLog] [info] Reading the reference files ...\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.411] [puff::index::jointLog] [info] positional integer width = 23\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.411] [puff::index::jointLog] [info] seqSize = 5,331,183\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.411] [puff::index::jointLog] [info] rankSize = 5,331,183\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.411] [puff::index::jointLog] [info] edgeVecSize = 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:38.411] [puff::index::jointLog] [info] num keys = 5,017,563\n",
      "\u001b[00mfor info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000 \n",
      "[Building BooPHF]  99.9 %   elapsed:   0 min 1  sec   remaining:   0 min 0  sec\n",
      "Bitarray        26296128  bits (100.00 %)   (array + ranks )\n",
      "final hash             0  bits (0.00 %) (nb in final hash 0)\n",
      "\u001b[00m[2024-09-13 10:38:39.472] [puff::index::jointLog] [info] mphf size = 3.13474 MB\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:39.482] [puff::index::jointLog] [info] chunk size = 5,331,183\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:39.482] [puff::index::jointLog] [info] chunk 0 = [0, 5,331,153)\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:40.875] [puff::index::jointLog] [info] finished populating pos vector\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:40.875] [puff::index::jointLog] [info] writing index components\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:40.890] [puff::index::jointLog] [info] finished writing dense pufferfish index\n",
      "\u001b[00m[2024-09-13 10:38:40.893] [jLog] [info] done building index\n"
     ]
    }
   ],
   "source": [
    "!salmon index -t data/reference/GCF_001632805.1_transcriptome_reference_w_decoy.fa -p $THREADS -i data/reference/transcriptome_index --decoys data/reference/decoys.txt -k 31 --keepDuplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 10: Run Salmon to Map Reads to Transcripts and Quantify Expression Levels\n",
    "Salmon aligns the trimmed reads to the reference transcriptome and generates the read counts per transcript. In this analysis, each gene has a single transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/GSM5004088_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/GSM5004088_quant }\n",
      "Logs will be written to data/quants/GSM5004088_quant/logs\n",
      "\u001b[00m[2024-09-13 10:38:41.097] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:41.097] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:41.097] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:41.097] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:41.097] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:41.097] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 5.8339 ms\n",
      "-----------------------------------------\n",
      "size = 10455\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 112.2 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 31.554 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2024-09-13 10:38:41.097] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:41.097] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading mphf table | Time = 20.451 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "Number of ones: 10454\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 18.657 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.3872 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 12.889 ms\n",
      "-----------------------------------------\n",
      "size = 9694896\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 2.4367 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 65.738 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2024-09-13 10:38:41.159] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:41.291] [jointLog] [info] Index contained 4,919 targets\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:41.294] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:38:41.294] [jointLog] [info] First decoy index : 4,918 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 20,557,833; hits per frag:  0.957959\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2024-09-13 10:40:13.689] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.691] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.703] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.723] [jointLog] [info] Thread saw mini-batch with a maximum of 0.39% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.742] [jointLog] [info] Thread saw mini-batch with a maximum of 0.46% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.743] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.744] [jointLog] [info] Thread saw mini-batch with a maximum of 0.44% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.745] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.787] [jointLog] [info] Computed 4,761 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.787] [jointLog] [info] Counted 20,901,892 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.807] [jointLog] [info] Number of mappings discarded because of alignment score : 327,071\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.807] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 277,466\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.807] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 154,126\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.807] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.807] [jointLog] [info] Mapping rate = 95.414%\n",
      "\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.807] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.807] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.810] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.811] [jointLog] [info] iteration = 0 | max rel diff. = 2472.8\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.859] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.860] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:13.860] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/GSM5004089_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/GSM5004089_quant }\n",
      "Logs will be written to data/quants/GSM5004089_quant/logs\n",
      "\u001b[00m[2024-09-13 10:40:14.890] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:14.890] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:14.890] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:14.890] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:14.890] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:14.890] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:14.890] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:14.890] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 2.2738 ms\n",
      "-----------------------------------------\n",
      "size = 10455\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 82.952 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 35.707 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.747 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "Number of ones: 10454\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 8.822 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 967.27 us\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 9.6045 ms\n",
      "-----------------------------------------\n",
      "size = 9694896\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.6488 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 62.399 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2024-09-13 10:40:14.917] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:15.060] [jointLog] [info] Index contained 4,919 targets\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:15.061] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:40:15.061] [jointLog] [info] First decoy index : 4,918 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,000,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 20,513,356; hits per frag:  0.955197\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2024-09-13 10:41:39.462] [jointLog] [info] Thread saw mini-batch with a maximum of 0.48% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.462] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.462] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.476] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.482] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.488] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.494] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.506] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.545] [jointLog] [info] Computed 4,730 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.545] [jointLog] [info] Counted 20,603,066 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.556] [jointLog] [info] Number of mappings discarded because of alignment score : 391,964\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.556] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 295,054\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.556] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 135,111\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.556] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.556] [jointLog] [info] Mapping rate = 95.2319%\n",
      "\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.556] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.556] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.559] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.560] [jointLog] [info] iteration = 0 | max rel diff. = 2462.47\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.619] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.620] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.620] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/GSM5004090_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/GSM5004090_quant }\n",
      "Logs will be written to data/quants/GSM5004090_quant/logs\n",
      "\u001b[00m[2024-09-13 10:41:39.891] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.891] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.891] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.891] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.891] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.892] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 2.2658 ms\n",
      "-----------------------------------------\n",
      "size = 10455\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 83.209 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 96.374 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.5187 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "Number of ones: 10454\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 9.1327 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.0449 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "\u001b[00m[2024-09-13 10:41:39.892] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:39.892] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading positions | Time = 10.594 ms\n",
      "-----------------------------------------\n",
      "size = 9694896\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.9248 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 59.853 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2024-09-13 10:41:39.920] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:40.030] [jointLog] [info] Index contained 4,919 targets\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:40.031] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:41:40.031] [jointLog] [info] First decoy index : 4,918 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,000,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 22,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 22,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 23,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 23,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 24,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 24,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 23,533,190; hits per frag:  0.961181\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2024-09-13 10:43:21.148] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.148] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.148] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.149] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.149] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.157] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.165] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.168] [jointLog] [info] Thread saw mini-batch with a maximum of 0.36% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.198] [jointLog] [info] Computed 4,752 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.198] [jointLog] [info] Counted 23,719,853 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.206] [jointLog] [info] Number of mappings discarded because of alignment score : 388,001\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.206] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 295,385\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.206] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 136,332\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.206] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.206] [jointLog] [info] Mapping rate = 95.9015%\n",
      "\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.206] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.206] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.209] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.210] [jointLog] [info] iteration = 0 | max rel diff. = 5069.99\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.277] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.278] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:21.278] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/GSM5004091_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/GSM5004091_quant }\n",
      "Logs will be written to data/quants/GSM5004091_quant/logs\n",
      "\u001b[00m[2024-09-13 10:43:22.089] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.089] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.089] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.089] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.089] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.089] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.089] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.089] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 2.0225 ms\n",
      "-----------------------------------------\n",
      "size = 10455\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 88.365 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 24.563 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.8513 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "Number of ones: 10454\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 17.987 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 2.9878 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 29.476 ms\n",
      "-----------------------------------------\n",
      "size = 9694896\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 3.7652 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 58.239 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2024-09-13 10:43:22.150] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.284] [jointLog] [info] Index contained 4,919 targets\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.285] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:43:22.285] [jointLog] [info] First decoy index : 4,918 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,000,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,000,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 22,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 22,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 23,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 23,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 24,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 24,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 25,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 25,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 24,227,951; hits per frag:  0.950412\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2024-09-13 10:44:54.169] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.169] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.170] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.170] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.173] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.185] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.188] [jointLog] [info] Thread saw mini-batch with a maximum of 0.30% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.192] [jointLog] [info] Thread saw mini-batch with a maximum of 0.28% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.215] [jointLog] [info] Computed 4,692 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.215] [jointLog] [info] Counted 24,204,390 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.223] [jointLog] [info] Number of mappings discarded because of alignment score : 895,968\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.223] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 525,599\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.223] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 103,920\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.223] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.223] [jointLog] [info] Mapping rate = 94.8674%\n",
      "\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.223] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.223] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.226] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.227] [jointLog] [info] iteration = 0 | max rel diff. = 5077.7\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.272] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.273] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.273] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/GSM5004092_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/GSM5004092_quant }\n",
      "Logs will be written to data/quants/GSM5004092_quant/logs\n",
      "\u001b[00m[2024-09-13 10:44:54.635] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.635] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.635] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.635] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.635] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.635] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.635] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.635] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 2.1521 ms\n",
      "-----------------------------------------\n",
      "size = 10455\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 83.462 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 27.95 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 3.6557 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "Number of ones: 10454\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 15.462 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.6131 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 23.609 ms\n",
      "-----------------------------------------\n",
      "size = 9694896\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 5.8839 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 162.22 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2024-09-13 10:44:54.688] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.818] [jointLog] [info] Index contained 4,919 targets\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.819] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:44:54.819] [jointLog] [info] First decoy index : 4,918 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,000,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,000,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,000,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,000,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 19,216,222; hits per frag:  0.962224\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2024-09-13 10:46:20.766] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.766] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.766] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.766] [jointLog] [info] Thread saw mini-batch with a maximum of 0.34% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.780] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.801] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.803] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.815] [jointLog] [info] Thread saw mini-batch with a maximum of 0.32% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.840] [jointLog] [info] Computed 4,674 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.840] [jointLog] [info] Counted 19,657,951 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.847] [jointLog] [info] Number of mappings discarded because of alignment score : 341,003\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.847] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 239,949\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.847] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 94,840\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.847] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.847] [jointLog] [info] Mapping rate = 95.9193%\n",
      "\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.847] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.847] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.850] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.851] [jointLog] [info] iteration = 0 | max rel diff. = 2425.02\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.901] [jointLog] [info] iteration = 100 | max rel diff. = 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.901] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:20.901] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00mVersion Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.3\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ index ] => { data/reference/transcriptome_index }\n",
      "### [ libType ] => { SR }\n",
      "### [ unmatedReads ] => { data/trimmed/GSM5004093_1_trimmed.fastq.gz }\n",
      "### [ threads ] => { 8 }\n",
      "### [ validateMappings ] => { }\n",
      "### [ output ] => { data/quants/GSM5004093_quant }\n",
      "Logs will be written to data/quants/GSM5004093_quant/logs\n",
      "\u001b[00m[2024-09-13 10:46:21.907] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:21.907] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:21.907] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:21.907] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:21.907] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:21.907] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:21.907] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:21.907] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 2.2178 ms\n",
      "-----------------------------------------\n",
      "size = 10455\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 147.54 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 24.404 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 2.2131 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "Number of ones: 10454\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 21\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 8.5087 ms\n",
      "-----------------------------------------\n",
      "size = 5331183\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 1.1721 ms\n",
      "-----------------------------------------\n",
      "size = 5017563\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 9.5743 ms\n",
      "-----------------------------------------\n",
      "size = 9694896\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 1.6923 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 56.149 us\n",
      "-----------------------------------------\n",
      "\u001b[00m[2024-09-13 10:46:21.933] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:22.041] [jointLog] [info] Index contained 4,919 targets\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:22.042] [jointLog] [info] Number of decoys : 1\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:46:22.042] [jointLog] [info] First decoy index : 4,918 \n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 1,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 2,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 3,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 4,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 5,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 6,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 7,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 8,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 9,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,000,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 10,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 11,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 12,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 13,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 14,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 15,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 16,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 17,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 18,500,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,000,063 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 19,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,000,001 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 20,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 21,500,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 22,000,000 \u001b[32mfragments\u001b[0m\n",
      "\u001b[32mprocessed\u001b[31m 22,500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 21,581,203; hits per frag:  0.959823\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2024-09-13 10:47:53.615] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.621] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.621] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.652] [jointLog] [info] Thread saw mini-batch with a maximum of 0.40% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.665] [jointLog] [info] Thread saw mini-batch with a maximum of 0.44% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.666] [jointLog] [info] Thread saw mini-batch with a maximum of 0.38% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.672] [jointLog] [info] Thread saw mini-batch with a maximum of 0.44% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.673] [jointLog] [info] Thread saw mini-batch with a maximum of 0.42% zero probability fragments\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.696] [jointLog] [info] Computed 4,707 rich equivalence classes for further processing\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.696] [jointLog] [info] Counted 21,873,586 total reads in the equivalence classes \n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.702] [jointLog] [info] Number of mappings discarded because of alignment score : 375,565\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.702] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 283,323\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.702] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 133,101\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.702] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 0\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.702] [jointLog] [info] Mapping rate = 95.7081%\n",
      "\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.702] [jointLog] [info] finished quantifyLibrary()\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.702] [jointLog] [info] Starting optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.705] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.705] [jointLog] [info] iteration = 0 | max rel diff. = 2501.37\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.754] [jointLog] [info] iteration = 100 | max rel diff. = 6.57063e-15\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.754] [jointLog] [info] Finished optimizer\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:53.754] [jointLog] [info] writing output \n",
      "\n",
      "\u001b[00m"
     ]
    }
   ],
   "source": [
    "!cat samples.txt | xargs -I {} salmon quant -i data/reference/transcriptome_index -l SR -r \"data/trimmed/{}_1_trimmed.fastq.gz\" -p 8 --validateMappings -o \"data/quants/{}_quant\" > dump.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 11: Report the top 10 most highly expressed genes in the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in each wild-type sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open ‘data/quants/SRR13349122_quant/quant.sf’ for reading: No such file or directory\n",
      "rna-BB28_RS07080\t117\t3.947\t356978.541980\t33036.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t229098.770148\t15383189.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t131441.969043\t3901381.000\n",
      "rna-BB28_RS17330\t369\t119.000\t74392.107979\t207551.000\n",
      "gene-BB28_RS02220\t204\t9.377\t8542.371705\t1878.000\n",
      "gene-BB28_RS20695\t231\t14.032\t7082.607784\t2330.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5848.136530\t21252.000\n",
      "gene-BB28_RS18745\t300\t51.326\t3838.522062\t4619.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3650.870077\t1040.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3418.883188\t284.000\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t462101.062780\t48026.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t205802.240114\t15519146.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t110021.184583\t3667370.000\n",
      "rna-BB28_RS17330\t369\t119.000\t61121.300280\t191507.000\n",
      "gene-BB28_RS02220\t204\t9.377\t5702.843173\t1408.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5565.014222\t2056.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5176.555422\t21126.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2896.295016\t3914.000\n",
      "gene-BB28_RS24750\t102\t3.543\t2894.246945\t270.000\n",
      "gene-BB28_RS18945\t222\t12.150\t2794.515060\t894.000\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t348582.921161\t32960.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t267512.073614\t18352818.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t129109.924058\t3915432.000\n",
      "rna-BB28_RS17330\t369\t119.000\t70751.136801\t201682.000\n",
      "gene-BB28_RS02220\t204\t9.377\t7448.058277\t1673.000\n",
      "gene-BB28_RS20695\t231\t14.032\t6259.609700\t2104.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4513.403173\t16758.000\n",
      "gene-BB28_RS18945\t222\t12.150\t3762.195901\t1095.000\n",
      "gene-BB28_RS24750\t102\t3.543\t3098.745571\t263.000\n",
      "gene-BB28_RS18745\t300\t51.326\t3067.976374\t3772.000\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!head data/quants/SRR13349122_quant/quant.sf -n 1\n",
    "!sort -nrk 4,4 data/quants/GSM5004088_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/GSM5004089_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/GSM5004090_quant/quant.sf | head -10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 most highly expressed genes in the double lysogen samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open ‘data/quants/SRR13349122_quant/quant.sf’ for reading: No such file or directory\n",
      "rna-BB28_RS07080\t117\t3.947\t444941.890913\t49486.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t241745.911592\t19508167.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t93948.807591\t3351269.000\n",
      "rna-BB28_RS17330\t369\t119.000\t80290.535400\t269213.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5162.339560\t2041.000\n",
      "rna-BB28_RS09710\t405\t155.000\t4664.405899\t20371.000\n",
      "gene-BB28_RS02220\t204\t9.377\t3955.172768\t1045.000\n",
      "gene-BB28_RS14885\t195\t8.348\t2908.074507\t684.000\n",
      "gene-BB28_RS06975\t216\t11.099\t2670.107894\t835.000\n",
      "gene-BB28_RS21780\t213\t10.625\t2328.304854\t697.000\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t391189.266059\t31215.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t276971.897018\t16035791.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t96633.969042\t2473120.000\n",
      "rna-BB28_RS17330\t369\t119.000\t78802.606265\t189570.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5002.262459\t15674.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4236.111265\t803.000\n",
      "gene-BB28_RS20695\t231\t14.032\t4177.577910\t1185.000\n",
      "gene-BB28_RS14885\t195\t8.348\t3016.267502\t509.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t2710.410444\t57148.000\n",
      "gene-BB28_RS18745\t300\t51.326\t2188.780190\t2271.000\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n",
      "rna-BB28_RS07080\t117\t3.947\t405260.200996\t38852.000\n",
      "rna-BB28_RS07075\t3114\t2864.000\t255684.443015\t17785333.000\n",
      "rna-BB28_RS07070\t1516\t1266.000\t79573.743599\t2446742.000\n",
      "rna-BB28_RS17330\t369\t119.000\t69956.774390\t202191.000\n",
      "rna-BB28_RS09710\t405\t155.000\t5923.371955\t22299.000\n",
      "gene-BB28_RS20695\t231\t14.032\t5155.549420\t1757.000\n",
      "gene-BB28_RS02220\t204\t9.377\t4364.506885\t994.000\n",
      "gene-BB28_RS14885\t195\t8.348\t3861.987108\t783.000\n",
      "gene-BB28_RS20665\t1293\t1043.000\t3692.645889\t93542.000\n",
      "gene-BB28_RS18945\t222\t12.150\t2761.764030\t815.000\n",
      "sort: write failed: standard output: Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "!head data/quants/SRR13349122_quant/quant.sf -n 1\n",
    "!sort -nrk 4,4 data/quants/GSM5004091_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/GSM5004092_quant/quant.sf | head -10\n",
    "!sort -nrk 4,4 data/quants/GSM5004093_quant/quant.sf | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 12: Report the expression of a putative acyl-ACP desaturase (BB28_RS16545) that was downregulated in the double lysogen relative to wild-type\n",
    "A acyl-transferase was reported to be downregulated in the double lysogen as shown in the table of the top 20 upregulated and downregulated genes from the paper describing the study.\n",
    "![RNA-Seq workflow](images/table-cushman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the wild-type sample. The fields in the Salmon `quant.sf` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene-BB28_RS16545\t987\t737.000\t51.681293\t893.000\n",
      "gene-BB28_RS16545\t987\t737.000\t43.494091\t844.000\n",
      "gene-BB28_RS16545\t987\t737.000\t53.187766\t939.000\n"
     ]
    }
   ],
   "source": [
    "!grep 'BB28_RS16545' data/quants/GSM5004088_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/GSM5004089_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/GSM5004090_quant/quant.sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `grep` to report the expression in the double lysogen sample. The fields in the Salmon `quant.sf` file are as follows. The level of expression is reported in the Transcripts Per Million (`TPM`) and number of reads (`NumReads`) fields:  \n",
    "`Name    Length  EffectiveLength TPM     NumReads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene-BB28_RS16545\t987\t737.000\t5.586068\t116.000\n",
      "gene-BB28_RS16545\t987\t737.000\t5.503826\t82.000\n",
      "gene-BB28_RS16545\t987\t737.000\t5.586603\t100.000\n"
     ]
    }
   ],
   "source": [
    "!grep 'BB28_RS16545' data/quants/GSM5004091_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/GSM5004092_quant/quant.sf\n",
    "!grep 'BB28_RS16545' data/quants/GSM5004093_quant/quant.sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 12: Combine Genecounts to a Single Genecount File\n",
    "Commonly, the readcounts for each sample are combined into a single table, where the rows contain the gene ID, and the columns identify the sample.\n",
    "\n",
    "As before, this can be done in many ways. The quantmerge function outputs a table.\n",
    "\n",
    "However, it is common for readcount tables to have sample headers for the columns, which this does not have.\n",
    "\n",
    "So you could manually add those headers in different ways, for instance using a spreadsheet editor, or using a shell command like sed as below to insert a line at the start of table with the relevant tab-seperated headers.\n",
    "\n",
    "You could also use sed to remove 'gene' or 'rna' prefixes from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Server Response: Not Found\n",
      "\u001b[00m[2024-09-13 10:47:56.798] [mergeLog] [info] samples: [ data/quants/GSM5004088_quant, data/quants/GSM5004089_quant, data/quants/GSM5004090_quant, data/quants/GSM5004091_quant, data/quants/GSM5004092_quant, data/quants/GSM5004093_quant ]\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:56.798] [mergeLog] [info] sample names : [ GSM5004088_quant, GSM5004089_quant, GSM5004090_quant, GSM5004091_quant, GSM5004092_quant, GSM5004093_quant ]\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:56.798] [mergeLog] [info] output column : NUMREADS\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:56.798] [mergeLog] [info] output file : data/quants/merged_quants.txt\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:56.798] [mergeLog] [info] Parsing data/quants/GSM5004088_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:56.808] [mergeLog] [info] Parsing data/quants/GSM5004089_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:56.820] [mergeLog] [info] Parsing data/quants/GSM5004090_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:56.832] [mergeLog] [info] Parsing data/quants/GSM5004091_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:56.840] [mergeLog] [info] Parsing data/quants/GSM5004092_quant/quant.sf\n",
      "\u001b[00m\u001b[00m[2024-09-13 10:47:56.851] [mergeLog] [info] Parsing data/quants/GSM5004093_quant/quant.sf\n",
      "\u001b[00mAn example of a combined genecount outputfile.\n",
      "Name\tGSM5004088\tGSM5004089\tGSM5004090\tGSM5004091\tGSM5004092\tGSM5004093\n",
      "BB28_RS24845\t118\t94\t105\t45\t36\t46\n",
      "BB28_RS24840\t308\t296\t288\t101\t81\t137\n",
      "BB28_RS24300\t1020\t834\t931\t352\t259\t405\n",
      "BB28_RS24270\t3\t4\t0\t1\t0\t3\n",
      "BB28_RS24265\t26\t14\t17\t5\t6\t9\n",
      "BB28_RS24255\t18\t20\t16\t28\t29\t55\n",
      "BB28_RS24245\t1051\t734\t799\t397\t348\t548\n",
      "BB28_RS24230\t124\t119\t91\t142\t111\t208\n",
      "BB28_RS24220\t1158\t957\t891\t651\t637\t1083\n"
     ]
    }
   ],
   "source": [
    "##first merge salmon files by number of reads.\n",
    "!salmon quantmerge --column numreads --quants data/quants/*_quant -o data/quants/merged_quants.txt\n",
    "##optinally we can rename the columns\n",
    "!sed -i \"1s/.*/Name\\tGSM5004088\\tGSM5004089\\tGSM5004090\\tGSM5004091\\tGSM5004092\\tGSM5004093/\" data/quants/merged_quants.txt\n",
    "\n",
    "##for further formatting, it may be easier in our r-code to later merge\n",
    "##if we remove the gene- and rna- prefix\n",
    "!sed -i \"s/gene-//\" data/quants/merged_quants.txt\n",
    "!sed -i \"s/rna-//\" data/quants/merged_quants.txt\n",
    "\n",
    "print(\"An example of a combined genecount outputfile.\")\n",
    "!head data/quants/merged_quants.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a name=\"workflow\">Additional Workflows</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have read counts per gene, feel free to explore the R workflow which creates plots and analyses using these readcount files, or try other alternate workflows for creating read count files, such as using snakemake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Workflow One:](Tutorial_1.ipynb) A short introduction to downloading and mapping sequences to a transcriptome using Trimmomatic and Salmon. Here is a link to the YouTube video demonstrating the tutorial: <https://youtu.be/ChGfBR4do_Y>.\n",
    "\n",
    "[Workflow One (Extended):](Tutorial_1B_Extended.ipynb) An extended version of workflow one. Once you have got your feet wet, you can retry workflow one with this extended version that covers the entire dataset, and includes elaboration such as using SRA tools for sequence downloading, and examples of running batches of fastq files through the pipeline. This workflow may take around an hour to run.\n",
    "\n",
    "[Workflow One (Using Snakemake):](Tutorial_2_Snakemake.ipynb) Using snakemake to run workflow one.\n",
    "\n",
    "[Workflow Two (DEG Analysis):](Tutorial_3_DEG_Analysis.ipynb) Using Deseq2 and R to conduct clustering and differential gene expression analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNA-Seq workflow](images/RNA-Seq_Notebook_Homepage.png)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m112"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
